<!DOCTYPE html><html lang="zh-CN" theme-mode="dark"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>5.加速 T2I 扩散模型的推理 | TO-Hitori</title><link rel="icon" type="image/x-icon" href="/favicon.ico"><link rel="preload" as="font" crossorigin="anonymous" href="/font/Bender.ttf"><link rel="preload" as="font" crossorigin="anonymous" href="/font/BenderLight.ttf"><link rel="preload" as="font" crossorigin="anonymous" href="/font/JetBrainsMono-Regular.woff2"><link rel="stylesheet" href="/css/arknights.css"><style>@font-face {
  font-family: Bender;
  src: local('Bender'), url("/font/Bender.ttf"), url("/font/Bender.otf");
}
@font-face {
  font-family: BenderLight;
  src: local('BenderLight'), url("/font/BenderLight.ttf");
}
@font-face {
  font-family: 'JetBrains Mono';
  src: local('JetBrains Mono'), url('/font/JetBrainsMono-Regular.woff2') format('woff2');
}
</style><script>var config = {"root":"/","search":{"preload":false,"activeHolder":"Enter here","blurHolder":"Search","noResult":"Data \"$0\" not found"},"code":{"codeInfo":"$0 - $1 lines","copy":"copy"}}</script><link type="text/css" rel="stylesheet" href="/lib/encrypt/hbe.style.css"><link type="text/css" rel="stylesheet" href="//unpkg.com/lightgallery@2.7.1/css/lightgallery.css"><link type="text/css" rel="stylesheet" href="//unpkg.com/lightgallery@2.7.1/css/lg-zoom.css"><link type="text/css" rel="stylesheet" href="//unpkg.com/lightgallery@2.7.1/css/lg-thumbnail.css"><link type="text/css" rel="stylesheet" href="/lib/fontawesome/css/all.min.css"><script>if (window.localStorage.getItem('theme-mode') === 'light')
 document.documentElement.setAttribute('theme-mode', 'light')
if (window.localStorage.getItem('theme-mode') === 'dark')
 document.documentElement.setAttribute('theme-mode', 'dark')</script><style>:root {
 --dark-background: url('https://ak.hypergryph.com/assets/index/images/ak/pc/bk.jpg');
 --light-background: url('/img/bk.jpg');
 --theme-encrypt-confirm: 'confirm'
}</style><script defer src="/js/arknights.js"></script><script defer src="/js/search.js"></script><script defer type="module">import mermaid from '//unpkg.com/mermaid@10.5.0/dist/mermaid.esm.mjs';
window.mermaid = mermaid;
code.paintMermaid();
</script><script async src="//unpkg.com/lightgallery@2.7.1/lightgallery.min.js"></script><script async src="//unpkg.com/lightgallery@2.7.1/plugins/zoom/lg-zoom.min.js"></script><script async src="//unpkg.com/lightgallery@2.7.1/plugins/thumbnail/lg-thumbnail.min.js"></script><script async src="/lib/encrypt/hbe.js"></script><script async src="/js/pjax.js"></script><script class="pjax-js">reset= () => {document.querySelector('.lg-container')?.remove()
lightGallery(document.getElementById('post-bg'), {
  plugins: [lgZoom,lgThumbnail],
  selector: '.item-img'})}</script><script>window.addEventListener("load",() => {pjax = new Pjax({
 cacheBust: false,
 selectors: ['title','article','#aside-block','.pjax-js','data-pjax','.busuanzi'],
 switches: {'article': Pjax.switches.sideBySide},
 switchesOptions: {
   'article': {
     classNames: {
       remove: "pjax-out",
       add: "pjax-in"
     }
   }
 }
});
document.addEventListener("pjax:complete", reset);reset()})</script><meta name="generator" content="Hexo 7.1.1"><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style></head><body><div class="loading" style="opacity: 0;"><div class="loadingBar left"></div><div class="loadingBar right"></div></div><main><header class="closed"><div class="navBtn"><i class="navBtnIcon"><span class="navBtnIconBar"></span><span class="navBtnIconBar"></span><span class="navBtnIconBar"></span></i></div><nav><div class="navItem" id="search-header"><span class="navItemTitle"><input autocomplete="off" autocorrect="off" autocapitalize="none" placeholder="Search" spellcheck="false" maxlength="50" type="text" id="search-input"></span></div><div class="navItem" id="search-holder"></div><div class="search-popup" tabindex="0"><div id="search-result"></div></div><ol class="navContent"><li class="navItem"><a class="navBlock" href="/"><span class="navItemTitle">Home</span></a></li><li class="navItem" matchdata="categories,tags"><a class="navBlock" href="/archives/"><span class="navItemTitle">Archives</span></a></li></ol></nav></header><article><div id="post-bg"><div id="post-title"><h1>5.加速 T2I 扩散模型的推理</h1><div id="post-info"><span>First Post: <div class="control"><time datetime="2024-04-10T14:32:30.000Z" id="date"> 2024-04-10</time></div></span><br><span>Last Update: <div class="control"><time datetime="2024-04-11T10:53:02.470Z" id="updated"> 2024-04-11</time></div></span><br><span>Word Count: <div class="control">1k</div></span><br><span>Read Time: <div class="control">4 min</div></span></div></div><hr><div id="post-content"><h1 id="加速-T2I-扩散模型的推理"><a href="#加速-T2I-扩散模型的推理" class="headerlink" title="加速 T2I 扩散模型的推理"></a>加速 T2I 扩散模型的推理</h1><p>由于迭代和反向扩散过程，扩散模型比 GAN 模型慢。有多种技术可以解决此限制：</p>
<ol>
<li>渐进时间步蒸馏 (LCM LoRA)</li>
<li>模型压缩 (SSD-1B) </li>
<li>重用降噪器的相邻特征 (DeepCache)。</li>
</ol>
<blockquote>
<ul>
<li><p><a target="_blank" rel="noopener" href="https://huggingface.co/docs/diffusers/using-diffusers/inference_with_lcm_lora">Performing inference with LCM-LoRA (huggingface.co)</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://huggingface.co/segmind/SSD-1B">segmind/SSD-1B · Hugging Face</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://huggingface.co/docs/diffusers/optimization/deepcache">DeepCache (huggingface.co)</a></p>
</li>
</ul>
</blockquote>
<p>但是，不一定需要使用这些技术来加速推理。仅使用 PyTorch 2，您就可以将文本到图像扩散模型的推理加速最多 3 倍。</p>
<h2 id="降低精度-bfloat16"><a href="#降低精度-bfloat16" class="headerlink" title="降低精度-bfloat16"></a>降低精度-bfloat16</h2><p>启用第一个优化：降低精度或更具体地说 bfloat16。使用降低的精度有几个好处：</p>
<ol>
<li>使用降低的数值精度（例如 float16 或 bfloat16）进行推理不会影响生成质量，但会显著改善推理延迟。</li>
<li>与 float16 相比，使用 bfloat16 的优势取决于硬件，现代 GPU 倾向于使用 bfloat16。</li>
<li>与 float16 相比，bfloat16 在与量化一起使用时更具弹性，但我们使用的最新版本的量化库 <a target="_blank" rel="noopener" href="https://github.com/pytorch-labs/ao">torchao</a> 不存在 float16 的数值问题。</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> StableDiffusionXLPipeline<br><span class="hljs-keyword">import</span> torch, os<br><br>num = <span class="hljs-built_in">len</span>(os.listdir(<span class="hljs-string">'results'</span>))<br><br>pipe = StableDiffusionXLPipeline.from_pretrained(<br>    <span class="hljs-string">"stabilityai/stable-diffusion-xl-base-1.0"</span>,<br>    torch_dtype=torch.bfloat16,   <span class="hljs-comment"># 使用float16</span><br>    variant=<span class="hljs-string">"fp16"</span><br>).to(<span class="hljs-string">"cuda"</span>)<br><br><span class="hljs-comment"># Run the attention ops without SDPA.</span><br>pipe.unet.set_default_attn_processor()<br>pipe.vae.set_default_attn_processor()<br><br>prompt = <span class="hljs-string">"Astronaut in a jungle, cold color palette, muted colors, detailed, 8k"</span><br>image = pipe(prompt, num_inference_steps=<span class="hljs-number">30</span>).images[<span class="hljs-number">0</span>]<br><br>image.save(<span class="hljs-string">f'results/sdxl-output<span class="hljs-subst">{num}</span>.jpg'</span>)<br></code></pre></td></tr></table></figure>



<h2 id="SDPA"><a href="#SDPA" class="headerlink" title="SDPA"></a>SDPA</h2><p>Attention模块运行耗时长。使用 PyTorch 的 <code>scaled_dot_product_attention</code> 函数后，它的效率要高很多。 Diffusers 中默认使用此函数，因此您<strong>无需对代码进行任何更改</strong>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> StableDiffusionXLPipeline<br><span class="hljs-keyword">import</span> torch, os<br><br>num = <span class="hljs-built_in">len</span>(os.listdir(<span class="hljs-string">'results'</span>))<br><br>pipe = StableDiffusionXLPipeline.from_pretrained(<br>    <span class="hljs-string">"stabilityai/stable-diffusion-xl-base-1.0"</span>,<br>    torch_dtype=torch.bfloat16,   <span class="hljs-comment"># 使用float16</span><br>    variant=<span class="hljs-string">"fp16"</span><br>).to(<span class="hljs-string">"cuda"</span>)<br><br><br>prompt = <span class="hljs-string">"Astronaut in a jungle, cold color palette, muted colors, detailed, 8k"</span><br>image = pipe(prompt, num_inference_steps=<span class="hljs-number">30</span>).images[<span class="hljs-number">0</span>]<br><br>image.save(<span class="hljs-string">f'results/sdxl-output<span class="hljs-subst">{num}</span>.jpg'</span>)<br></code></pre></td></tr></table></figure>

<blockquote>
<p><a target="_blank" rel="noopener" href="https://huggingface.co/docs/diffusers/optimization/torch2.0#scaled-dot-product-attention">SDPA (huggingface.co)</a></p>
</blockquote>
<h2 id="torch-compile"><a href="#torch-compile" class="headerlink" title="torch.compile"></a>torch.compile</h2><blockquote>
<p>Windows 不支持：</p>
<p><code>RuntimeError: Windows not yet supported for torch.compile</code></p>
</blockquote>
<p>PyTorch 2 包含 <code>torch.compile</code>，它使用快速且优化的内核。在 Diffusers 中，通常编译 UNet 和 VAE模块，因为它们是计算最耗时的模块。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> StableDiffusionXLPipeline<br><span class="hljs-keyword">import</span> torch<br><br>torch._inductor.config.conv_1x1_as_mm = <span class="hljs-literal">True</span><br>torch._inductor.config.coordinate_descent_tuning = <span class="hljs-literal">True</span><br>torch._inductor.config.epilogue_fusion = <span class="hljs-literal">False</span><br>torch._inductor.config.coordinate_descent_check_all_directions = <span class="hljs-literal">True</span><br></code></pre></td></tr></table></figure>

<p>在编译 UNet 和 VAE 时将其内存布局更改为“channels_last”也很重要，以确保最大速度。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">pipe.unet.to(memory_format=torch.channels_last)<br>pipe.vae.to(memory_format=torch.channels_last)<br></code></pre></td></tr></table></figure>

<p>现在编译 UNet 和 VAE 并执行推理：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">pipe.unet = torch.<span class="hljs-built_in">compile</span>(pipe.unet, mode=<span class="hljs-string">"max-autotune"</span>, fullgraph=<span class="hljs-literal">True</span>)<br>pipe.vae.decode = torch.<span class="hljs-built_in">compile</span>(pipe.vae.decode, mode=<span class="hljs-string">"max-autotune"</span>, fullgraph=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure>

<p>torch.compile 提供不同的后端和模式。为了获得最大推理速度，请对 inductor backend 使用“max-autotune”。 </p>
<p>“max-autotune”使用 CUDA 图并专门针对延迟优化编译图。 CUDA 图通过使用通过单个 CPU 操作启动多个 GPU 操作的机制，大大减少了启动 GPU 操作的开销。</p>
<h3 id="Prevent-graph-breaks"><a href="#Prevent-graph-breaks" class="headerlink" title="Prevent graph breaks"></a>Prevent graph breaks</h3><p>指定 fullgraph=True 可确保底层模型中没有图形中断，以充分利用 torch.compile，而不会降低任何性能。对于 UNet 和 VAE，这意味着更改访问返回变量的方式。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python">- latents = unet(<br>    latents, <br>    timestep=timestep, <br>    encoder_hidden_states=prompt_embeds<br>-).sample<br><br>+ latents = unet(<br>+   latents, <br>    timestep=timestep, <br>    encoder_hidden_states=prompt_embeds, <br>+   return_dict=<span class="hljs-literal">False</span><br>+)[<span class="hljs-number">0</span>]<br></code></pre></td></tr></table></figure>





<h2 id="组合Attention模块的投影矩阵"><a href="#组合Attention模块的投影矩阵" class="headerlink" title="组合Attention模块的投影矩阵"></a>组合Attention模块的投影矩阵</h2><p>SDXL 中的 UNet 和 VAE 使用类似 Transformer 的模块，由Attention模块和feed-forward模块组成。</p>
<p>在Attention模块中，使用三个不同的投影矩阵（Q、K 和 V）将输入投影到三个子空间中。这些投影在输入上单独执行。但是我们可以将投影矩阵水平组合成一个矩阵并一步执行投影。这增加了输入投影的矩阵乘法的大小并改善了量化的影响。</p>
<p>只需一行代码即可组合投影矩阵：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">pipe.fuse_qkv_projections()<br></code></pre></td></tr></table></figure>

<blockquote>
<p>这种方法效果优先，且仅适用于部分扩散模型</p>
</blockquote>
<h2 id="动态量化"><a href="#动态量化" class="headerlink" title="动态量化"></a>动态量化</h2><p>还可以使用超轻量级 PyTorch 量化库 torchao（commit SHA 54bcd5a10d0abbe7b0c045052029257099f83fd9）将动态 int8 量化应用于 UNet 和 VAE。量化给模型增加了额外的转换开销，可以通过更快的 matmuls（动态量化）来弥补。</p>
<p>如果矩阵相乘太小，这些技术可能会降低性能。</p>
<h2 id="Next"><a href="#Next" class="headerlink" title="Next"></a>Next</h2><p><a target="_blank" rel="noopener" href="https://huggingface.co/docs/diffusers/optimization/fp16">Speed up inference (huggingface.co)</a></p>
<p><a target="_blank" rel="noopener" href="https://huggingface.co/docs/diffusers/optimization/torch2.0#scaled-dot-product-attention">SDPA (huggingface.co)</a></p>
<div id="paginator"></div></div><div id="post-footer"><div id="pages" style="justify-content: flex-end"><div class="footer-link" style="width: 50%;right:1px;border-left:1px #fe2 solid"><a href="/2024/04/10/4.%20%E8%BD%BD%E5%85%A5%20LoRA%20%E8%BF%9B%E8%A1%8C%E6%8E%A8%E7%90%86/">4.载入 LoRA 进行推理 Prev →</a></div></div></div></div><div class="bottom-btn"><div><a class="i-top" id="to-top" onClick="scrolls.scrolltop();" title="To Top" style="opacity: 0; display: none;">∧ </a><a class="i-index" id="to-index" href="#toc-div" title="To Catalog">≡</a><a class="i-color" id="color-mode" onClick="colorMode.change()" title="Change Theme"></a></div></div></article><aside><div id="about"><a href="/" id="logo"><img src="https://ak.hypergryph.com/assets/index/images/ak/pc/faction/1.png" alt="Logo"></a><h1 id="Dr"><a href="/">TO-Hitori</a></h1><div id="description"><p></p></div></div><div id="aside-block"><div id="toc-div"><h1>Catalog</h1><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8A%A0%E9%80%9F-T2I-%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%8E%A8%E7%90%86"><span class="toc-number">1.</span> <span class="toc-text">加速 T2I 扩散模型的推理</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%99%8D%E4%BD%8E%E7%B2%BE%E5%BA%A6-bfloat16"><span class="toc-number">1.1.</span> <span class="toc-text">降低精度-bfloat16</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#SDPA"><span class="toc-number">1.2.</span> <span class="toc-text">SDPA</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#torch-compile"><span class="toc-number">1.3.</span> <span class="toc-text">torch.compile</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Prevent-graph-breaks"><span class="toc-number">1.3.1.</span> <span class="toc-text">Prevent graph breaks</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BB%84%E5%90%88Attention%E6%A8%A1%E5%9D%97%E7%9A%84%E6%8A%95%E5%BD%B1%E7%9F%A9%E9%98%B5"><span class="toc-number">1.4.</span> <span class="toc-text">组合Attention模块的投影矩阵</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8A%A8%E6%80%81%E9%87%8F%E5%8C%96"><span class="toc-number">1.5.</span> <span class="toc-text">动态量化</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Next"><span class="toc-number">1.6.</span> <span class="toc-text">Next</span></a></li></ol></li></ol></div></div><footer><nobr>Published with <a target="_blank" rel="noopener" href="http://hexo.io">Hexo</a></nobr><wbr><nobr> Theme <a target="_blank" rel="noopener" href="https://github.com/Yue-plus/hexo-theme-arknights">Arknights</a></nobr><wbr><nobr> by <a target="_blank" rel="noopener" href="https://github.com/Yue-plus">Yue_plus</a></nobr></footer></aside></main><canvas id="canvas-dust"></canvas></body></html>