<!DOCTYPE html><html lang="zh-CN" theme-mode="dark"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>1.解构Stable Diffusion | TO-Hitori</title><link rel="icon" type="image/x-icon" href="/favicon.ico"><link rel="preload" as="font" crossorigin="anonymous" href="/font/Bender.ttf"><link rel="preload" as="font" crossorigin="anonymous" href="/font/BenderLight.ttf"><link rel="preload" as="font" crossorigin="anonymous" href="/font/JetBrainsMono-Regular.woff2"><link rel="stylesheet" href="/css/arknights.css"><style>@font-face {
  font-family: Bender;
  src: local('Bender'), url("/font/Bender.ttf"), url("/font/Bender.otf");
}
@font-face {
  font-family: BenderLight;
  src: local('BenderLight'), url("/font/BenderLight.ttf");
}
@font-face {
  font-family: 'JetBrains Mono';
  src: local('JetBrains Mono'), url('/font/JetBrainsMono-Regular.woff2') format('woff2');
}
</style><script>var config = {"root":"/","search":{"preload":false,"activeHolder":"Enter here","blurHolder":"Search","noResult":"Data \"$0\" not found"},"code":{"codeInfo":"$0 - $1 lines","copy":"copy"}}</script><link type="text/css" rel="stylesheet" href="/lib/encrypt/hbe.style.css"><link type="text/css" rel="stylesheet" href="//unpkg.com/lightgallery@2.7.1/css/lightgallery.css"><link type="text/css" rel="stylesheet" href="//unpkg.com/lightgallery@2.7.1/css/lg-zoom.css"><link type="text/css" rel="stylesheet" href="//unpkg.com/lightgallery@2.7.1/css/lg-thumbnail.css"><link type="text/css" rel="stylesheet" href="/lib/fontawesome/css/all.min.css"><script>if (window.localStorage.getItem('theme-mode') === 'light')
 document.documentElement.setAttribute('theme-mode', 'light')
if (window.localStorage.getItem('theme-mode') === 'dark')
 document.documentElement.setAttribute('theme-mode', 'dark')</script><style>:root {
 --dark-background: url('https://ak.hypergryph.com/assets/index/images/ak/pc/bk.jpg');
 --light-background: url('/img/bk.jpg');
 --theme-encrypt-confirm: 'confirm'
}</style><script defer src="/js/arknights.js"></script><script defer src="/js/search.js"></script><script defer type="module">import mermaid from '//unpkg.com/mermaid@10.5.0/dist/mermaid.esm.mjs';
window.mermaid = mermaid;
code.paintMermaid();
</script><script async src="//unpkg.com/lightgallery@2.7.1/lightgallery.min.js"></script><script async src="//unpkg.com/lightgallery@2.7.1/plugins/zoom/lg-zoom.min.js"></script><script async src="//unpkg.com/lightgallery@2.7.1/plugins/thumbnail/lg-thumbnail.min.js"></script><script async src="/lib/encrypt/hbe.js"></script><script async src="/js/pjax.js"></script><script class="pjax-js">reset= () => {document.querySelector('.lg-container')?.remove()
lightGallery(document.getElementById('post-bg'), {
  plugins: [lgZoom,lgThumbnail],
  selector: '.item-img'})}</script><script>window.addEventListener("load",() => {pjax = new Pjax({
 cacheBust: false,
 selectors: ['title','article','#aside-block','.pjax-js','data-pjax','.busuanzi'],
 switches: {'article': Pjax.switches.sideBySide},
 switchesOptions: {
   'article': {
     classNames: {
       remove: "pjax-out",
       add: "pjax-in"
     }
   }
 }
});
document.addEventListener("pjax:complete", reset);reset()})</script><meta name="generator" content="Hexo 7.1.1"></head><body><div class="loading" style="opacity: 0;"><div class="loadingBar left"></div><div class="loadingBar right"></div></div><main><header class="closed"><div class="navBtn"><i class="navBtnIcon"><span class="navBtnIconBar"></span><span class="navBtnIconBar"></span><span class="navBtnIconBar"></span></i></div><nav><div class="navItem" id="search-header"><span class="navItemTitle"><input autocomplete="off" autocorrect="off" autocapitalize="none" placeholder="Search" spellcheck="false" maxlength="50" type="text" id="search-input"></span></div><div class="navItem" id="search-holder"></div><div class="search-popup" tabindex="0"><div id="search-result"></div></div><ol class="navContent"><li class="navItem"><a class="navBlock" href="/"><span class="navItemTitle">Home</span></a></li><li class="navItem" matchdata="categories,tags"><a class="navBlock" href="/archives/"><span class="navItemTitle">Archives</span></a></li></ol></nav></header><article><div id="post-bg"><div id="post-title"><h1>1.解构Stable Diffusion</h1><div id="post-info"><span>First Post: <div class="control"><time datetime="2024-04-07T11:35:30.000Z" id="date"> 2024-04-07</time></div></span><br><span>Last Update: <div class="control"><time datetime="2024-04-11T10:50:11.441Z" id="updated"> 2024-04-11</time></div></span></div></div><hr><div id="post-content"><h1 id="解构Stable-Diffusion"><a href="#解构Stable-Diffusion" class="headerlink" title="解构Stable Diffusion"></a>解构Stable Diffusion</h1><p>Stable Diffusion是一种文本到图像的潜在扩散模型（LDM）。它使用图像的低维表示而不是实际的像素空间，这使得它的内存效率更高。</p>
<ul>
<li><p>VAE编码器将图像压缩为低维表示，VAE解码器将压缩的低维表示转换回图像。</p>
</li>
<li><p>对于文本到图像模型，需要一个分词器（tokenizer）和一个文本编码器（text encoder）来生成文本嵌入（text embeddings）。</p>
</li>
</ul>
<p>如上所述，SD pipeline比仅包含 UNet 模型的 DDPM pipeline更复杂。Stable Diffusion具有三个独立的预训练模型。</p>
<blockquote>
<p>运作机制：<a target="_blank" rel="noopener" href="https://huggingface.co/blog/stable_diffusion#how-does-stable-diffusion-work">Stable Diffusion with 🧨 Diffusers (huggingface.co)</a></p>
</blockquote>
<ol>
<li><strong>The autoencoder (VAE)</strong>: AutoencoderKL</li>
<li><strong>The U-Net</strong>: UNet2DConditionModel</li>
<li><strong>The Text-encoder</strong>: CLIPTextModel</li>
</ol>
<h2 id="SD-pipeline-运作机制"><a href="#SD-pipeline-运作机制" class="headerlink" title="SD pipeline 运作机制"></a>SD pipeline 运作机制</h2><h3 id="载入所有组件"><a href="#载入所有组件" class="headerlink" title="载入所有组件"></a>载入所有组件</h3><p>使用 from_pretrained() 方法加载所有组件。可以在预训练的 <a target="_blank" rel="noopener" href="https://huggingface.co/runwayml/stable-diffusion-v1-5">runwayml&#x2F;stable-diffusion-v1-5</a> 中找到它们，每个组件都存储在单独的子文件夹中：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> CLIPTextModel, CLIPTokenizer<br><span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> AutoencoderKL, UNet2DConditionModel, PNDMScheduler<br><br><span class="hljs-comment"># 自编码器，使用fp16半精度权重</span><br>vae = AutoencoderKL.from_pretrained(<span class="hljs-string">&quot;sd-v1.5&quot;</span>, subfolder=<span class="hljs-string">&quot;vae&quot;</span>, variant=<span class="hljs-string">&#x27;fp16&#x27;</span>, use_safetensors=<span class="hljs-literal">True</span>)<br><span class="hljs-comment"># 分词器</span><br>tokenizer = CLIPTokenizer.from_pretrained(<span class="hljs-string">&quot;sd-v1.5&quot;</span>, subfolder=<span class="hljs-string">&quot;tokenizer&quot;</span>)<br><span class="hljs-comment"># 文本编码器，使用fp16半精度权重</span><br>text_encoder = CLIPTextModel.from_pretrained(<span class="hljs-string">&quot;sd-v1.5&quot;</span>, subfolder=<span class="hljs-string">&quot;text_encoder&quot;</span>, variant=<span class="hljs-string">&#x27;fp16&#x27;</span>, use_safetensors=<span class="hljs-literal">True</span>)<br><span class="hljs-comment"># 去噪器Unet，使用fp16半精度权重</span><br>unet = UNet2DConditionModel.from_pretrained(<span class="hljs-string">&quot;sd-v1.5&quot;</span>, subfolder=<span class="hljs-string">&quot;unet&quot;</span>, variant=<span class="hljs-string">&#x27;fp16&#x27;</span>, use_safetensors=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure>

<p>将采样器替换为 UniPCMultistepScheduler，而不是 sd1.5 默认的 PNDMScheduler，通过以下代码实现：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> UniPCMultistepScheduler<br><span class="hljs-comment"># 采样器，修改为UniPCMultistepScheduler 而不是默认的PNDMScheduler</span><br>scheduler = UniPCMultistepScheduler.from_pretrained(<span class="hljs-string">&quot;sd-v1.5&quot;</span>, subfolder=<span class="hljs-string">&quot;scheduler&quot;</span>)<br></code></pre></td></tr></table></figure>

<p>为了加速推理，将具有可训练权重的模型移至 GPU：</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs stylus">torch_device = torch<span class="hljs-selector-class">.device</span>(<span class="hljs-string">&quot;cuda&quot;</span>)<br>vae<span class="hljs-selector-class">.to</span>(torch_device)<br>text_encoder<span class="hljs-selector-class">.to</span>(torch_device)<br>unet<span class="hljs-selector-class">.to</span>(torch_device)<br></code></pre></td></tr></table></figure>



<h3 id="创建文本嵌入"><a href="#创建文本嵌入" class="headerlink" title="创建文本嵌入"></a>创建文本嵌入</h3><p>对文本进行标记以生成文本嵌入。该文本用于为 UNet 模型输入文本条件，在扩散过程中引导生成内容。</p>
<blockquote>
<p>guidance_scale: 该参数决定生成图像时应给予文本提示的权重，即文本引导的强度</p>
</blockquote>
<p>随意选择你喜欢的任何文本提示！设定基本参数如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">prompt = [<span class="hljs-string">&quot;a photograph of an astronaut riding a horse&quot;</span>]<br>batch_size = <span class="hljs-built_in">len</span>(prompt)          <span class="hljs-comment"># 生成的批量大小</span><br>height = <span class="hljs-number">512</span>                      <span class="hljs-comment"># 目标生成的图像的高</span><br>width = <span class="hljs-number">512</span>                       <span class="hljs-comment"># 目标生成的图像的宽</span><br>num_inference_steps = <span class="hljs-number">25</span>          <span class="hljs-comment"># 去噪总步数</span><br>guidance_scale = <span class="hljs-number">7.5</span>              <span class="hljs-comment"># classifier-free guidance 条件引导强度</span><br>generator = torch.manual_seed(<span class="hljs-number">0</span>)  <span class="hljs-comment"># 用于生成随机噪声的随机数种子</span><br></code></pre></td></tr></table></figure>

<p>使用分词器（tokenizer）对文本进行标记并生成嵌入：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 分词</span><br>text_input = tokenizer(<br>    prompt,                                <span class="hljs-comment"># 文本</span><br>    padding=<span class="hljs-string">&quot;max_length&quot;</span>,                  <span class="hljs-comment"># 填充文本以达到最大长度</span><br>    max_length=tokenizer.model_max_length, <span class="hljs-comment"># 设置了文本分词的最大长度 max_length = 77</span><br>    truncation=<span class="hljs-literal">True</span>,                       <span class="hljs-comment"># 如果文本超过最大长度，将截断它。</span><br>    return_tensors=<span class="hljs-string">&quot;pt&quot;</span>                    <span class="hljs-comment"># 表示返回 PyTorch 张量格式的结果。</span><br>).to(torch_device)<br><span class="hljs-comment"># 将分词结果转为文本嵌入</span><br><span class="hljs-keyword">with</span> torch.no_grad():<br>    text_embeddings = text_encoder(text_input.input_ids)[<span class="hljs-number">0</span>]<br></code></pre></td></tr></table></figure>

<p>部分变量细节：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python">text_input:<br>&lt;<span class="hljs-keyword">class</span> <span class="hljs-string">&#x27;transformers.tokenization_utils_base.BatchEncoding&#x27;</span>&gt;<br><br>text_input.input_ids:<br>  - <span class="hljs-built_in">type</span>: &lt;<span class="hljs-keyword">class</span> <span class="hljs-string">&#x27;torch.Tensor&#x27;</span>&gt;<br>  - shape: torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">77</span>]) [batch, max_length]<br>  - dtype: torch.int64<br>  - device: cuda:<span class="hljs-number">0</span><br>    <br>text_embeddings:<br>  - &lt;<span class="hljs-keyword">class</span> <span class="hljs-string">&#x27;torch.Tensor&#x27;</span>&gt;<br>  - torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">77</span>, <span class="hljs-number">768</span>])<br>  - torch.float32<br>  - cuda:<span class="hljs-number">0</span><br></code></pre></td></tr></table></figure>

<p>接下来还需要生成无条件文本嵌入，即填充标记的嵌入。这些需要与条件 text_embeddings 具有相同的形状（batch_size 和 seq_length）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">max_length = text_input.input_ids.shape[-<span class="hljs-number">1</span>] <span class="hljs-comment"># 77</span><br><span class="hljs-comment"># 用空文本获取ids</span><br>uncond_input = tokenizer(<br>    [<span class="hljs-string">&quot;&quot;</span>] * batch_size, <br>    padding=<span class="hljs-string">&quot;max_length&quot;</span>, <br>    max_length=max_length, <br>    return_tensors=<span class="hljs-string">&quot;pt&quot;</span><br>)<br>uncond_embeddings = text_encoder(uncond_input.input_ids.to(torch_device))[<span class="hljs-number">0</span>]<br></code></pre></td></tr></table></figure>

<p>让我们将条件嵌入和无条件嵌入连接为一个批量，以避免进行两次前向传递：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs pyth">text_embeddings = torch.cat([uncond_embeddings, text_embeddings])<br>  - &lt;class &#x27;torch.Tensor&#x27;&gt;<br>  - torch.Size([2, 77, 768])<br>  - torch.float32<br>  - cuda:0<br></code></pre></td></tr></table></figure>



<h3 id="创建随机噪声"><a href="#创建随机噪声" class="headerlink" title="创建随机噪声"></a>创建随机噪声</h3><p>接下来，生成一些初始随机噪声作为扩散过程的起点。它将逐渐去噪来生成图像的潜在表示。此时，潜在表示小于最终图像尺寸，VAE解码器后会将其转换为最终的 $512 \times 512$ 图像。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">print</span>(vae.config.block_out_channels) <span class="hljs-comment"># [128, 256, 512, 512]</span><br><span class="hljs-built_in">print</span>(<span class="hljs-number">2</span> ** (<span class="hljs-built_in">len</span>(vae.config.block_out_channels) - <span class="hljs-number">1</span>))<br>VAE的层数为<span class="hljs-number">4</span>，每两层之间一次下采样，下采样倍率为<span class="hljs-number">8</span><br></code></pre></td></tr></table></figure>

<p>生成初始噪声：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># shape: [1, 4, 64, 64]</span><br>latents = torch.randn(<br>    (batch_size, unet.config.in_channels, height // <span class="hljs-number">8</span>, width // <span class="hljs-number">8</span>), <br>    generator=generator                                             <br>).to(torch_device)<br></code></pre></td></tr></table></figure>



<h3 id="对图像进行去噪"><a href="#对图像进行去噪" class="headerlink" title="对图像进行去噪"></a>对图像进行去噪</h3><p>首先使用 sigma（噪声缩放值）缩放初始噪声分布，这是 UniPCMultistepScheduler 等改进采样器所需的：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">latents = latents * scheduler.init_noise_sigma<br><span class="hljs-comment"># init_noise_sigma = 1.0</span><br></code></pre></td></tr></table></figure>

<p>最后一步是创建去噪循环，该循环将逐步将纯噪声转换为文本提示所描述的图像的潜在表示。去噪循环需要做三件事：</p>
<ol>
<li>设置去噪期间采样器使用的时间步长。</li>
<li>迭代时间步。</li>
<li>在每个时间步 $t$，调用 UNet 模型来根据 $x_t$ 预测噪声残差 $\epsilon_t$，并将其传递给采样器以计算上一个时间步的噪声样本 $x_{t-1}$。<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> tqdm.auto <span class="hljs-keyword">import</span> tqdm<br><br><span class="hljs-comment"># 设定采样器的迭代步数</span><br>scheduler.set_timesteps(num_inference_steps) <span class="hljs-comment"># 25</span><br><br><span class="hljs-comment"># 迭代时间步：scheduler.timesteps</span><br><span class="hljs-comment">#   - &lt;class &#x27;torch.Tensor&#x27;&gt;</span><br><span class="hljs-comment">#   - torch.Size([25])</span><br><span class="hljs-comment">#   - torch.int64</span><br><span class="hljs-comment">#   - cpu</span><br><br><span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> tqdm(scheduler.timesteps):<br>    <span class="hljs-comment"># 如果使用CFG，为了避免进行两次前向传递，则可以在batch维度扩展输入。</span><br>    latent_model_input = torch.cat([latents] * <span class="hljs-number">2</span>)<br>    <span class="hljs-comment"># 预测噪声前，根据时间步t缩放Unet的输入x_t</span><br>    latent_model_input = scheduler.scale_model_input(latent_model_input, timestep=t)<br><br>    <span class="hljs-comment"># 预测噪声残差</span><br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        <span class="hljs-comment"># unet的输出类型：&lt;class &#x27;diffusers.models.unets.unet_2d_condition.UNet2DConditionOutput&#x27;&gt;</span><br>        noise_pred = unet(latent_model_input, t, encoder_hidden_states=text_embeddings)<br>        noise_pred = noise_pred.sample<br>        <span class="hljs-comment"># &lt;class &#x27;torch.Tensor&#x27;&gt;</span><br>        <span class="hljs-comment"># torch.Size([2, 4, 64, 64])</span><br>        <span class="hljs-comment"># torch.float32</span><br>        <span class="hljs-comment"># cuda: 0</span><br>    <br>    <span class="hljs-comment"># 使用CFG计算新的噪声残差</span><br>    noise_pred_uncond, noise_pred_text = noise_pred.chunk(<span class="hljs-number">2</span>)<br>    noise_pred = noise_pred_uncond + guidance_scale * (noise_pred_text - noise_pred_uncond)<br>    <br>    <span class="hljs-comment"># 使用采样器计算上一个时间步的样本：x_t -&gt; x_t-1</span><br>    <span class="hljs-comment"># 采样器的输出类型：&lt;class &#x27;diffusers.schedulers.scheduling_utils.SchedulerOutput&#x27;&gt;</span><br>    latents = scheduler.step(noise_pred, t, latents)<br>    latents = latents.prev_sample<br></code></pre></td></tr></table></figure></li>
</ol>
<h3 id="解码潜在表示为图像"><a href="#解码潜在表示为图像" class="headerlink" title="解码潜在表示为图像"></a>解码潜在表示为图像</h3><p>最后一步是使用 vae 将潜在表示解码为图像，并通过样本获取解码输出：</p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-comment"># 在将潜在表示输入VAE解码器前进行缩放</span><br><span class="hljs-attribute">latents</span> = <span class="hljs-number">1</span> / <span class="hljs-number">0</span>.<span class="hljs-number">18215</span> * latents<br><span class="hljs-attribute">with</span> torch.no_grad():<br>    <span class="hljs-comment"># VAE解码器输出类型：&lt;class &#x27;diffusers.models.autoencoders.vae.DecoderOutput&#x27;&gt;</span><br>    <span class="hljs-attribute">image</span> = vae.decode(latents)<br>    <span class="hljs-attribute">image</span> = image.sample<br></code></pre></td></tr></table></figure>

<p>最后，将图像转换为 PIL.Image 以查看生成的图像！</p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-comment"># 调整图像的范围和数据类型</span><br><span class="hljs-attribute">num</span> = len(os.listdir(&#x27;./results&#x27;))<br><span class="hljs-attribute">image</span> = (image / <span class="hljs-number">2</span> + <span class="hljs-number">0</span>.<span class="hljs-number">5</span>).clamp(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>).squeeze()<br><span class="hljs-attribute">image</span> = (image.permute(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>) * <span class="hljs-number">255</span>).to(torch.uint8).cpu().numpy()<br><span class="hljs-attribute">image</span> = Image.fromarray(image)<br><span class="hljs-attribute">image</span>.save(f&#x27;./results/learn_sp&#123;num&#125;.png&#x27;)<br></code></pre></td></tr></table></figure>



<p>从基本管道到复杂管道，您已经看到编写自己的扩散系统真正需要的只是一个降噪循环。该循环应设置调度程序的时间步长，对其进行迭代，并交替调用 UNet 模型来预测噪声残差，并将其传递给调度程序以计算先前的噪声样本。</p>
<p>这就是Diffusers 的设计目的：让使用模型和调度程序直观、轻松地编写自己的扩散系统。</p>
<p>Next:</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://huggingface.co/docs/diffusers/using-diffusers/contribute_pipeline">Contribute a community pipeline (huggingface.co)</a></li>
<li><a target="_blank" rel="noopener" href="https://huggingface.co/docs/diffusers/api/pipelines/overview">Pipelines (huggingface.co)</a></li>
<li>运作机制：<a target="_blank" rel="noopener" href="https://huggingface.co/blog/stable_diffusion#how-does-stable-diffusion-work">Stable Diffusion with 🧨 Diffusers (huggingface.co)</a></li>
</ul>
<div id="paginator"></div></div><div id="post-footer"><div id="pages"><div class="footer-link" style="width: 50%;text-align:right;border-right:1px #fe2 solid"><a href="/2024/04/09/2.%20Auto%20Pipeline/">← Next 2.AutoPipeline基本教程</a></div><div class="footer-link" style="width: 50%;right:1px;border-left:1px #fe2 solid"><a href="/2024/04/06/0.%20%E8%A7%A3%E6%9E%84%E5%9F%BA%E6%9C%ACpipeline/">0.解构基本pipeline Prev →</a></div></div></div></div><div class="bottom-btn"><div><a class="i-top" id="to-top" onClick="scrolls.scrolltop();" title="To Top" style="opacity: 0; display: none;">∧ </a><a class="i-index" id="to-index" href="#toc-div" title="To Catalog">≡</a><a class="i-color" id="color-mode" onClick="colorMode.change()" title="Change Theme"></a></div></div></article><aside><div id="about"><a href="/" id="logo"><img src="https://ak.hypergryph.com/assets/index/images/ak/pc/faction/1.png" alt="Logo"></a><h1 id="Dr"><a href="/">TO-Hitori</a></h1><div id="description"><p></p></div></div><div id="aside-block"><div id="toc-div"><h1>Catalog</h1><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%A7%A3%E6%9E%84Stable-Diffusion"><span class="toc-number">1.</span> <span class="toc-text">解构Stable Diffusion</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#SD-pipeline-%E8%BF%90%E4%BD%9C%E6%9C%BA%E5%88%B6"><span class="toc-number">1.1.</span> <span class="toc-text">SD pipeline 运作机制</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BD%BD%E5%85%A5%E6%89%80%E6%9C%89%E7%BB%84%E4%BB%B6"><span class="toc-number">1.1.1.</span> <span class="toc-text">载入所有组件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA%E6%96%87%E6%9C%AC%E5%B5%8C%E5%85%A5"><span class="toc-number">1.1.2.</span> <span class="toc-text">创建文本嵌入</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA%E9%9A%8F%E6%9C%BA%E5%99%AA%E5%A3%B0"><span class="toc-number">1.1.3.</span> <span class="toc-text">创建随机噪声</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AF%B9%E5%9B%BE%E5%83%8F%E8%BF%9B%E8%A1%8C%E5%8E%BB%E5%99%AA"><span class="toc-number">1.1.4.</span> <span class="toc-text">对图像进行去噪</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%A7%A3%E7%A0%81%E6%BD%9C%E5%9C%A8%E8%A1%A8%E7%A4%BA%E4%B8%BA%E5%9B%BE%E5%83%8F"><span class="toc-number">1.1.5.</span> <span class="toc-text">解码潜在表示为图像</span></a></li></ol></li></ol></li></ol></div></div><footer><nobr>Published with <a target="_blank" rel="noopener" href="http://hexo.io">Hexo</a></nobr><wbr><nobr> Theme <a target="_blank" rel="noopener" href="https://github.com/Yue-plus/hexo-theme-arknights">Arknights</a></nobr><wbr><nobr> by <a target="_blank" rel="noopener" href="https://github.com/Yue-plus">Yue_plus</a></nobr></footer></aside></main><canvas id="canvas-dust"></canvas></body></html>