<!DOCTYPE html><html lang="zh-CN" theme-mode="dark"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>1.解构Stable Diffusion | TO-Hitori</title><link rel="icon" type="image/x-icon" href="/favicon.ico"><link rel="preload" as="font" crossorigin="anonymous" href="/font/Bender.ttf"><link rel="preload" as="font" crossorigin="anonymous" href="/font/BenderLight.ttf"><link rel="preload" as="font" crossorigin="anonymous" href="/font/JetBrainsMono-Regular.woff2"><link rel="stylesheet" href="/css/arknights.css"><style>@font-face {
  font-family: Bender;
  src: local('Bender'), url("/font/Bender.ttf"), url("/font/Bender.otf");
}
@font-face {
  font-family: BenderLight;
  src: local('BenderLight'), url("/font/BenderLight.ttf");
}
@font-face {
  font-family: 'JetBrains Mono';
  src: local('JetBrains Mono'), url('/font/JetBrainsMono-Regular.woff2') format('woff2');
}
</style><script>var config = {"root":"/","search":{"preload":false,"activeHolder":"Enter here","blurHolder":"Search","noResult":"Data \"$0\" not found"},"code":{"codeInfo":"$0 - $1 lines","copy":"copy"}}</script><link type="text/css" rel="stylesheet" href="/lib/encrypt/hbe.style.css"><link type="text/css" rel="stylesheet" href="//unpkg.com/lightgallery@2.7.1/css/lightgallery.css"><link type="text/css" rel="stylesheet" href="//unpkg.com/lightgallery@2.7.1/css/lg-zoom.css"><link type="text/css" rel="stylesheet" href="//unpkg.com/lightgallery@2.7.1/css/lg-thumbnail.css"><link type="text/css" rel="stylesheet" href="/lib/fontawesome/css/all.min.css"><script>if (window.localStorage.getItem('theme-mode') === 'light')
 document.documentElement.setAttribute('theme-mode', 'light')
if (window.localStorage.getItem('theme-mode') === 'dark')
 document.documentElement.setAttribute('theme-mode', 'dark')</script><style>:root {
 --dark-background: url('https://ak.hypergryph.com/assets/index/images/ak/pc/bk.jpg');
 --light-background: url('/img/bk.jpg');
 --theme-encrypt-confirm: 'confirm'
}</style><script defer src="/js/arknights.js"></script><script defer src="/js/search.js"></script><script defer type="module">import mermaid from '//unpkg.com/mermaid@10.5.0/dist/mermaid.esm.mjs';
window.mermaid = mermaid;
code.paintMermaid();
</script><script async src="//unpkg.com/lightgallery@2.7.1/lightgallery.min.js"></script><script async src="//unpkg.com/lightgallery@2.7.1/plugins/zoom/lg-zoom.min.js"></script><script async src="//unpkg.com/lightgallery@2.7.1/plugins/thumbnail/lg-thumbnail.min.js"></script><script async src="/lib/encrypt/hbe.js"></script><script async src="/js/pjax.js"></script><script class="pjax-js">reset= () => {document.querySelector('.lg-container')?.remove()
lightGallery(document.getElementById('post-bg'), {
  plugins: [lgZoom,lgThumbnail],
  selector: '.item-img'})}</script><script>window.addEventListener("load",() => {pjax = new Pjax({
 cacheBust: false,
 selectors: ['title','article','#aside-block','.pjax-js','data-pjax','.busuanzi'],
 switches: {'article': Pjax.switches.sideBySide},
 switchesOptions: {
   'article': {
     classNames: {
       remove: "pjax-out",
       add: "pjax-in"
     }
   }
 }
});
document.addEventListener("pjax:complete", reset);reset()})</script><meta name="generator" content="Hexo 7.1.1"><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style></head><body><div class="loading" style="opacity: 0;"><div class="loadingBar left"></div><div class="loadingBar right"></div></div><main><header class="closed"><div class="navBtn"><i class="navBtnIcon"><span class="navBtnIconBar"></span><span class="navBtnIconBar"></span><span class="navBtnIconBar"></span></i></div><nav><div class="navItem" id="search-header"><span class="navItemTitle"><input autocomplete="off" autocorrect="off" autocapitalize="none" placeholder="Search" spellcheck="false" maxlength="50" type="text" id="search-input"></span></div><div class="navItem" id="search-holder"></div><div class="search-popup" tabindex="0"><div id="search-result"></div></div><ol class="navContent"><li class="navItem"><a class="navBlock" href="/"><span class="navItemTitle">Home</span></a></li><li class="navItem" matchdata="categories,tags"><a class="navBlock" href="/archives/"><span class="navItemTitle">Archives</span></a></li></ol></nav></header><article><div id="post-bg"><div id="post-title"><h1>1.解构Stable Diffusion</h1><div id="post-info"><span>First Post: <div class="control"><time datetime="2024-04-07T11:35:30.000Z" id="date"> 2024-04-07</time></div></span><br><span>Last Update: <div class="control"><time datetime="2024-04-11T10:57:03.359Z" id="updated"> 2024-04-11</time></div></span></div></div><hr><div id="post-content"><h1 id="解构Stable-Diffusion"><a href="#解构Stable-Diffusion" class="headerlink" title="解构Stable Diffusion"></a>解构Stable Diffusion</h1><p>Stable Diffusion是一种文本到图像的潜在扩散模型（LDM）。它使用图像的低维表示而不是实际的像素空间，这使得它的内存效率更高。</p>
<ul>
<li><p>VAE编码器将图像压缩为低维表示，VAE解码器将压缩的低维表示转换回图像。</p>
</li>
<li><p>对于文本到图像模型，需要一个分词器（tokenizer）和一个文本编码器（text encoder）来生成文本嵌入（text embeddings）。</p>
</li>
</ul>
<p>如上所述，SD pipeline比仅包含 UNet 模型的 DDPM pipeline更复杂。Stable Diffusion具有三个独立的预训练模型。</p>
<blockquote>
<p>运作机制：<a target="_blank" rel="noopener" href="https://huggingface.co/blog/stable_diffusion#how-does-stable-diffusion-work">Stable Diffusion with 🧨 Diffusers (huggingface.co)</a></p>
</blockquote>
<ol>
<li><strong>The autoencoder (VAE)</strong>: AutoencoderKL</li>
<li><strong>The U-Net</strong>: UNet2DConditionModel</li>
<li><strong>The Text-encoder</strong>: CLIPTextModel</li>
</ol>
<h2 id="SD-pipeline-运作机制"><a href="#SD-pipeline-运作机制" class="headerlink" title="SD pipeline 运作机制"></a>SD pipeline 运作机制</h2><h3 id="载入所有组件"><a href="#载入所有组件" class="headerlink" title="载入所有组件"></a>载入所有组件</h3><p>使用 from_pretrained() 方法加载所有组件。可以在预训练的 <a target="_blank" rel="noopener" href="https://huggingface.co/runwayml/stable-diffusion-v1-5">runwayml/stable-diffusion-v1-5</a> 中找到它们，每个组件都存储在单独的子文件夹中：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> CLIPTextModel, CLIPTokenizer<br><span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> AutoencoderKL, UNet2DConditionModel, PNDMScheduler<br><br><span class="hljs-comment"># 自编码器，使用fp16半精度权重</span><br>vae = AutoencoderKL.from_pretrained(<span class="hljs-string">"sd-v1.5"</span>, subfolder=<span class="hljs-string">"vae"</span>, variant=<span class="hljs-string">'fp16'</span>, use_safetensors=<span class="hljs-literal">True</span>)<br><span class="hljs-comment"># 分词器</span><br>tokenizer = CLIPTokenizer.from_pretrained(<span class="hljs-string">"sd-v1.5"</span>, subfolder=<span class="hljs-string">"tokenizer"</span>)<br><span class="hljs-comment"># 文本编码器，使用fp16半精度权重</span><br>text_encoder = CLIPTextModel.from_pretrained(<span class="hljs-string">"sd-v1.5"</span>, subfolder=<span class="hljs-string">"text_encoder"</span>, variant=<span class="hljs-string">'fp16'</span>, use_safetensors=<span class="hljs-literal">True</span>)<br><span class="hljs-comment"># 去噪器Unet，使用fp16半精度权重</span><br>unet = UNet2DConditionModel.from_pretrained(<span class="hljs-string">"sd-v1.5"</span>, subfolder=<span class="hljs-string">"unet"</span>, variant=<span class="hljs-string">'fp16'</span>, use_safetensors=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure>

<p>将采样器替换为 UniPCMultistepScheduler，而不是 sd1.5 默认的 PNDMScheduler，通过以下代码实现：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> UniPCMultistepScheduler<br><span class="hljs-comment"># 采样器，修改为UniPCMultistepScheduler 而不是默认的PNDMScheduler</span><br>scheduler = UniPCMultistepScheduler.from_pretrained(<span class="hljs-string">"sd-v1.5"</span>, subfolder=<span class="hljs-string">"scheduler"</span>)<br></code></pre></td></tr></table></figure>

<p>为了加速推理，将具有可训练权重的模型移至 GPU：</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs stylus">torch_device = torch<span class="hljs-selector-class">.device</span>(<span class="hljs-string">"cuda"</span>)<br>vae<span class="hljs-selector-class">.to</span>(torch_device)<br>text_encoder<span class="hljs-selector-class">.to</span>(torch_device)<br>unet<span class="hljs-selector-class">.to</span>(torch_device)<br></code></pre></td></tr></table></figure>



<h3 id="创建文本嵌入"><a href="#创建文本嵌入" class="headerlink" title="创建文本嵌入"></a>创建文本嵌入</h3><p>对文本进行标记以生成文本嵌入。该文本用于为 UNet 模型输入文本条件，在扩散过程中引导生成内容。</p>
<blockquote>
<p>guidance_scale: 该参数决定生成图像时应给予文本提示的权重，即文本引导的强度</p>
</blockquote>
<p>随意选择你喜欢的任何文本提示！设定基本参数如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">prompt = [<span class="hljs-string">"a photograph of an astronaut riding a horse"</span>]<br>batch_size = <span class="hljs-built_in">len</span>(prompt)          <span class="hljs-comment"># 生成的批量大小</span><br>height = <span class="hljs-number">512</span>                      <span class="hljs-comment"># 目标生成的图像的高</span><br>width = <span class="hljs-number">512</span>                       <span class="hljs-comment"># 目标生成的图像的宽</span><br>num_inference_steps = <span class="hljs-number">25</span>          <span class="hljs-comment"># 去噪总步数</span><br>guidance_scale = <span class="hljs-number">7.5</span>              <span class="hljs-comment"># classifier-free guidance 条件引导强度</span><br>generator = torch.manual_seed(<span class="hljs-number">0</span>)  <span class="hljs-comment"># 用于生成随机噪声的随机数种子</span><br></code></pre></td></tr></table></figure>

<p>使用分词器（tokenizer）对文本进行标记并生成嵌入：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 分词</span><br>text_input = tokenizer(<br>    prompt,                                <span class="hljs-comment"># 文本</span><br>    padding=<span class="hljs-string">"max_length"</span>,                  <span class="hljs-comment"># 填充文本以达到最大长度</span><br>    max_length=tokenizer.model_max_length, <span class="hljs-comment"># 设置了文本分词的最大长度 max_length = 77</span><br>    truncation=<span class="hljs-literal">True</span>,                       <span class="hljs-comment"># 如果文本超过最大长度，将截断它。</span><br>    return_tensors=<span class="hljs-string">"pt"</span>                    <span class="hljs-comment"># 表示返回 PyTorch 张量格式的结果。</span><br>).to(torch_device)<br><span class="hljs-comment"># 将分词结果转为文本嵌入</span><br><span class="hljs-keyword">with</span> torch.no_grad():<br>    text_embeddings = text_encoder(text_input.input_ids)[<span class="hljs-number">0</span>]<br></code></pre></td></tr></table></figure>

<p>部分变量细节：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python">text_input:<br>&lt;<span class="hljs-keyword">class</span> <span class="hljs-string">'transformers.tokenization_utils_base.BatchEncoding'</span>&gt;<br><br>text_input.input_ids:<br>  - <span class="hljs-built_in">type</span>: &lt;<span class="hljs-keyword">class</span> <span class="hljs-string">'torch.Tensor'</span>&gt;<br>  - shape: torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">77</span>]) [batch, max_length]<br>  - dtype: torch.int64<br>  - device: cuda:<span class="hljs-number">0</span><br>    <br>text_embeddings:<br>  - &lt;<span class="hljs-keyword">class</span> <span class="hljs-string">'torch.Tensor'</span>&gt;<br>  - torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">77</span>, <span class="hljs-number">768</span>])<br>  - torch.float32<br>  - cuda:<span class="hljs-number">0</span><br></code></pre></td></tr></table></figure>

<p>接下来还需要生成无条件文本嵌入，即填充标记的嵌入。这些需要与条件 text_embeddings 具有相同的形状（batch_size 和 seq_length）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">max_length = text_input.input_ids.shape[-<span class="hljs-number">1</span>] <span class="hljs-comment"># 77</span><br><span class="hljs-comment"># 用空文本获取ids</span><br>uncond_input = tokenizer(<br>    [<span class="hljs-string">""</span>] * batch_size, <br>    padding=<span class="hljs-string">"max_length"</span>, <br>    max_length=max_length, <br>    return_tensors=<span class="hljs-string">"pt"</span><br>)<br>uncond_embeddings = text_encoder(uncond_input.input_ids.to(torch_device))[<span class="hljs-number">0</span>]<br></code></pre></td></tr></table></figure>

<p>让我们将条件嵌入和无条件嵌入连接为一个批量，以避免进行两次前向传递：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs pyth">text_embeddings = torch.cat([uncond_embeddings, text_embeddings])<br>  - &lt;class 'torch.Tensor'&gt;<br>  - torch.Size([2, 77, 768])<br>  - torch.float32<br>  - cuda:0<br></code></pre></td></tr></table></figure>



<h3 id="创建随机噪声"><a href="#创建随机噪声" class="headerlink" title="创建随机噪声"></a>创建随机噪声</h3><p>接下来，生成一些初始随机噪声作为扩散过程的起点。它将逐渐去噪来生成图像的潜在表示。此时，潜在表示小于最终图像尺寸，VAE解码器后会将其转换为最终的 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.05ex;" xmlns="http://www.w3.org/2000/svg" width="9.553ex" height="1.557ex" role="img" focusable="false" viewBox="0 -666 4222.4 688"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="35" d="M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(1000,0)"></path></g><g data-mml-node="mo" transform="translate(1722.2,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mn" transform="translate(2722.4,0)"><path data-c="35" d="M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(1000,0)"></path></g></g></g></svg></mjx-container> 图像。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">print</span>(vae.config.block_out_channels) <span class="hljs-comment"># [128, 256, 512, 512]</span><br><span class="hljs-built_in">print</span>(<span class="hljs-number">2</span> ** (<span class="hljs-built_in">len</span>(vae.config.block_out_channels) - <span class="hljs-number">1</span>))<br>VAE的层数为<span class="hljs-number">4</span>，每两层之间一次下采样，下采样倍率为<span class="hljs-number">8</span><br></code></pre></td></tr></table></figure>

<p>生成初始噪声：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># shape: [1, 4, 64, 64]</span><br>latents = torch.randn(<br>    (batch_size, unet.config.in_channels, height // <span class="hljs-number">8</span>, width // <span class="hljs-number">8</span>), <br>    generator=generator                                             <br>).to(torch_device)<br></code></pre></td></tr></table></figure>



<h3 id="对图像进行去噪"><a href="#对图像进行去噪" class="headerlink" title="对图像进行去噪"></a>对图像进行去噪</h3><p>首先使用 sigma（噪声缩放值）缩放初始噪声分布，这是 UniPCMultistepScheduler 等改进采样器所需的：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">latents = latents * scheduler.init_noise_sigma<br><span class="hljs-comment"># init_noise_sigma = 1.0</span><br></code></pre></td></tr></table></figure>

<p>最后一步是创建去噪循环，该循环将逐步将纯噪声转换为文本提示所描述的图像的潜在表示。去噪循环需要做三件事：</p>
<ol>
<li>设置去噪期间采样器使用的时间步长。</li>
<li>迭代时间步。</li>
<li>在每个时间步 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="0.817ex" height="1.441ex" role="img" focusable="false" viewBox="0 -626 361 637"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g></g></g></svg></mjx-container>，调用 UNet 模型来根据 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.357ex;" xmlns="http://www.w3.org/2000/svg" width="2.059ex" height="1.357ex" role="img" focusable="false" viewBox="0 -442 910.3 599.8"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mi" transform="translate(605,-150) scale(0.707)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g></g></g></g></svg></mjx-container> 预测噪声残差 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.357ex;" xmlns="http://www.w3.org/2000/svg" width="1.684ex" height="1.332ex" role="img" focusable="false" viewBox="0 -431 744.3 588.8"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D716" d="M227 -11Q149 -11 95 41T40 174Q40 262 87 322Q121 367 173 396T287 430Q289 431 329 431H367Q382 426 382 411Q382 385 341 385H325H312Q191 385 154 277L150 265H327Q340 256 340 246Q340 228 320 219H138V217Q128 187 128 143Q128 77 160 52T231 26Q258 26 284 36T326 57T343 68Q350 68 354 58T358 39Q358 36 357 35Q354 31 337 21T289 0T227 -11Z"></path></g><g data-mml-node="mi" transform="translate(439,-150) scale(0.707)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g></g></g></g></svg></mjx-container>，并将其传递给采样器以计算上一个时间步的噪声样本 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.471ex;" xmlns="http://www.w3.org/2000/svg" width="4.104ex" height="1.471ex" role="img" focusable="false" viewBox="0 -442 1813.9 650"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="TeXAtom" transform="translate(605,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(361,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(1139,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></g></g></svg></mjx-container>。<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> tqdm.auto <span class="hljs-keyword">import</span> tqdm<br><br><span class="hljs-comment"># 设定采样器的迭代步数</span><br>scheduler.set_timesteps(num_inference_steps) <span class="hljs-comment"># 25</span><br><br><span class="hljs-comment"># 迭代时间步：scheduler.timesteps</span><br><span class="hljs-comment">#   - &lt;class 'torch.Tensor'&gt;</span><br><span class="hljs-comment">#   - torch.Size([25])</span><br><span class="hljs-comment">#   - torch.int64</span><br><span class="hljs-comment">#   - cpu</span><br><br><span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> tqdm(scheduler.timesteps):<br>    <span class="hljs-comment"># 如果使用CFG，为了避免进行两次前向传递，则可以在batch维度扩展输入。</span><br>    latent_model_input = torch.cat([latents] * <span class="hljs-number">2</span>)<br>    <span class="hljs-comment"># 预测噪声前，根据时间步t缩放Unet的输入x_t</span><br>    latent_model_input = scheduler.scale_model_input(latent_model_input, timestep=t)<br><br>    <span class="hljs-comment"># 预测噪声残差</span><br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        <span class="hljs-comment"># unet的输出类型：&lt;class 'diffusers.models.unets.unet_2d_condition.UNet2DConditionOutput'&gt;</span><br>        noise_pred = unet(latent_model_input, t, encoder_hidden_states=text_embeddings)<br>        noise_pred = noise_pred.sample<br>        <span class="hljs-comment"># &lt;class 'torch.Tensor'&gt;</span><br>        <span class="hljs-comment"># torch.Size([2, 4, 64, 64])</span><br>        <span class="hljs-comment"># torch.float32</span><br>        <span class="hljs-comment"># cuda: 0</span><br>    <br>    <span class="hljs-comment"># 使用CFG计算新的噪声残差</span><br>    noise_pred_uncond, noise_pred_text = noise_pred.chunk(<span class="hljs-number">2</span>)<br>    noise_pred = noise_pred_uncond + guidance_scale * (noise_pred_text - noise_pred_uncond)<br>    <br>    <span class="hljs-comment"># 使用采样器计算上一个时间步的样本：x_t -&gt; x_t-1</span><br>    <span class="hljs-comment"># 采样器的输出类型：&lt;class 'diffusers.schedulers.scheduling_utils.SchedulerOutput'&gt;</span><br>    latents = scheduler.step(noise_pred, t, latents)<br>    latents = latents.prev_sample<br></code></pre></td></tr></table></figure></li>
</ol>
<h3 id="解码潜在表示为图像"><a href="#解码潜在表示为图像" class="headerlink" title="解码潜在表示为图像"></a>解码潜在表示为图像</h3><p>最后一步是使用 vae 将潜在表示解码为图像，并通过样本获取解码输出：</p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-comment"># 在将潜在表示输入VAE解码器前进行缩放</span><br><span class="hljs-attribute">latents</span> = <span class="hljs-number">1</span> / <span class="hljs-number">0</span>.<span class="hljs-number">18215</span> * latents<br><span class="hljs-attribute">with</span> torch.no_grad():<br>    <span class="hljs-comment"># VAE解码器输出类型：&lt;class 'diffusers.models.autoencoders.vae.DecoderOutput'&gt;</span><br>    <span class="hljs-attribute">image</span> = vae.decode(latents)<br>    <span class="hljs-attribute">image</span> = image.sample<br></code></pre></td></tr></table></figure>

<p>最后，将图像转换为 PIL.Image 以查看生成的图像！</p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-comment"># 调整图像的范围和数据类型</span><br><span class="hljs-attribute">num</span> = len(os.listdir('./results'))<br><span class="hljs-attribute">image</span> = (image / <span class="hljs-number">2</span> + <span class="hljs-number">0</span>.<span class="hljs-number">5</span>).clamp(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>).squeeze()<br><span class="hljs-attribute">image</span> = (image.permute(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>) * <span class="hljs-number">255</span>).to(torch.uint8).cpu().numpy()<br><span class="hljs-attribute">image</span> = Image.fromarray(image)<br><span class="hljs-attribute">image</span>.save(f'./results/learn_sp{num}.png')<br></code></pre></td></tr></table></figure>



<p>从基本管道到复杂管道，您已经看到编写自己的扩散系统真正需要的只是一个降噪循环。该循环应设置调度程序的时间步长，对其进行迭代，并交替调用 UNet 模型来预测噪声残差，并将其传递给调度程序以计算先前的噪声样本。</p>
<p>这就是Diffusers 的设计目的：让使用模型和调度程序直观、轻松地编写自己的扩散系统。</p>
<p>Next:</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://huggingface.co/docs/diffusers/using-diffusers/contribute_pipeline">Contribute a community pipeline (huggingface.co)</a></li>
<li><a target="_blank" rel="noopener" href="https://huggingface.co/docs/diffusers/api/pipelines/overview">Pipelines (huggingface.co)</a></li>
<li>运作机制：<a target="_blank" rel="noopener" href="https://huggingface.co/blog/stable_diffusion#how-does-stable-diffusion-work">Stable Diffusion with 🧨 Diffusers (huggingface.co)</a></li>
</ul>
<div id="paginator"></div></div><div id="post-footer"><div id="pages"><div class="footer-link" style="width: 50%;text-align:right;border-right:1px #fe2 solid"><a href="/2024/04/09/2.%20Auto%20Pipeline/">← Next 2.AutoPipeline基本教程</a></div><div class="footer-link" style="width: 50%;right:1px;border-left:1px #fe2 solid"><a href="/2024/04/06/0.%20%E8%A7%A3%E6%9E%84%E5%9F%BA%E6%9C%ACpipeline/">0.解构基本pipeline Prev →</a></div></div></div></div><div class="bottom-btn"><div><a class="i-top" id="to-top" onClick="scrolls.scrolltop();" title="To Top" style="opacity: 0; display: none;">∧ </a><a class="i-index" id="to-index" href="#toc-div" title="To Catalog">≡</a><a class="i-color" id="color-mode" onClick="colorMode.change()" title="Change Theme"></a></div></div></article><aside><div id="about"><a href="/" id="logo"><img src="https://ak.hypergryph.com/assets/index/images/ak/pc/faction/1.png" alt="Logo"></a><h1 id="Dr"><a href="/">TO-Hitori</a></h1><div id="description"><p></p></div></div><div id="aside-block"><div id="toc-div"><h1>Catalog</h1><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%A7%A3%E6%9E%84Stable-Diffusion"><span class="toc-number">1.</span> <span class="toc-text">解构Stable Diffusion</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#SD-pipeline-%E8%BF%90%E4%BD%9C%E6%9C%BA%E5%88%B6"><span class="toc-number">1.1.</span> <span class="toc-text">SD pipeline 运作机制</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BD%BD%E5%85%A5%E6%89%80%E6%9C%89%E7%BB%84%E4%BB%B6"><span class="toc-number">1.1.1.</span> <span class="toc-text">载入所有组件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA%E6%96%87%E6%9C%AC%E5%B5%8C%E5%85%A5"><span class="toc-number">1.1.2.</span> <span class="toc-text">创建文本嵌入</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA%E9%9A%8F%E6%9C%BA%E5%99%AA%E5%A3%B0"><span class="toc-number">1.1.3.</span> <span class="toc-text">创建随机噪声</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AF%B9%E5%9B%BE%E5%83%8F%E8%BF%9B%E8%A1%8C%E5%8E%BB%E5%99%AA"><span class="toc-number">1.1.4.</span> <span class="toc-text">对图像进行去噪</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%A7%A3%E7%A0%81%E6%BD%9C%E5%9C%A8%E8%A1%A8%E7%A4%BA%E4%B8%BA%E5%9B%BE%E5%83%8F"><span class="toc-number">1.1.5.</span> <span class="toc-text">解码潜在表示为图像</span></a></li></ol></li></ol></li></ol></div></div><footer><nobr>Published with <a target="_blank" rel="noopener" href="http://hexo.io">Hexo</a></nobr><wbr><nobr> Theme <a target="_blank" rel="noopener" href="https://github.com/Yue-plus/hexo-theme-arknights">Arknights</a></nobr><wbr><nobr> by <a target="_blank" rel="noopener" href="https://github.com/Yue-plus">Yue_plus</a></nobr></footer></aside></main><canvas id="canvas-dust"></canvas></body></html>