<!DOCTYPE html><html lang="zh-CN" theme-mode="dark"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>【Using-Diffusers-01】Loading &amp; Hub | TO-Hitori</title><link rel="icon" type="image/x-icon" href="/favicon.ico"><link rel="preload" as="font" crossorigin="anonymous" href="/font/Bender.ttf"><link rel="preload" as="font" crossorigin="anonymous" href="/font/BenderLight.ttf"><link rel="preload" as="font" crossorigin="anonymous" href="/font/JetBrainsMono-Regular.woff2"><link rel="stylesheet" href="/css/arknights.css"><style>@font-face {
  font-family: Bender;
  src: local('Bender'), url("/font/Bender.ttf"), url("/font/Bender.otf");
}
@font-face {
  font-family: BenderLight;
  src: local('BenderLight'), url("/font/BenderLight.ttf");
}
@font-face {
  font-family: 'JetBrains Mono';
  src: local('JetBrains Mono'), url('/font/JetBrainsMono-Regular.woff2') format('woff2');
}
</style><script>var config = {"root":"/","search":{"preload":false,"activeHolder":"Enter here","blurHolder":"Search","noResult":"Data \"$0\" not found"},"code":{"codeInfo":"$0 - $1 lines","copy":"copy"}}</script><link type="text/css" rel="stylesheet" href="/lib/encrypt/hbe.style.css"><link type="text/css" rel="stylesheet" href="//unpkg.com/lightgallery@2.7.1/css/lightgallery.css"><link type="text/css" rel="stylesheet" href="//unpkg.com/lightgallery@2.7.1/css/lg-zoom.css"><link type="text/css" rel="stylesheet" href="//unpkg.com/lightgallery@2.7.1/css/lg-thumbnail.css"><link type="text/css" rel="stylesheet" href="/lib/fontawesome/css/all.min.css"><script>if (window.localStorage.getItem('theme-mode') === 'light')
 document.documentElement.setAttribute('theme-mode', 'light')
if (window.localStorage.getItem('theme-mode') === 'dark')
 document.documentElement.setAttribute('theme-mode', 'dark')</script><style>:root {
 --dark-background: url('https://ak.hypergryph.com/assets/index/images/ak/pc/bk.jpg');
 --light-background: url('/img/bk.jpg');
 --theme-encrypt-confirm: 'confirm'
}</style><script defer src="/js/arknights.js"></script><script defer src="/js/search.js"></script><script defer type="module">import mermaid from '//unpkg.com/mermaid@10.5.0/dist/mermaid.esm.mjs';
window.mermaid = mermaid;
code.paintMermaid();
</script><script async src="//unpkg.com/lightgallery@2.7.1/lightgallery.min.js"></script><script async src="//unpkg.com/lightgallery@2.7.1/plugins/zoom/lg-zoom.min.js"></script><script async src="//unpkg.com/lightgallery@2.7.1/plugins/thumbnail/lg-thumbnail.min.js"></script><script async src="/lib/encrypt/hbe.js"></script><script async src="/js/pjax.js"></script><script class="pjax-js">reset= () => {document.querySelector('.lg-container')?.remove()
lightGallery(document.getElementById('post-bg'), {
  plugins: [lgZoom,lgThumbnail],
  selector: '.item-img'})}</script><script>window.addEventListener("load",() => {pjax = new Pjax({
 cacheBust: false,
 selectors: ['title','article','#aside-block','.pjax-js','data-pjax','.busuanzi'],
 switches: {'article': Pjax.switches.sideBySide},
 switchesOptions: {
   'article': {
     classNames: {
       remove: "pjax-out",
       add: "pjax-in"
     }
   }
 }
});
document.addEventListener("pjax:complete", reset);reset()})</script><meta name="generator" content="Hexo 7.1.1"><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style></head><body><div class="loading" style="opacity: 0;"><div class="loadingBar left"></div><div class="loadingBar right"></div></div><main><header class="closed"><div class="navBtn"><i class="navBtnIcon"><span class="navBtnIconBar"></span><span class="navBtnIconBar"></span><span class="navBtnIconBar"></span></i></div><nav><div class="navItem" id="search-header"><span class="navItemTitle"><input autocomplete="off" autocorrect="off" autocapitalize="none" placeholder="Search" spellcheck="false" maxlength="50" type="text" id="search-input"></span></div><div class="navItem" id="search-holder"></div><div class="search-popup" tabindex="0"><div id="search-result"></div></div><ol class="navContent"><li class="navItem"><a class="navBlock" href="/"><span class="navItemTitle">Home</span></a></li><li class="navItem" matchdata="categories,tags"><a class="navBlock" href="/archives/"><span class="navItemTitle">Archives</span></a></li></ol></nav></header><article><div id="post-bg"><div id="post-title"><h1>【Using-Diffusers-01】Loading &amp; Hub</h1><div id="post-info"><span>First Post: <div class="control"><time datetime="2024-04-11T14:00:30.000Z" id="date"> 2024-04-11</time></div></span><br><span>Last Update: <div class="control"><time datetime="2024-04-16T13:46:12.077Z" id="updated"> 2024-04-16</time></div></span><br><span>Word Count: <div class="control">6.8k</div></span><br><span>Read Time: <div class="control">29 min</div></span></div></div><hr><div id="post-content"><p>[TOC]</p>
<h1 id="Loading-Hub"><a href="#Loading-Hub" class="headerlink" title="Loading & Hub"></a>Loading &amp; Hub</h1><h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><p>Diffusers 为生成任务提供了许多 <strong>Pipeline</strong>、<strong>模型</strong>和<strong>采样器</strong>。为了使加载这些组件尽可能简单，我们提供了一个统一的方法 <code>from_pretrained()</code> 从 Hugging Face Hub 或本地路径加载任何组件。</p>
<p>从 Hugging Face Hub 加载模型需要配置代理：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br>os.environ[<span class="hljs-string">'HTTP_PROXY'</span>] = <span class="hljs-string">'http://127.0.0.1:33210'</span><br>os.environ[<span class="hljs-string">'HTTPS_PROXY'</span>] = <span class="hljs-string">'http://127.0.0.1:33210'</span><br></code></pre></td></tr></table></figure>

<p>本节的主要内容包括：</p>
<ul>
<li>加载 Pipeline</li>
<li>加载 Pipeline 中的不同组件</li>
<li>加载检查点变体</li>
<li>加载社区 Pipeline 所需了解的所有信息。</li>
<li>加载采样器并比较使用不同采样器的速度和质量权衡。</li>
<li>转换和加载 KerasCV 检查点，以便在 PyTorch 中通过 Diffusers 使用它们。</li>
</ul>
<h2 id="Load-pipelines-models-and-schedulers"><a href="#Load-pipelines-models-and-schedulers" class="headerlink" title="Load pipelines, models, and schedulers"></a>Load pipelines, models, and schedulers</h2><p><code>DiffusionPipeline</code> 将整个扩散系统的复杂组成包装到一个易于使用的 API 中，同时保持足够的灵活性，例如将每个组件单独加载来组装您自己的扩散系统。</p>
<p>推理或训练所需的一切都可以通过 <code>from_pretrained()</code> 方法访问。</p>
<ul>
<li>来自 Hub 和本地的 Pipeline </li>
<li>将不同的组件加入 Pipeline 中</li>
<li>检查点变体，例如不同的浮点类型或非指数平均 (EMA) 权重 </li>
<li>模型和采样器</li>
</ul>
<h3 id="通过Diffusion-Pipeline加载检查点"><a href="#通过Diffusion-Pipeline加载检查点" class="headerlink" title="通过Diffusion Pipeline加载检查点"></a>通过Diffusion Pipeline加载检查点</h3><p><code>DiffusionPipeline</code> 类是从 Hub 加载最新扩散模型的最简单、最通用的方法。</p>
<p><code>DiffusionPipeline.from_pretrained()</code> 方法自动从检查点检测正确的Pipeline类，并返回用于推理的 Pipeline 实例。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> DiffusionPipeline<br><span class="hljs-keyword">import</span> torch<br><br><span class="hljs-comment"># 从HF Hub加载，会自动下载需要使用的文件（需要VPN，配置代理）</span><br><span class="hljs-comment"># repo_id = "runwayml/stable-diffusion-v1-5"</span><br><span class="hljs-comment"># 从本地路径加载</span><br>checkpoint_path = <span class="hljs-string">r'D:\MyCode\Torch_Deom\SDXL\stable-diffusion-xl-base-1.0'</span><br>pipe = DiffusionPipeline.from_pretrained(<br>    checkpoint_path,            <span class="hljs-comment"># 或 repo_id</span><br>    use_safetensors=<span class="hljs-literal">True</span>,       <span class="hljs-comment"># 使用后缀为.safetensors的权重文件</span><br>    torch_dtype=torch.float16,  <span class="hljs-comment"># 加载16位的半精度模型</span><br>    variant=<span class="hljs-string">"fp16"</span>              <span class="hljs-comment"># 16位权重文件中包含'fp16'字段</span><br>)<br></code></pre></td></tr></table></figure>

<p>出现如下信息表示成功加载各个组件：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">Loading pipeline components...: 100%|██████████| 7/7 [00:00&lt;00:00,  9.67it/s]<br></code></pre></td></tr></table></figure>

<p>还可以加载具有特定 Pipeline 类的检查点。要获得相同的结果，请使用 <code>StableDiffusionXLPipeline</code> 类：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> StableDiffusionXLPipeline<br><span class="hljs-keyword">import</span> torch<br><br><span class="hljs-comment"># repo_id = "runwayml/stable-diffusion-v1-5"</span><br>checkpoint_path = <span class="hljs-string">r'D:\MyCode\Torch_Deom\SDXL\stable-diffusion-xl-base-1.0'</span><br>pipe = StableDiffusionXLPipeline.from_pretrained(<br>    checkpoint_path,            <br>    use_safetensors=<span class="hljs-literal">True</span>,       <br>    torch_dtype=torch.float16,  <br>    variant=<span class="hljs-string">"fp16"</span>              <br>)<br></code></pre></td></tr></table></figure>

<p>检查点（例如 <a target="_blank" rel="noopener" href="https://huggingface.co/runwayml/stable-diffusion-v1-5">runwayml/stable-diffusion-v1-5</a> 可以用于多个任务，例如文本到图像生成或图像到图像生成。为了区分特定的任务，必须直接使用其相应任务的 Pipeline 类来加载它：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> <br>StableDiffusionXLInpaintPipeline<br>StableDiffusionXLImg2ImgPipeline<br>StableDiffusionXLControlNetImg2ImgPipeline<br>...<br></code></pre></td></tr></table></figure>



<h3 id="替换Pipeline中的组件"><a href="#替换Pipeline中的组件" class="headerlink" title="替换Pipeline中的组件"></a>替换Pipeline中的组件</h3><p>可以使用其他兼容的组件自定义任何管道的默认组件。这种定制很重要，因为：</p>
<ul>
<li>更改采样器对于探索生成<strong>速度</strong>和质量之间的权衡非常重要。</li>
<li>模型的不同组件通常是<strong>独立训练</strong>的，您可以用性能更好的组件替换原有组件。</li>
<li>在<strong>微调</strong>过程中，通常只训练一些组件（例如 UNet 或文本编码器）。</li>
</ul>
<p>以 SD1.5 为例，要找出哪些采样器兼容自定义，可以使用 <code>compatibles</code> 方法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> DiffusionPipeline<br><span class="hljs-keyword">import</span> torch<br><br>checkpoint_path = <span class="hljs-string">r'D:\MyCode\Torch_Deom\sd-v1.5\sd-v1.5'</span><br>pipeline = DiffusionPipeline.from_pretrained(<br>    checkpoint_path,<br>    torch_dtype=torch.float16,<br>    variant=<span class="hljs-string">'fp16'</span><br>)<br><span class="hljs-comment"># 查看能够兼容当前pipeline的采样器</span><br><span class="hljs-built_in">print</span>(pipeline.scheduler.compatibles)<br></code></pre></td></tr></table></figure>

<p>输出可供替换的采样器类组成的列表：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs shell">[<br>&lt;class 'diffusers.utils.dummy_torch_and_torchsde_objects.DPMSolverSDEScheduler'&gt;, <br>&lt;class 'diffusers.schedulers.scheduling_euler_ancestral_discrete.EulerAncestralDiscreteScheduler'&gt;, <br>&lt;class 'diffusers.schedulers.scheduling_deis_multistep.DEISMultistepScheduler'&gt;, <br>&lt;class 'diffusers.schedulers.scheduling_pndm.PNDMScheduler'&gt;, <br>&lt;class 'diffusers.schedulers.scheduling_ddpm.DDPMScheduler'&gt;, <br>&lt;class 'diffusers.schedulers.scheduling_euler_discrete.EulerDiscreteScheduler'&gt;, <br>&lt;class 'diffusers.schedulers.scheduling_edm_euler.EDMEulerScheduler'&gt;, <br>&lt;class 'diffusers.schedulers.scheduling_unipc_multistep.UniPCMultistepScheduler'&gt;, <br>&lt;class 'diffusers.schedulers.scheduling_heun_discrete.HeunDiscreteScheduler'&gt;, <br>&lt;class 'diffusers.schedulers.scheduling_dpmsolver_singlestep.DPMSolverSinglestepScheduler'&gt;, <br>&lt;class 'diffusers.schedulers.scheduling_ddim.DDIMScheduler'&gt;, <br>&lt;class 'diffusers.schedulers.scheduling_k_dpm_2_ancestral_discrete.KDPM2AncestralDiscreteScheduler'&gt;, <br>&lt;class 'diffusers.schedulers.scheduling_k_dpm_2_discrete.KDPM2DiscreteScheduler'&gt;, <br>&lt;class 'diffusers.schedulers.scheduling_lms_discrete.LMSDiscreteScheduler'&gt;, <br>&lt;class 'diffusers.schedulers.scheduling_dpmsolver_multistep.DPMSolverMultistepScheduler'&gt;<br>]<br></code></pre></td></tr></table></figure>

<p>使用 <code>SchedulerMixin.from_pretrained()</code> 方法将默认的 <code>PNDMScheduler</code> 替换为性能更高的采样器 <code>EulerDiscreteScheduler</code>。</p>
<p>需要 <code>subfolder="scheduler"</code> 参数才能从 Pipeline 检查点存储的正确子文件夹加载采样器配置文件。</p>
<p>然后，就可以将新的 <code>EulerDiscreteScheduler</code> 实例传递给 <code>DiffusionPipeline</code> 中的采样器参数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> DiffusionPipeline<br><span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> EulerDiscreteScheduler<br><span class="hljs-keyword">import</span> torch<br><br>checkpoint_path = <span class="hljs-string">r'D:\MyCode\Torch_Deom\sd-v1.5\sd-v1.5'</span><br><br>scheduler = EulerDiscreteScheduler.from_pretrained(checkpoint_path, subfolder=<span class="hljs-string">"scheduler"</span>)<br>pipeline = DiffusionPipeline.from_pretrained(<br>    checkpoint_path,<br>    scheduler=scheduler,<br>    torch_dtype=torch.float16,<br>    variant=<span class="hljs-string">'fp16'</span><br>)<br><span class="hljs-built_in">print</span>(pipeline.scheduler)<br></code></pre></td></tr></table></figure>

<p>如下所示，当前采样器被修改为 <code>EulerDiscreteScheduler</code></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs shell">EulerDiscreteScheduler {<br>  "_class_name": "EulerDiscreteScheduler",<br>  "_diffusers_version": "0.27.2",<br>  "beta_end": 0.012,<br>  "beta_schedule": "scaled_linear",<br>  "beta_start": 0.00085,<br>  "clip_sample": false,<br>  "interpolation_type": "linear",<br>  "num_train_timesteps": 1000,<br>  "prediction_type": "epsilon",<br>  "rescale_betas_zero_snr": false,<br>  "set_alpha_to_one": false,<br>  "sigma_max": null,<br>  "sigma_min": null,<br>  "skip_prk_steps": true,<br>  "steps_offset": 1,<br>  "timestep_spacing": "linspace",<br>  "timestep_type": "discrete",<br>  "trained_betas": null,<br>  "use_karras_sigmas": false<br>}<br></code></pre></td></tr></table></figure>



<h3 id="Safety-checker"><a href="#Safety-checker" class="headerlink" title="Safety checker"></a>Safety checker</h3><p>像 Stable Diffusion 这样的扩散模型可以生成<strong>有害内容</strong>，这就是为什么Diffusers 有一个安全检查器（Safety checker）来根据已知的 NSFW（Not Safe For Work） 内容检查生成的输出。</p>
<p>如果想要禁用安全检查器，请将 None 传递给 safety_checker 参数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">pipeline = DiffusionPipeline.from_pretrained(<br>    checkpoint_path,<br>    scheduler=scheduler,<br>    safety_checker = <span class="hljs-literal">None</span>,<br>    torch_dtype=torch.float16,<br>    variant=<span class="hljs-string">'fp16'</span><br>)<br></code></pre></td></tr></table></figure>

<p>加载组件的数量变为6个：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">Loading pipeline components...: 100%|██████████| 6/6 [00:00&lt;00:00, 15.77it/s]<br></code></pre></td></tr></table></figure>



<h3 id="跨Pipeline重用组件"><a href="#跨Pipeline重用组件" class="headerlink" title="跨Pipeline重用组件"></a>跨Pipeline重用组件</h3><p>您还可以在多个 Pipeline 中重复使用相同的组件，以避免将权重加载到 RAM 中两次。使用 <code>components</code> 方法保存组件：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> StableDiffusionPipeline, StableDiffusionImg2ImgPipeline<br><span class="hljs-keyword">import</span> torch<br><br>checkpoint_path = <span class="hljs-string">r'D:\MyCode\Torch_Deom\sd-v1.5\sd-v1.5'</span><br>stable_diffusion_txt2img = StableDiffusionPipeline.from_pretrained(<br>    checkpoint_path,<br>    safety_checker=<span class="hljs-literal">None</span>,<br>    use_safetensors=<span class="hljs-literal">True</span>,<br>    torch_dtype=torch.float16,<br>    variant=<span class="hljs-string">'fp16'</span><br>)<br><br>components = stable_diffusion_txt2img.components<br></code></pre></td></tr></table></figure>

<p>然后，您可以将组件通过 <code>components</code> 变量传递到另一个 Pipeline ，而无需将权重重新加载到 RAM 中：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">stable_diffusion_img2img = StableDiffusionImg2ImgPipeline(**components)<br></code></pre></td></tr></table></figure>

<p>如果希望更灵活地重用或禁用哪些组件，还可以将组件<strong>单独</strong>传递到新的Pipeline。</p>
<p>例如，要在图像到图像 Pipeline 中重用文本到图像管道中的相同组件（安全检查器和特征提取器除外）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> StableDiffusionPipeline, StableDiffusionImg2ImgPipeline<br><span class="hljs-keyword">import</span> torch<br><br>checkpoint_path = <span class="hljs-string">r'D:\MyCode\Torch_Deom\sd-v1.5\sd-v1.5'</span><br>stable_diffusion_txt2img = StableDiffusionPipeline.from_pretrained(<br>    checkpoint_path,<br>    use_safetensors=<span class="hljs-literal">True</span>,<br>    torch_dtype=torch.float16,<br>    variant=<span class="hljs-string">'fp16'</span><br>)<br>stable_diffusion_img2img = StableDiffusionImg2ImgPipeline(<br>    vae=stable_diffusion_txt2img.vae,<br>    text_encoder=stable_diffusion_txt2img.text_encoder,<br>    tokenizer=stable_diffusion_txt2img.tokenizer,<br>    unet=stable_diffusion_txt2img.unet,<br>    scheduler=stable_diffusion_txt2img.scheduler,<br>    safety_checker=<span class="hljs-literal">None</span>,<br>    feature_extractor=<span class="hljs-literal">None</span>,<br>    requires_safety_checker=<span class="hljs-literal">False</span>,<br>)<br></code></pre></td></tr></table></figure>



<h3 id="检查点变体-Checkpoint-variants"><a href="#检查点变体-Checkpoint-variants" class="headerlink" title="检查点变体 Checkpoint variants"></a>检查点变体 Checkpoint variants</h3><p>检查点变体通常是权重为：</p>
<ul>
<li>存储在不同的浮点类型中，以实现较低的精度和较低的存储，例如torch.float16，因为它只需要一半的带宽和存储来下载。如果您正在继续训练或使用 CPU，则无法使用此变体。 </li>
<li>非指数平均 (EMA) 权重，这种权重不适用于推理，用于继续微调模型。</li>
</ul>
<p>当检查点具有相同的模型结构，但它们在不同的数据集和不同的训练设置上进行训练时，它们应该存储在单独的存储库中而不是变体中</p>
<p>变体与原始检查点完全相同。它们具有完全相同的序列化格式（如 Safetensors）、模型结构和具有相同形状张量的权重。</p>
<table>
<thead>
<tr>
<th><strong>checkpoint</strong>类型</th>
<th>权重文件名</th>
<th>加载权重文件的参数</th>
</tr>
</thead>
<tbody><tr>
<td>original</td>
<td><code>diffusion_pytorch_model.bin</code></td>
<td></td>
</tr>
<tr>
<td>floating point（fp16）</td>
<td><code>diffusion_pytorch_model.fp16.bin</code></td>
<td><code>variant='fp16', torch_dtype=torch.float16</code></td>
</tr>
<tr>
<td>non-EMA</td>
<td><code>diffusion_pytorch_model.non_ema.bin</code></td>
<td><code>variant='non_ema'</code></td>
</tr>
</tbody></table>
<h4 id="加载变体"><a href="#加载变体" class="headerlink" title="加载变体"></a>加载变体</h4><p>对于加载检查点变体，有两个重要的参数：</p>
<ul>
<li><code>torch_dtype</code>： 定义加载检查点的浮点精度。<ul>
<li>如果想通过加载 fp16 变体来节省带宽，则应指定 <code>torch_dtype=torch.float16</code> 将权重转换为 fp16。否则，fp16 权重将转换为默认的 fp32 精度。</li>
<li>还可以在不定义该参数的情况下加载原始检查点，并使用 torch_dtype=torch.float16 将其转换为 fp16。在这种情况下，首先下载默认的 fp32 权重，然后在加载后将其转换为 fp16。</li>
</ul>
</li>
<li><code>variant</code>：定义应从存储库加载哪些文件。<ul>
<li>如果想加载 <code>non_ema</code> 变体，则应指定<code>variant="non_ema</code> 来下载 non_ema 文件。</li>
<li>如果想加载 <code>fp16</code> 变体，则应指定<code>variant="fp16</code> 来下载半精度文件。</li>
</ul>
</li>
</ul>
<h4 id="保存变体"><a href="#保存变体" class="headerlink" title="保存变体"></a>保存变体</h4><p>要将检查点保存为不同浮点类型或作为非 EMA 变体，请使用 <code>DiffusionPipeline.save_pretrained()</code> 方法并指定 <code>variant</code> 参数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">save_path = <span class="hljs-string">'./save_variant'</span><br><span class="hljs-comment"># save as fp16 variant</span><br>stable_diffusion.save_pretrained(save_path, variant=<span class="hljs-string">"fp16"</span>)<br><span class="hljs-comment"># save as non-ema variant</span><br>stable_diffusion.save_pretrained(save_path, variant=<span class="hljs-string">"non_ema"</span>)<br></code></pre></td></tr></table></figure>

<p>保存的文件结构与原始检查点的结构一致</p>
<h3 id="Models"><a href="#Models" class="headerlink" title="Models"></a>Models</h3><p>模型从 <code>ModelMixin.from_pretrained()</code> 方法加载。</p>
<p>可以使用 <code>subfolder</code> 参数从子文件夹加载模型。例如，<code>stable-diffusion-v1-5</code> 的U-Net</p>
<p>模型权重存储在 <code>unet</code> 子文件夹中：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> UNet2DConditionModel<br><span class="hljs-keyword">import</span> torch<br><br>checkpoint_path = <span class="hljs-string">r'D:\MyCode\Torch_Deom\sd-v1.5\sd-v1.5'</span><br>model = UNet2DConditionModel.from_pretrained(<br>    checkpoint_path,<br>    subfolder=<span class="hljs-string">'unet'</span>,<br>    use_safetensors=<span class="hljs-literal">True</span>,<br>    torch_dtype=torch.float16,<br>    variant=<span class="hljs-string">'fp16'</span><br>)<br></code></pre></td></tr></table></figure>

<p>或者直接从存储库的目录加载：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> UNet2DModel<br><br>repo_id = <span class="hljs-string">"google/ddpm-cifar10-32"</span><br>model = UNet2DModel.from_pretrained(repo_id, use_safetensors=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure>

<p>还可以通过在 <code>ModelMixin.from_pretrained()</code> 和 <code>ModelMixin.save_pretrained()</code> 中指定变量参数来<strong>加载</strong>和<strong>保存</strong>变体模型：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> UNet2DConditionModel<br><br>model = UNet2DConditionModel.from_pretrained(<br>    <span class="hljs-string">"runwayml/stable-diffusion-v1-5"</span>, <br>    subfolder=<span class="hljs-string">"unet"</span>, <br>    variant=<span class="hljs-string">"non_ema"</span>, <br>    use_safetensors=<span class="hljs-literal">True</span><br>)<br>model.save_pretrained(<br>    <span class="hljs-string">"./local-unet"</span>, <br>    variant=<span class="hljs-string">"non_ema"</span><br>)<br></code></pre></td></tr></table></figure>



<h3 id="采样器"><a href="#采样器" class="headerlink" title="采样器"></a>采样器</h3><p>采样器是从 <code>SchedulerMixin.from_pretrained()</code> 方法加载的，与模型不同，调度程序没有参数；它们由配置文件定义。</p>
<p>加载采样器不会消耗任何大量的内存，并且相同的配置文件可以用于各种不同的采样器。</p>
<p>例如，以下调度程序与 StableDiffusionPipeline 兼容，这意味着您可以在这些类中的任何一个中加载相同的调度程序配置文件：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> StableDiffusionPipeline<br><span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> (<br>    DDPMScheduler,<br>    DDIMScheduler,<br>    PNDMScheduler,<br>    LMSDiscreteScheduler,<br>    EulerAncestralDiscreteScheduler,<br>    EulerDiscreteScheduler,<br>    DPMSolverMultistepScheduler,<br>)<br><span class="hljs-keyword">import</span> torch<br><br>checkpoint_path = <span class="hljs-string">r'D:\MyCode\Torch_Deom\sd-v1.5\sd-v1.5'</span><br><br>ddpm = DDPMScheduler.from_pretrained(checkpoint_path, subfolder=<span class="hljs-string">"scheduler"</span>)<br>ddim = DDIMScheduler.from_pretrained(checkpoint_path, subfolder=<span class="hljs-string">"scheduler"</span>)<br>pndm = PNDMScheduler.from_pretrained(checkpoint_path, subfolder=<span class="hljs-string">"scheduler"</span>)<br>lms = LMSDiscreteScheduler.from_pretrained(checkpoint_path, subfolder=<span class="hljs-string">"scheduler"</span>)<br>euler_anc = EulerAncestralDiscreteScheduler.from_pretrained(checkpoint_path, subfolder=<span class="hljs-string">"scheduler"</span>)<br>euler = EulerDiscreteScheduler.from_pretrained(checkpoint_path, subfolder=<span class="hljs-string">"scheduler"</span>)<br>dpm = DPMSolverMultistepScheduler.from_pretrained(checkpoint_path, subfolder=<span class="hljs-string">"scheduler"</span>)<br><br><span class="hljs-comment"># replace `dpm` with any of `ddpm`, `ddim`, `pndm`, `lms`, `euler_anc`, `euler`</span><br>pipeline = StableDiffusionPipeline.from_pretrained(<br>    checkpoint_path,<br>    scheduler=dpm,<br>    use_safetensors=<span class="hljs-literal">True</span>,<br>    torch_dtype=torch.float16,<br>    variant=<span class="hljs-string">'fp16'</span><br>)<br></code></pre></td></tr></table></figure>



<h3 id="DiffusionPipeline详解"><a href="#DiffusionPipeline详解" class="headerlink" title="DiffusionPipeline详解"></a>DiffusionPipeline详解</h3><p><code>DiffusionPipeline.from_pretrained()</code> 负责两件事：</p>
<ul>
<li>下载推理所需的最新版本的文件夹结构并将其缓存。如果本地缓存中有最新的文件夹结构，则重用缓存且不会重复下载文件。</li>
<li>将缓存的权重加载到正确的 Pipeline 类中（从 model_index.json 文件中检索）并返回实例。</li>
</ul>
<p> Pipeline 的底层文件夹结构与其类实例直接对应。例如，StableDiffusionPipeline 对应于 <a target="_blank" rel="noopener" href="https://huggingface.co/runwayml/stable-diffusion-v1-5">runwayml/stable-diffusion-v1-5</a> 中的文件夹结构。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> DiffusionPipeline<br><span class="hljs-keyword">import</span> torch<br><br>checkpoint_path = <span class="hljs-string">r'D:\MyCode\Torch_Deom\sd-v1.5\sd-v1.5'</span><br><br>pipeline = DiffusionPipeline.from_pretrained(<br>    checkpoint_path,<br>    torch_dtype=torch.float16,<br>    variant=<span class="hljs-string">'fp16'</span><br>)<br><span class="hljs-built_in">print</span>(pipeline)<br></code></pre></td></tr></table></figure>



<p>你会看到 <code>pipeline</code> 是 <code>StableDiffusionPipeline</code> 的一个实例，它由七个组件组成：</p>
<table>
<thead>
<tr>
<th>组件</th>
<th>类</th>
<th>库</th>
</tr>
</thead>
<tbody><tr>
<td><code>feature_extractor</code></td>
<td><code>CLIPImageProcessor</code></td>
<td><code>Transformers</code></td>
</tr>
<tr>
<td><code>safety_checker</code></td>
<td><code>CLIPImageProcessor</code></td>
<td><code>diffusers</code></td>
</tr>
<tr>
<td><code>scheduler</code></td>
<td><code>PNDMScheduler</code></td>
<td><code>diffusers</code></td>
</tr>
<tr>
<td><code>text_encoder</code></td>
<td><code>CLIPTextModel</code></td>
<td><code>Transformers</code></td>
</tr>
<tr>
<td><code>tokenizer</code></td>
<td><code>CLIPTokenizer</code></td>
<td><code>Transformers</code></td>
</tr>
<tr>
<td><code>unet</code></td>
<td><code>UNet2DConditionModel</code></td>
<td><code>diffusers</code></td>
</tr>
<tr>
<td><code>vae</code></td>
<td><code>AutoencoderKL</code></td>
<td><code>diffusers</code></td>
</tr>
</tbody></table>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><code class="hljs shell">StableDiffusionPipeline {<br>  "_class_name": "StableDiffusionPipeline",<br>  "_diffusers_version": "0.27.2",<br>  "_name_or_path": "D:\\MyCode\\Torch_Deom\\sd-v1.5\\sd-v1.5",<br>  "feature_extractor": [<br>    "transformers",<br>    "CLIPImageProcessor"<br>  ],<br>  "image_encoder": [<br>    null,<br>    null<br>  ],<br>  "requires_safety_checker": true,<br>  "safety_checker": [<br>    "stable_diffusion",<br>    "StableDiffusionSafetyChecker"<br>  ],<br>  "scheduler": [<br>    "diffusers",<br>    "PNDMScheduler"<br>  ],<br>  "text_encoder": [<br>    "transformers",<br>    "CLIPTextModel"<br>  ],<br>  "tokenizer": [<br>    "transformers",<br>    "CLIPTokenizer"<br>  ],<br>  "unet": [<br>    "diffusers",<br>    "UNet2DConditionModel"<br>  ],<br>  "vae": [<br>    "diffusers",<br>    "AutoencoderKL"<br>  ]<br>}<br></code></pre></td></tr></table></figure>

<p>将实例的组件与检查点文件夹结构进行比较，您将看到存储库中的每个组件都有一个单独的文件夹</p>
<p>可以将管道的每个组件作为属性访问以查看其配置：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs">pipeline.tokenizer<br></code></pre></td></tr></table></figure>

<p>每个管道都需要一个 <code>model_index.json</code> 文件来告诉 <code>DiffusionPipeline</code>：</p>
<ul>
<li>从 <code>_class_name</code> 加载哪个管道类</li>
<li>使用哪个版本的Diffusers 在 <code>_diffusers_version</code> 中创建模型</li>
<li>子文件夹中存储了哪个库中的哪些组件</li>
</ul>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">{</span><br>  <span class="hljs-attr">"_class_name"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"StableDiffusionPipeline"</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">"_diffusers_version"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"0.6.0"</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">"feature_extractor"</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>    <span class="hljs-string">"transformers"</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-string">"CLIPImageProcessor"</span><br>  <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">"safety_checker"</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>    <span class="hljs-string">"stable_diffusion"</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-string">"StableDiffusionSafetyChecker"</span><br>  <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">"scheduler"</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>    <span class="hljs-string">"diffusers"</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-string">"PNDMScheduler"</span><br>  <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">"text_encoder"</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>    <span class="hljs-string">"transformers"</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-string">"CLIPTextModel"</span><br>  <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">"tokenizer"</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>    <span class="hljs-string">"transformers"</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-string">"CLIPTokenizer"</span><br>  <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">"unet"</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>    <span class="hljs-string">"diffusers"</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-string">"UNet2DConditionModel"</span><br>  <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">"vae"</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>    <span class="hljs-string">"diffusers"</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-string">"AutoencoderKL"</span><br>  <span class="hljs-punctuation">]</span><br><span class="hljs-punctuation">}</span><br></code></pre></td></tr></table></figure>



<hr>
<h2 id="Load-and-compare-different-schedulers"><a href="#Load-and-compare-different-schedulers" class="headerlink" title="Load and compare different schedulers"></a>Load and compare different schedulers</h2><p>采样器定义整个去噪过程：</p>
<ul>
<li>去噪步数</li>
<li>随机性还是确定性</li>
<li>使用什么算法</li>
</ul>
<p>通常需要在去噪速度和去噪质量之间做出权衡。定量测量哪个采样器最适合给定的扩散Pipeline是极其困难的，因此通常建议简单地尝试哪个最适合。</p>
<h3 id="访问采样器"><a href="#访问采样器" class="headerlink" title="访问采样器"></a>访问采样器</h3><p>以<code>stable diffusion v1.5</code> 为例，加载检查点并访问调度器</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> DiffusionPipeline<br><span class="hljs-keyword">import</span> torch<br><br>checkpoint_path = <span class="hljs-string">r'D:\MyCode\Torch_Deom\sd-v1.5\sd-v1.5'</span><br><br>pipeline = DiffusionPipeline.from_pretrained(<br>    checkpoint_path,<br>    torch_dtype=torch.float16,<br>    variant=<span class="hljs-string">'fp16'</span><br>)<br><span class="hljs-built_in">print</span>(pipeline.scheduler)<br></code></pre></td></tr></table></figure>

<p>输出为：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs shell">PNDMScheduler {<br>  "_class_name": "PNDMScheduler",<br>  "_diffusers_version": "0.27.2",<br>  "beta_end": 0.012,<br>  "beta_schedule": "scaled_linear",<br>  "beta_start": 0.00085,<br>  "clip_sample": false,<br>  "num_train_timesteps": 1000,<br>  "prediction_type": "epsilon",<br>  "set_alpha_to_one": false,<br>  "skip_prk_steps": true,<br>  "steps_offset": 1,<br>  "timestep_spacing": "leading",<br>  "trained_betas": null<br>}<br></code></pre></td></tr></table></figure>

<p>可以看到采样器的类为 <code>PNDMScheduler</code>。现在与其他采样器进行比较。首先，我们定义一个 prompt，我们将使用它测试所有不同的采样器：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">prompt = <span class="hljs-string">"A photograph of an astronaut riding a horse on Mars, high resolution, high definition."</span><br></code></pre></td></tr></table></figure>

<p>接下来，我们从随机种子 <code>4</code> 中创建一个生成器，确保可以生成类似的图像：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python">generator = torch.Generator(device=<span class="hljs-string">"cuda"</span>).manual_seed(<span class="hljs-number">4</span>)<br>image = pipeline(<br>    prompt,<br>    generator=generator<br>).images[<span class="hljs-number">0</span>]<br><br>save_name = <span class="hljs-string">'PNDMS-50.png'</span><br>save_path = <span class="hljs-string">'./results/schedulers'</span><br><span class="hljs-keyword">if</span>(<span class="hljs-keyword">not</span> os.path.exists(save_path)):<br>    os.makedirs(save_path)<br><br>image.save(os.path.join(save_path, save_name))<br></code></pre></td></tr></table></figure>

<p class='item-img' data-src='https://github.com/TO-Hitori/HBIL/blob/main/diffuser-doc/scheduler/PNDMS-50.png?raw=true'><img src="https://github.com/TO-Hitori/HBIL/blob/main/diffuser-doc/scheduler/PNDMS-50.png?raw=true" alt="PNDMS-50.png"></p>
<h3 id="更改采样器"><a href="#更改采样器" class="headerlink" title="更改采样器"></a>更改采样器</h3><p>通过 <code>compatibles</code> 属性查看兼容的其他采样器：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">print</span>(pipeline.scheduler.compatibles)<br></code></pre></td></tr></table></figure>

<p>输出为：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs shell">[<br>&lt;class 'diffusers.schedulers.scheduling_k_dpm_2_discrete.KDPM2DiscreteScheduler'&gt;, <br>&lt;class 'diffusers.schedulers.scheduling_pndm.PNDMScheduler'&gt;, <br>&lt;class 'diffusers.schedulers.scheduling_deis_multistep.DEISMultistepScheduler'&gt;, <br>&lt;class 'diffusers.schedulers.scheduling_dpmsolver_multistep.DPMSolverMultistepScheduler'&gt;, <br>&lt;class 'diffusers.schedulers.scheduling_unipc_multistep.UniPCMultistepScheduler'&gt;, <br>&lt;class 'diffusers.schedulers.scheduling_lms_discrete.LMSDiscreteScheduler'&gt;, <br>&lt;class 'diffusers.schedulers.scheduling_edm_euler.EDMEulerScheduler'&gt;, <br>&lt;class 'diffusers.schedulers.scheduling_k_dpm_2_ancestral_discrete.KDPM2AncestralDiscreteScheduler'&gt;, <br>&lt;class 'diffusers.schedulers.scheduling_ddpm.DDPMScheduler'&gt;, <br>&lt;class 'diffusers.schedulers.scheduling_euler_discrete.EulerDiscreteScheduler'&gt;, <br>&lt;class 'diffusers.schedulers.scheduling_dpmsolver_singlestep.DPMSolverSinglestepScheduler'&gt;, <br>&lt;class 'diffusers.utils.dummy_torch_and_torchsde_objects.DPMSolverSDEScheduler'&gt;, <br>&lt;class 'diffusers.schedulers.scheduling_heun_discrete.HeunDiscreteScheduler'&gt;, <br>&lt;class 'diffusers.schedulers.scheduling_ddim.DDIMScheduler'&gt;, <br>&lt;class 'diffusers.schedulers.scheduling_euler_ancestral_discrete.EulerAncestralDiscreteScheduler'&gt;<br>]<br></code></pre></td></tr></table></figure>



<p>要更改管道的调度程序，可以结合使用方便的 <code>config</code> 属性和 <code>from_config()</code> 函数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">print</span>(pipeline.scheduler.config)<br></code></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs shell">FrozenDict([<br>    ('num_train_timesteps', 1000), <br>    ('beta_start', 0.00085), <br>    ('beta_end', 0.012), <br>    ('beta_schedule', 'scaled_linear'), <br>    ('trained_betas', None), <br>    ('skip_prk_steps', True), <br>    ('set_alpha_to_one', False), <br>    ('prediction_type', 'epsilon'), <br>    ('timestep_spacing', 'leading'), <br>    ('steps_offset', 1), <br>    ('_use_default_values', ['prediction_type', 'timestep_spacing']), <br>    ('_class_name', 'PNDMScheduler'), <br>    ('_diffusers_version', '0.27.2'), <br>    ('clip_sample', False)<br>])<br></code></pre></td></tr></table></figure>

<p>然后，可以使用此配置实例化一个与 Pipeline 兼容的不同的采样器。在这里，我们将调度程序更改为 <code>DDIMScheduler</code>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> DDIMScheduler<br>pipeline.scheduler = DDIMScheduler.from_config(pipeline.scheduler.config)<br></code></pre></td></tr></table></figure>

<p class='item-img' data-src='https://github.com/TO-Hitori/HBIL/blob/main/diffuser-doc/scheduler/DDIM-50.png?raw=true'><img src="https://github.com/TO-Hitori/HBIL/blob/main/diffuser-doc/scheduler/DDIM-50.png?raw=true" alt="DDIM-50.png"></p>
<h3 id="比较采样器"><a href="#比较采样器" class="headerlink" title="比较采样器"></a>比较采样器</h3><p>现在已经发布了一些更好的采样器，它们可以用更少的步骤运行；让我们在这里对它们进行比较：</p>
<ul>
<li><code>LMSDiscreteScheduler</code>通常会带来更好的结果</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> LMSDiscreteScheduler<br>pipeline.scheduler = LMSDiscreteScheduler.from_config(pipeline.scheduler.config)<br></code></pre></td></tr></table></figure>

<p><code>LMSDiscreteScheduler</code> 50步：</p>
<p class='item-img' data-src='https://github.com/TO-Hitori/HBIL/blob/main/diffuser-doc/scheduler/LMSDiscrete-50.png?raw=true'><img src="https://github.com/TO-Hitori/HBIL/blob/main/diffuser-doc/scheduler/LMSDiscrete-50.png?raw=true" alt="LMSDiscrete-50.png"></p>
<ul>
<li><code>EulerDiscreteScheduler</code> 和 <code>EulerAncestralDiscreteScheduler</code> 仅需 30 个步骤即可生成高质量结果。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> EulerDiscreteScheduler<br>pipeline.scheduler = EulerDiscreteScheduler.from_config(pipeline.scheduler.config)<br></code></pre></td></tr></table></figure>

<pre><code>1. `EulerDiscreteScheduler` 50步：
</code></pre>
<p class='item-img' data-src='https://github.com/TO-Hitori/HBIL/blob/main/diffuser-doc/scheduler/EulerDiscrete-50.png?raw=true'><img src="https://github.com/TO-Hitori/HBIL/blob/main/diffuser-doc/scheduler/EulerDiscrete-50.png?raw=true" alt="EulerDiscrete-50.png"></p>
<ol start="2">
<li><code>EulerDiscreteScheduler</code> 30步：</li>
</ol>
<p class='item-img' data-src='https://github.com/TO-Hitori/HBIL/blob/main/diffuser-doc/scheduler/EulerDiscrete-30.png?raw=true'><img src="https://github.com/TO-Hitori/HBIL/blob/main/diffuser-doc/scheduler/EulerDiscrete-30.png?raw=true" alt="EulerDiscrete-30.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> EulerAncestralDiscreteScheduler<br>pipeline.scheduler = EulerAncestralDiscreteScheduler.from_config(pipeline.scheduler.config)<br></code></pre></td></tr></table></figure>

<pre><code> 1. `EulerAncestralDiscreteScheduler` 50步：
</code></pre>
<p class='item-img' data-src='https://github.com/TO-Hitori/HBIL/blob/main/diffuser-doc/scheduler/EulerAncestralDiscrete-50.png?raw=true'><img src="https://github.com/TO-Hitori/HBIL/blob/main/diffuser-doc/scheduler/EulerAncestralDiscrete-50.png?raw=true" alt="EulerAncestralDiscrete-50.png"></p>
<ol start="2">
<li><code>EulerAncestralDiscreteScheduler</code> 30步：</li>
</ol>
<p class='item-img' data-src='https://github.com/TO-Hitori/HBIL/blob/main/diffuser-doc/scheduler/EulerAncestralDiscrete-30.png?raw=true'><img src="https://github.com/TO-Hitori/HBIL/blob/main/diffuser-doc/scheduler/EulerAncestralDiscrete-30.png?raw=true" alt="EulerAncestralDiscrete-30.png"></p>
<ul>
<li><code>DPMSolverMultistepScheduler</code> 给出了合理的速度和质量的权衡，并且可以用最少 20 个步骤运行。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> DPMSolverMultistepScheduler<br>pipeline.scheduler = DPMSolverMultistepScheduler.from_config(pipeline.scheduler.config)<br></code></pre></td></tr></table></figure>

<ol>
<li><code>DPMSolverMultistepScheduler</code> 50步：</li>
</ol>
<p class='item-img' data-src='https://github.com/TO-Hitori/HBIL/blob/main/diffuser-doc/scheduler/DPMSolverMultistep-50.png?raw=true'><img src="https://github.com/TO-Hitori/HBIL/blob/main/diffuser-doc/scheduler/DPMSolverMultistep-50.png?raw=true" alt="DPMSolverMultistep-50.png"></p>
<ol start="2">
<li><code>DPMSolverMultistepScheduler</code> 20步：</li>
</ol>
<p class='item-img' data-src='https://github.com/TO-Hitori/HBIL/blob/main/diffuser-doc/scheduler/DPMSolverMultistep-20.png?raw=true'><img src="https://github.com/TO-Hitori/HBIL/blob/main/diffuser-doc/scheduler/DPMSolverMultistep-20.png?raw=true" alt="DPMSolverMultistep-20.png"></p>
<p>正如您所看到的，大多数图像看起来都非常相似，质量也可以说非常接近。选择哪种通常取决于具体的使用情况。最好的方法是运行多个不同的采样器来比较结果。</p>
<h2 id="Load-community-pipelines-and-components"><a href="#Load-community-pipelines-and-components" class="headerlink" title="Load community pipelines and components"></a>Load community pipelines and components</h2><p>社区pipeline是指不同于其论文中指定的原始实现的任何 <code>DiffusionPipeline</code> 类（例如，<code>StableDiffusionControlNetPipeline</code> 与 ControlNet 论文中的文本到图像生成相对应）。它们提供了额外的功能或扩展了pipeline的原始实现。</p>
<blockquote>
<p>社区pipeline示例：<a target="_blank" rel="noopener" href="https://github.com/huggingface/diffusers/tree/main/examples/community">diffusers/examples/community at main · huggingface/diffusers (github.com)</a></p>
</blockquote>
<p>要在 Hub 上加载任何社区管道，请在 <code>custom_pipeline</code> 参数中输入社区pipeline的资源库 id，以及要加载管道权重和组件的模型资源库。例如，下面的示例从<code>hf-internal-testing/diffusers-dummy-pipeline</code>以及<code>Google/DDPM-CIFAR10-32</code>的管道权重和组件加载了一个 pipeline：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> DiffusionPipeline<br><br>pipeline = DiffusionPipeline.from_pretrained(<br>    <span class="hljs-string">"google/ddpm-cifar10-32"</span>, <br>    custom_pipeline=<span class="hljs-string">"hf-internal-testing/diffusers-dummy-pipeline"</span>, <br>    use_safetensors=<span class="hljs-literal">True</span><br>)<br></code></pre></td></tr></table></figure>



<p>加载官方社区pipeline可以混合加载来自官方资源库的权重，并直接传递管道组件。下面的示例加载了社区pipeline <a target="_blank" rel="noopener" href="https://github.com/huggingface/diffusers/tree/main/examples/community#clip-guided-stable-diffusion">CLIP Guided Stable Diffusion</a> ，你可以直接将 CLIP 模型组件传递给它：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> DiffusionPipeline<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> CLIPImageProcessor, CLIPModel<br><br>clip_model_id = <span class="hljs-string">"laion/CLIP-ViT-B-32-laion2B-s34B-b79K"</span><br><br>feature_extractor = CLIPImageProcessor.from_pretrained(clip_model_id)<br>clip_model = CLIPModel.from_pretrained(clip_model_id)<br><br>pipeline = DiffusionPipeline.from_pretrained(<br>    <span class="hljs-string">"runwayml/stable-diffusion-v1-5"</span>,<br>    custom_pipeline=<span class="hljs-string">"clip_guided_stable_diffusion"</span>,<br>    clip_model=clip_model,<br>    feature_extractor=feature_extractor,<br>    use_safetensors=<span class="hljs-literal">True</span>,<br>)<br></code></pre></td></tr></table></figure>



<h3 id="从本地文件加载"><a href="#从本地文件加载" class="headerlink" title="从本地文件加载"></a>从本地文件加载</h3><p>如果您通过文件路径，也可以从本地文件加载社区 pipeline。文件路径必须包含一个<code>pipeline.py</code>文件，该文件包含pipeline类。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">pipeline = DiffusionPipeline.from_pretrained(<br>    <span class="hljs-string">"runwayml/stable-diffusion-v1-5"</span>,<br>    custom_pipeline=<span class="hljs-string">"./path/to/pipeline_directory/"</span>,<br>    clip_model=clip_model,<br>    feature_extractor=feature_extractor,<br>    use_safetensors=<span class="hljs-literal">True</span>,<br>)<br></code></pre></td></tr></table></figure>

<h3 id="从特定版本加载"><a href="#从特定版本加载" class="headerlink" title="从特定版本加载"></a>从特定版本加载</h3><p>默认情况下，社区 pipeline 是从最新稳定版本的 Diffusers 中加载的。要从另一个版本加载社区管道，请设置 <code>custom_revision</code> 参数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python">pipeline = DiffusionPipeline.from_pretrained(<br>    <span class="hljs-string">"runwayml/stable-diffusion-v1-5"</span>,<br>    custom_pipeline=<span class="hljs-string">"clip_guided_stable_diffusion"</span>,<br>    custom_revision=<span class="hljs-string">"main"</span>, <span class="hljs-comment"># 或"v0.25.0"等特定版本</span><br>    clip_model=clip_model,<br>    feature_extractor=feature_extractor,<br>    use_safetensors=<span class="hljs-literal">True</span>,<br>)<br></code></pre></td></tr></table></figure>



<h2 id="Load-safetensors"><a href="#Load-safetensors" class="headerlink" title="Load safetensors"></a>Load safetensors</h2><blockquote>
<p><a target="_blank" rel="noopener" href="https://github.com/huggingface/safetensors">huggingface/safetensors: Simple, safe way to store and distribute tensors (github.com)</a></p>
</blockquote>
<p>是一种安全、快速的文件格式，用于存储和加载张量。通常情况下，PyTorch 模型权重会通过 Python 的 pickle 工具保存到 .bin 文件中。然而，pickle 并不安全，文件可能包含可被执行的恶意代码。safetensors 是 pickle 的安全替代品，是共享模型权重的理想选择。</p>
<p>接下来介绍如何加载 .safetensor 文件，以及如何将以其他格式存储的Stable Diffusion模型权重转换为 <code>.safetensor</code> 格式。开始之前，请确保已安装 safetensors：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">pip install safetensors<br></code></pre></td></tr></table></figure>

<p>默认情况下（如runwayml/stable-diffusion-v1-5），如果模型库中有这些 .safetensors 文件，Diffusers 会自动从它们的子文件夹中加载这些文件。</p>
<p>要实现更<strong>明确</strong>的控制，可以选择设置 <code>use_safetensors=True</code>（如果未安装 safetensors，则会收到要求安装的错误信息）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> DiffusionPipeline<br><br>pipeline = DiffusionPipeline.from_pretrained(<br>    <span class="hljs-string">"runwayml/stable-diffusion-v1-5"</span>, <br>    use_safetensors=<span class="hljs-literal">True</span><br>)<br></code></pre></td></tr></table></figure>

<p>不过，模型权重并不一定像上例那样存储在<strong>单独的子文件夹</strong>中。有时，所有权重都存储在一个 <code>.safetensors</code> 文件中。在这种情况下，如果权重是稳定扩散权重，则可以使用 <code>from_single_file()</code> 方法直接加载该文件：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> StableDiffusionPipeline<br><br>pipeline = StableDiffusionPipeline.from_single_file( <span class="hljs-string">"https://huggingface.co/WarriorMama777/OrangeMixs/blob/main/Models/AbyssOrangeMix/AbyssOrangeMix.safetensors"</span><br>)<br></code></pre></td></tr></table></figure>

<h3 id="转换为safetensors"><a href="#转换为safetensors" class="headerlink" title="转换为safetensors"></a>转换为safetensors</h3><p>并非 Hub 上的所有权重都是 <code>.safetensors</code> 格式，您可能会遇到以 <code>.bin</code> 格式存储的权重。在这种情况下，请使用 <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/diffusers/convert">Convert Space</a> 将权重转换为 <code>.safetensors</code> 格式。</p>
<p>Convert Space会下载权重并进行转换，然后打开一个Pull Request，将新转换的 <code>.safetensors</code> 文件上传到集线器上。这样，如果腌制文件中包含任何恶意代码，它们就会被上传到Hub，而不是你的电脑，因为Hub有一个<a target="_blank" rel="noopener" href="https://huggingface.co/docs/hub/security-pickle#hubs-security-scanner">security scanner</a>来检测不安全的文件。</p>
<h3 id="为什么要使用safetensors？"><a href="#为什么要使用safetensors？" class="headerlink" title="为什么要使用safetensors？"></a>为什么要使用safetensors？</h3><p>使用 safetensors 有几个原因：</p>
<ul>
<li><strong>安全</strong>是使用 safetensors 的首要原因。随着开源和模型分发的发展，确保您下载的模型权重不包含任何恶意代码非常重要。目前 safetensors 中标头的 <code>current size</code> 会阻止解析超大 JSON 文件。</li>
<li>safetensors 也支持延迟加载（Lazy loading），这在分布式设置中非常有用，可以只加载部分张量。通过这种格式，在 8 个 GPU 上加载 BLOOM 模型只需 45 秒，而使用普通 PyTorch 权重则需要 10 分钟。</li>
<li>切换模型之间的<strong>加载速度</strong>是使用 safetensors 的另一个原因，它会对张量执行零拷贝。如果将权重加载到 CPU（默认情况），它的速度比 pickle 更快，而直接将权重加载到 GPU 时，也同样快。</li>
</ul>
<p>加载整个pipeline所需的时间：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> StableDiffusionPipeline<br><br>pipeline = StableDiffusionPipeline.from_pretrained(<span class="hljs-string">"stabilityai/stable-diffusion-2-1"</span>, use_safetensors=<span class="hljs-literal">True</span>)<br><span class="hljs-string">"Loaded in safetensors 0:00:02.033658"</span><br><span class="hljs-string">"Loaded in PyTorch 0:00:02.663379"</span><br></code></pre></td></tr></table></figure>

<p>但加载 500MB 模型权重的实际时间仅为：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">safetensors: 3.4873ms<br>PyTorch: 172.7537ms<br></code></pre></td></tr></table></figure>



<h2 id="Load-different-Stable-Diffusion-formats"><a href="#Load-different-Stable-Diffusion-formats" class="headerlink" title="Load different Stable Diffusion formats"></a>Load different Stable Diffusion formats</h2><p>Stable Diffusion 模型有不同的格式，这取决于它们是用什么框架训练和保存的，以及从哪里下载的。转换这些格式以便在 Diffusers 中使用，可以让您使用该库支持的所有功能，例如：</p>
<ol>
<li>使用不同的采样器进行推理</li>
<li>构建自定义管道</li>
<li>优化推理速度</li>
</ol>
<p>接下来介绍如何转换其他格式以与 Diffusers 兼容。</p>
<h3 id="PyTorch-ckpt"><a href="#PyTorch-ckpt" class="headerlink" title="PyTorch .ckpt"></a>PyTorch .ckpt</h3><p>在 PyTorch 中 <code>checkpoint</code>（或 <code>.ckpt</code>）格式通常用于保存模型。<code>.ckpt</code> 文件包含整个模型。虽然可以使用 <code>from_single_file()</code> 方法直接加载和使用，但通常最好将 <code>.ckpt</code> 文件转换为 Diffusers 推荐的 <code>safetensors</code> 格式。</p>
<p>转换 <code>.ckpt</code> 文件有两种方式：</p>
<ol>
<li>使用 Space 转换检查点</li>
<li>使用脚本转换 <code>.ckpt</code> 文件</li>
</ol>
<h4 id="用Space转换"><a href="#用Space转换" class="headerlink" title="用Space转换"></a>用Space转换</h4><blockquote>
<p><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/diffusers/sd-to-diffusers">SD To Diffusers - a Hugging Face Space by diffusers</a></p>
</blockquote>
<p>转换 <code>.ckpt</code> 文件最简单方便的方法是使用 <code>SD To Diffusers Space</code>。</p>
<p>这种方法对基本模型很有效，但对更多定制模型可能会有困难。如果 Space 返回<code> empty pull request</code>或<code>erroe</code>，可以尝试用脚本转换 <code>.ckpt</code> 文件。</p>
<h4 id="用脚本转换"><a href="#用脚本转换" class="headerlink" title="用脚本转换"></a>用脚本转换</h4><blockquote>
<p><a target="_blank" rel="noopener" href="https://github.com/huggingface/diffusers/blob/main/scripts/convert_original_stable_diffusion_to_diffusers.py">diffusers/scripts/convert_original_stable_diffusion_to_diffusers.py at main · huggingface/diffusers (github.com)</a></p>
</blockquote>
<p>这种方法比上面的Space更可靠，需要设定如下参数：</p>
<ul>
<li><code>checkpoint_path</code>：要转换的 <code>.ckpt</code> 文件的路径。</li>
<li><code>original_config_file</code>：定义原始架构配置的 YAML 文件。如果找不到此文件，请尝试在找到 .ckpt 文件的 GitHub 存储库中搜索 YAML 文件。</li>
<li><code>dump_path</code>：转换后模型的保存路径</li>
</ul>
<h3 id="A1111-LoRA-files"><a href="#A1111-LoRA-files" class="headerlink" title="A1111 LoRA files"></a>A1111 LoRA files</h3><p><a target="_blank" rel="noopener" href="https://github.com/AUTOMATIC1111/stable-diffusion-webui">Automatic1111</a> (A1111) 是一种流行的Stable Diffusion Web UI，支持<a target="_blank" rel="noopener" href="https://civitai.com/">Civitai</a>等模型共享平台。</p>
<p>Diffusers 支持使用 <code>load_lora_weights()</code> 将 LoRA 检查点加载到 pipeline 中：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python">pipeline.load_lora_weights(<br>    <span class="hljs-string">"LoRA/civitai_LoRA"</span>, <br>    weight_name=<span class="hljs-string">"bl3uprint.safetensors"</span><br>)<br><br>save_name = <span class="hljs-string">'lora-blueprint.png'</span><br><br>prompt = <span class="hljs-string">"bl3uprint, a highly detailed blueprint of the empire state building, explaining how to build all parts, many txt, blueprint grid backdrop"</span><br>negative_prompt = <span class="hljs-string">"lowres, cropped, worst quality, low quality, normal quality, artifacts, signature, watermark, username, blurry, more than one bridge, bad architecture"</span><br><br>image = pipeline(<br>    prompt=prompt,<br>    negative_prompt=negative_prompt,<br>    generator=torch.manual_seed(<span class="hljs-number">0</span>),<br>).images[<span class="hljs-number">0</span>]<br>save_path = <span class="hljs-string">'./results/LoRA'</span><br>image.save(os.path.join(save_path, save_name))<br></code></pre></td></tr></table></figure>

<p class='item-img' data-src='https://github.com/TO-Hitori/HBIL/blob/main/diffuser-doc/lora-blueprint.png?raw=true'><img src="https://github.com/TO-Hitori/HBIL/blob/main/diffuser-doc/lora-blueprint.png?raw=true" alt="lora-blueprint.png"></p>
<h2 id="Load-adapters"><a href="#Load-adapters" class="headerlink" title="Load adapters"></a>Load adapters</h2><p>有多种训练技术可用于个性化扩散模型以生成特定主题的图像或某些风格的图像。每种训练方法都依赖不同类型的 Adapter。有些适配器会生成一个全新的模型，而其他适配器则只修改较小的嵌入或权重集。这意味着每个适配器的加载过程也不尽相同。</p>
<p>接下来介绍如何加载 <strong>DreamBooth</strong>、<strong>Textual inversion</strong>和 <strong>LoRA</strong> 权重。</p>
<h3 id="DreamBooth"><a href="#DreamBooth" class="headerlink" title="DreamBooth"></a>DreamBooth</h3><blockquote>
<p><a target="_blank" rel="noopener" href="https://huggingface.co/sd-dreambooth-library">sd-dreambooth-library (Stable Diffusion Dreambooth Concepts Library) (huggingface.co)</a></p>
</blockquote>
<p>DreamBooth 只需在几张同一主题或风格的图像上微调整个扩散模型，就能生成新的同一主题或风格的图像。</p>
<p>这种方法的原理是在提示中使用一个特殊的提示词，让模型学会将该单词与主题图像联系起来。在所有训练方法中，DreamBooth 产生的文件尺寸最大（通常为几 GB），因为它是一个<strong>完整</strong>的检查点。</p>
<p>加载方式和普通pipeline类似：</p>
<p>让我们加载 <a target="_blank" rel="noopener" href="https://huggingface.co/sd-dreambooth-library/pikachu">sd-dreambooth-library/pikachu</a> 检查点，它只对 9 张由 <strong>皮卡丘</strong> 的图像进行训练。为了让它正常工作，需要在提示中加入 <strong>pikachu</strong> 这个特殊的单词来触发检查点：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> AutoPipelineForText2Image<br><span class="hljs-keyword">import</span> torch<br><br>checkpoint_path = <span class="hljs-string">'DreamBooth/pikachu'</span><br>pipeline = AutoPipelineForText2Image.from_pretrained(<br>    checkpoint_path,<br>    torch_dtype=torch.float16<br>).to(<span class="hljs-string">"cuda"</span>)<br>prompt = <span class="hljs-string">"A pikachu is playing the guitar, masterpiece"</span><br>image = pipeline(prompt).images[<span class="hljs-number">0</span>]<br>image.save(<span class="hljs-string">'./result/pikachu_DB.png'</span>)<br></code></pre></td></tr></table></figure class='item-img' data-src='https://github.com/TO-Hitori/HBIL/blob/main/diffuser-doc/pikachu_DB.png?raw=true'><img src="https://github.com/TO-Hitori/HBIL/blob/main/diffuser-doc/pikachu_DB.png?raw=true" alt="pikachu_DB.png" style="zoom:50%;">





<h3 id="Textual-inversion"><a href="#Textual-inversion" class="headerlink" title="Textual inversion"></a>Textual inversion</h3><blockquote>
<p><a target="_blank" rel="noopener" href="https://huggingface.co/sd-concepts-library">sd-concepts-library (Stable Diffusion concepts library) (huggingface.co)</a></p>
</blockquote>
<p>文本反转与 DreamBooth 非常相似，从几张图片中学习生成特定的概念（风格、对象）。这种方法的工作原理是通过训练和寻找新的 embedding，用提示中的一个特殊单词来代表你提供的图片。因此，扩散模型的权重保持不变，训练过程产生的文件也相对较小（几 KB）。</p>
<p>由于文本反转会创建 embedding，因此它不能像 DreamBooth 那样单独使用，而需要依附于另一个扩散模型，这里使用 SD1.5：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> AutoPipelineForText2Image<br><span class="hljs-keyword">import</span> torch, os<br><br>checkpoint_path = <span class="hljs-string">'sd-v1.5/sd-v1.5'</span><br>pipeline = AutoPipelineForText2Image.from_pretrained(<br>    checkpoint_path,<br>    torch_dtype=torch.float16,<br>    variant=<span class="hljs-string">'fp16'</span>,<br>    use_safetensors=<span class="hljs-literal">True</span>,<br>    safety_checker=<span class="hljs-literal">None</span>,<br>).to(<span class="hljs-string">"cuda"</span>)<br></code></pre></td></tr></table></figure>

<p>现在，你可以使用 <code>load_textual_inversion()</code> 方法加载文本反转embedding来生成图像。让我们加载 <a target="_blank" rel="noopener" href="https://huggingface.co/sd-concepts-library/gta5-artwork">sd-concepts-library/gta5-artwork</a> 嵌入，然后在提示中包含特殊字 <code>&lt;gta5-artwork&gt;</code> 来触发它：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python">seed = <span class="hljs-number">0</span><br>save_name = (<span class="hljs-string">f'gta5-artwork-TI-<span class="hljs-subst">{seed}</span>.png'</span>)<br>pipeline.load_textual_inversion(<span class="hljs-string">"Textual_inversion/gta5-artwork"</span>)<br>prompt = <span class="hljs-string">"a man is playing the guitar, masterpiece, best quality, &lt;gta5-artwork&gt; style"</span><br>image = pipeline(<br>    prompt,<br>    num_inference_steps=<span class="hljs-number">25</span>,<br>    generator=torch.manual_seed(seed)<br>).images[<span class="hljs-number">0</span>]<br><br>save_path = <span class="hljs-string">'./results/Textual_inversion'</span><br><span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> os.path.exists(save_path):<br>    os.makedirs(save_path)<br>image.save(os.path.join(save_path, save_name))<br></code></pre></td></tr></table></figure class='item-img' data-src='https://github.com/TO-Hitori/HBIL/blob/main/diffuser-doc/gta5-artwork-TI-0.png?raw=true'><img src="https://github.com/TO-Hitori/HBIL/blob/main/diffuser-doc/gta5-artwork-TI-0.png?raw=true" alt="gta5-artwork-TI-0.png" style="zoom: 67%;">

<p>文本反转也可以针对不需要的事物进行训练，以创建<code>negative embeddings</code>，阻止模型生成含有我们不希望出现内容的图像，如带有模糊的图像或人物手指数量异常的图像。</p>
<p>这是快速改进 prompt 的简单方法。可以使用 <code>load_textual_inversion()</code> 加载embedding，设定这两个参数：</p>
<ul>
<li><code>weight_name</code>：要加载的权重文件</li>
<li><code>token</code>：在 prompt 中的触发词</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python">seed = <span class="hljs-number">0</span><br>save_name = (<span class="hljs-string">f'gta5-artwork-TI-EN-<span class="hljs-subst">{seed}</span>.png'</span>)<br>pipeline.load_textual_inversion(<span class="hljs-string">"Textual_inversion/gta5-artwork"</span>)<br><br><span class="hljs-comment"># 载入 EasyNegative</span><br>pipeline.load_textual_inversion(<br>    <span class="hljs-string">"Textual_inversion"</span>,<br>    weight_name=<span class="hljs-string">"EasyNegative.safetensors"</span>,<br>    token=<span class="hljs-string">"EasyNegative"</span><br>)<br><br>prompt = <span class="hljs-string">"A man is playing the guitar, masterpiece, best quality, &lt;gta5-artwork&gt; style, EasyNegative"</span><br>negative_prompt = <span class="hljs-string">"EasyNegative"</span><br>image = pipeline(<br>    prompt,<br>    negative_prompt=negative_prompt,<br>    num_inference_steps=<span class="hljs-number">25</span>,<br>    generator=torch.manual_seed(seed),<br>).images[<span class="hljs-number">0</span>]<br></code></pre></td></tr></table></figure class='item-img' data-src='https://github.com/TO-Hitori/HBIL/blob/main/diffuser-doc/gta5-artwork-TI-EN-0.png?raw=true'><img src="https://github.com/TO-Hitori/HBIL/blob/main/diffuser-doc/gta5-artwork-TI-EN-0.png?raw=true" alt="gta5-artwork-TI-EN-0.png" style="zoom: 67%;">



<h3 id="LoRA"><a href="#LoRA" class="headerlink" title="LoRA"></a>LoRA</h3><p>Low-Rank Adaptation（LoRA）是一种流行的微调技术，因为它速度快，生成的文件较小（几百 MB）。从几张图像中学习新的风格。</p>
<p>它的工作原理是在扩散模型中插入新的权重，然后只训练新权重而不是整个模型。这使得 LoRA 的训练速度更快，也更易于存储。</p>
<blockquote>
<p>LoRA 是一种非常通用的训练技术，可以与其他训练方法一起使用。</p>
<p>使用 DreamBooth 和 LoRA 训练模型就很常见。</p>
</blockquote>
<p>LoRA 也需要依附于一个扩散模型使用，这里使用SDXL：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> AutoPipelineForText2Image<br><span class="hljs-keyword">import</span> torch, os<br><br>checkpoint_path = <span class="hljs-string">'SDXL/stable-diffusion-xl-base-1.0'</span><br>pipeline = AutoPipelineForText2Image.from_pretrained(<br>    checkpoint_path,<br>    torch_dtype=torch.float16,<br>    variant=<span class="hljs-string">'fp16'</span>,<br>    use_safetensors=<span class="hljs-literal">True</span>,<br>    safety_checker=<span class="hljs-literal">None</span>,<br>).to(<span class="hljs-string">"cuda"</span>)<br></code></pre></td></tr></table></figure>

<p>然后使用 <code>load_lora_weights()</code> 方法加载 <a target="_blank" rel="noopener" href="https://civitai.com/models/266711/sdxlpixel-art-lora">Pixel Art LoRA | Civitai</a> 权重并指定权重文件名，命名这个 LoRA 为 <code>pixel</code>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python">pipeline.load_lora_weights(<br>    <span class="hljs-string">"LoRA/civitai_LoRA"</span>,<br>    weight_name=<span class="hljs-string">"pixel_stormXL.safetensors"</span>,<br>    adapter_name=<span class="hljs-string">"pixel"</span><br>)<br><br>seed = <span class="hljs-number">0</span><br>save_name = (<span class="hljs-string">f'pixel-LoRA-<span class="hljs-subst">{seed}</span>.png'</span>)<br><br>prompt = <span class="hljs-string">"A man is playing the guitar, masterpiece, best quality"</span><br>image = pipeline(<br>    prompt,<br>    num_inference_steps=<span class="hljs-number">30</span>,<br>    generator=torch.manual_seed(seed),<br>).images[<span class="hljs-number">0</span>]<br><br>save_path = <span class="hljs-string">'./results/LoRA'</span><br><span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> os.path.exists(save_path):<br>    os.makedirs(save_path)<br>image.save(os.path.join(save_path, save_name))<br></code></pre></td></tr></table></figure class='item-img' data-src='https://github.com/TO-Hitori/HBIL/blob/main/diffuser-doc/pixel-LoRA-0.png?raw=true'><img src="https://github.com/TO-Hitori/HBIL/blob/main/diffuser-doc/pixel-LoRA-0.png?raw=true" alt="pixel-LoRA-0.png" style="zoom:50%;">

<p><code>load_lora_weights()</code> 方法可将 LoRA 权重加载到 <strong>UNet</strong> 和文本编码器中。通过 <code>get_list_adapters()</code> 方法查看加载位置：</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs stylus">list_adapters_component_wise = pipeline<span class="hljs-selector-class">.get_list_adapters</span>()<br><span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(list_adapters_component_wise)</span></span><br><br>{<span class="hljs-string">'text_encoder'</span>: <span class="hljs-selector-attr">[<span class="hljs-string">'pixel'</span>]</span>, <span class="hljs-string">'text_encoder_2'</span>: <span class="hljs-selector-attr">[<span class="hljs-string">'pixel'</span>]</span>, <span class="hljs-string">'unet'</span>: <span class="hljs-selector-attr">[<span class="hljs-string">'pixel'</span>]</span>}<br></code></pre></td></tr></table></figure>

<p>这是加载 LoRA 的首选方法，因为它可以处理以下情况</p>
<ul>
<li>LoRA 权重在 UNet 和文本编码器中没有单独的标识符</li>
<li>LoRA 权重在 UNet 和文本编码器中有单独的标识符</li>
</ul>
<p>但如果你只需要将LoRA权重加载到UNet中，那么你可以使用 <code>load_attn_procs()</code>方法。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">pipeline.unet.load_attn_procs(<br>	<span class="hljs-string">"LoRA/civitai_LoRA"</span>,<br>    weight_name=<span class="hljs-string">"pixel_stormXL.safetensors"</span>,<br>)<br></code></pre></td></tr></table></figure>

<p>要卸载 LoRA 权重，请使用 <code>unload_lora_weights()</code> 方法丢弃 LoRA 权重并将模型恢复为其原始权重：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs pyhton">pipeline.unload_lora_weights()<br></code></pre></td></tr></table></figure>



<h3 id="IP-Adapter"><a href="#IP-Adapter" class="headerlink" title="IP-Adapter"></a>IP-Adapter</h3><blockquote>
<p><a target="_blank" rel="noopener" href="https://huggingface.co/h94/IP-Adapter">h94/IP-Adapter · Hugging Face</a></p>
</blockquote>
<p>IP-Adapter 是一种轻量级Adapter，可为任何扩散模型提供图像 prompt。该适配器通过解耦图像和文本特征的交叉注意层来工作。所有其他模型组件都被冻结，只有 UNet 中的embedded image features会被训练。因此，IP-Adapter 文件大小通常只有约 100MB。</p>
<p>首先，加载 Stable Diffusion 检查点。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs pyhton">import os<br>os.environ['HTTP_PROXY'] = 'http://127.0.0.1:33210'<br>os.environ['HTTPS_PROXY'] = 'http://127.0.0.1:33210'<br>from diffusers import AutoPipelineForText2Image, DPMSolverMultistepScheduler<br>import torch<br>from diffusers.utils import load_image<br><br>checkpoint_path = 'sd-v1.5/sd-v1.5'<br>pipeline = AutoPipelineForText2Image.from_pretrained(<br>    checkpoint_path,<br>    torch_dtype=torch.float16,<br>    variant='fp16',<br>    use_safetensors=True,<br>    safety_checker=None,<br>).to("cuda")<br></code></pre></td></tr></table></figure>

<p>然后使用 load_ip_adapter() 方法将其添加到 pipeline 中。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs pyhton">pipeline.load_ip_adapter("LoRA/IP-Adapter", subfolder="models", weight_name="ip-adapter_sd15.safetensors")<br></code></pre></td></tr></table></figure>

<p>加载后，您可以使用带有图像和文本提示的管道来指导图像生成过程。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs pyhton">image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/load_neg_embed.png")<br>generator = torch.Generator(device="cpu").manual_seed(33)<br>images = pipeline(<br>    prompt='best quality, high quality, wearing sunglasses',<br>    ip_adapter_image=image,<br>    negative_prompt="monochrome, lowres, bad anatomy, worst quality, low quality",<br>    num_inference_steps=50,<br>    generator=generator,<br>).images[0]<br>images.save('./results/IP-Adapter.png')<br></code></pre></td></tr></table></figure>

<p class='item-img' data-src='https://huggingface.co/datasets/YiYiXu/testing-images/resolve/main/ip-bear.png'><img src="https://huggingface.co/datasets/YiYiXu/testing-images/resolve/main/ip-bear.png" alt="img"></p>
<h3 id="IP-Adapter-Plus"><a href="#IP-Adapter-Plus" class="headerlink" title="IP-Adapter Plus"></a>IP-Adapter Plus</h3><p>IP-Adapter 依靠图像编码器生成图像特征。如果 IP-Adapter 资源库包含 <code>image_encoder</code> 子文件夹，图像编码器就会自动加载并注册到 pipeline 中。否则，就需要使用 <code>CLIPVisionModelWithProjection</code> 模型显式加载图像编码器，并将其传递给 pipeline。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> CLIPVisionModelWithProjection<br><br><span class="hljs-comment"># 显式加载图像编码器</span><br>image_encoder = CLIPVisionModelWithProjection.from_pretrained(<br>    <span class="hljs-string">"h94/IP-Adapter"</span>,<br>    subfolder=<span class="hljs-string">"models/image_encoder"</span>,<br>    torch_dtype=torch.float16<br>)<br><br>pipeline = AutoPipelineForText2Image.from_pretrained(<br>    <span class="hljs-string">"stabilityai/stable-diffusion-xl-base-1.0"</span>,<br>    image_encoder=image_encoder,<br>    torch_dtype=torch.float16<br>).to(<span class="hljs-string">"cuda"</span>)<br><br>pipeline.load_ip_adapter(<span class="hljs-string">"h94/IP-Adapter"</span>, subfolder=<span class="hljs-string">"sdxl_models"</span>, weight_name=<span class="hljs-string">"ip-adapter-plus_sdxl_vit-h.safetensors"</span>)<br></code></pre></td></tr></table></figure>



<h2 id="Push-files-to-the-Hub"><a href="#Push-files-to-the-Hub" class="headerlink" title="Push files to the Hub"></a>Push files to the Hub</h2><p>待定</p>
<div id="paginator"></div></div><div id="post-footer"><div id="pages"><div class="footer-link" style="width: 50%;text-align:right;border-right:1px #fe2 solid"><a href="/2024/04/19/Accelerate%20base/">← Next Accelerate基本使用方法</a></div><div class="footer-link" style="width: 50%;right:1px;border-left:1px #fe2 solid"><a href="/2024/04/10/5.%20%E5%8A%A0%E9%80%9F%20T2I%20%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%8E%A8%E7%90%86/">5.加速 T2I 扩散模型的推理 Prev →</a></div></div></div></div><div class="bottom-btn"><div><a class="i-top" id="to-top" onClick="scrolls.scrolltop();" title="To Top" style="opacity: 0; display: none;">∧ </a><a class="i-index" id="to-index" href="#toc-div" title="To Catalog">≡</a><a class="i-color" id="color-mode" onClick="colorMode.change()" title="Change Theme"></a></div></div></article><aside><div id="about"><a href="/" id="logo"><img src="https://ak.hypergryph.com/assets/index/images/ak/pc/faction/1.png" alt="Logo"></a><h1 id="Dr"><a href="/">TO-Hitori</a></h1><div id="description"><p></p></div></div><div id="aside-block"><div id="toc-div"><h1>Catalog</h1><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Loading-Hub"><span class="toc-number">1.</span> <span class="toc-text">Loading &amp; Hub</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Overview"><span class="toc-number">1.1.</span> <span class="toc-text">Overview</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Load-pipelines-models-and-schedulers"><span class="toc-number">1.2.</span> <span class="toc-text">Load pipelines, models, and schedulers</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%80%9A%E8%BF%87Diffusion-Pipeline%E5%8A%A0%E8%BD%BD%E6%A3%80%E6%9F%A5%E7%82%B9"><span class="toc-number">1.2.1.</span> <span class="toc-text">通过Diffusion Pipeline加载检查点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9B%BF%E6%8D%A2Pipeline%E4%B8%AD%E7%9A%84%E7%BB%84%E4%BB%B6"><span class="toc-number">1.2.2.</span> <span class="toc-text">替换Pipeline中的组件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Safety-checker"><span class="toc-number">1.2.3.</span> <span class="toc-text">Safety checker</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%B7%A8Pipeline%E9%87%8D%E7%94%A8%E7%BB%84%E4%BB%B6"><span class="toc-number">1.2.4.</span> <span class="toc-text">跨Pipeline重用组件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A3%80%E6%9F%A5%E7%82%B9%E5%8F%98%E4%BD%93-Checkpoint-variants"><span class="toc-number">1.2.5.</span> <span class="toc-text">检查点变体 Checkpoint variants</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8A%A0%E8%BD%BD%E5%8F%98%E4%BD%93"><span class="toc-number">1.2.5.1.</span> <span class="toc-text">加载变体</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BF%9D%E5%AD%98%E5%8F%98%E4%BD%93"><span class="toc-number">1.2.5.2.</span> <span class="toc-text">保存变体</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Models"><span class="toc-number">1.2.6.</span> <span class="toc-text">Models</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%87%87%E6%A0%B7%E5%99%A8"><span class="toc-number">1.2.7.</span> <span class="toc-text">采样器</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#DiffusionPipeline%E8%AF%A6%E8%A7%A3"><span class="toc-number">1.2.8.</span> <span class="toc-text">DiffusionPipeline详解</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Load-and-compare-different-schedulers"><span class="toc-number">1.3.</span> <span class="toc-text">Load and compare different schedulers</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%BF%E9%97%AE%E9%87%87%E6%A0%B7%E5%99%A8"><span class="toc-number">1.3.1.</span> <span class="toc-text">访问采样器</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9B%B4%E6%94%B9%E9%87%87%E6%A0%B7%E5%99%A8"><span class="toc-number">1.3.2.</span> <span class="toc-text">更改采样器</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%AF%94%E8%BE%83%E9%87%87%E6%A0%B7%E5%99%A8"><span class="toc-number">1.3.3.</span> <span class="toc-text">比较采样器</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Load-community-pipelines-and-components"><span class="toc-number">1.4.</span> <span class="toc-text">Load community pipelines and components</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%8E%E6%9C%AC%E5%9C%B0%E6%96%87%E4%BB%B6%E5%8A%A0%E8%BD%BD"><span class="toc-number">1.4.1.</span> <span class="toc-text">从本地文件加载</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%8E%E7%89%B9%E5%AE%9A%E7%89%88%E6%9C%AC%E5%8A%A0%E8%BD%BD"><span class="toc-number">1.4.2.</span> <span class="toc-text">从特定版本加载</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Load-safetensors"><span class="toc-number">1.5.</span> <span class="toc-text">Load safetensors</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BD%AC%E6%8D%A2%E4%B8%BAsafetensors"><span class="toc-number">1.5.1.</span> <span class="toc-text">转换为safetensors</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E4%BD%BF%E7%94%A8safetensors%EF%BC%9F"><span class="toc-number">1.5.2.</span> <span class="toc-text">为什么要使用safetensors？</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Load-different-Stable-Diffusion-formats"><span class="toc-number">1.6.</span> <span class="toc-text">Load different Stable Diffusion formats</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#PyTorch-ckpt"><span class="toc-number">1.6.1.</span> <span class="toc-text">PyTorch .ckpt</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%94%A8Space%E8%BD%AC%E6%8D%A2"><span class="toc-number">1.6.1.1.</span> <span class="toc-text">用Space转换</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%94%A8%E8%84%9A%E6%9C%AC%E8%BD%AC%E6%8D%A2"><span class="toc-number">1.6.1.2.</span> <span class="toc-text">用脚本转换</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#A1111-LoRA-files"><span class="toc-number">1.6.2.</span> <span class="toc-text">A1111 LoRA files</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Load-adapters"><span class="toc-number">1.7.</span> <span class="toc-text">Load adapters</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#DreamBooth"><span class="toc-number">1.7.1.</span> <span class="toc-text">DreamBooth</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Textual-inversion"><span class="toc-number">1.7.2.</span> <span class="toc-text">Textual inversion</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#LoRA"><span class="toc-number">1.7.3.</span> <span class="toc-text">LoRA</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#IP-Adapter"><span class="toc-number">1.7.4.</span> <span class="toc-text">IP-Adapter</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#IP-Adapter-Plus"><span class="toc-number">1.7.5.</span> <span class="toc-text">IP-Adapter Plus</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Push-files-to-the-Hub"><span class="toc-number">1.8.</span> <span class="toc-text">Push files to the Hub</span></a></li></ol></li></ol></div></div><footer><nobr>Published with <a target="_blank" rel="noopener" href="http://hexo.io">Hexo</a></nobr><wbr><nobr> Theme <a target="_blank" rel="noopener" href="https://github.com/Yue-plus/hexo-theme-arknights">Arknights</a></nobr><wbr><nobr> by <a target="_blank" rel="noopener" href="https://github.com/Yue-plus">Yue_plus</a></nobr></footer></aside></main><canvas id="canvas-dust"></canvas></body></html>