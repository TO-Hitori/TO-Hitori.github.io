<!DOCTYPE html><html lang="zh-CN" theme-mode="dark"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>3.训练diffusion model | TO-Hitori</title><link rel="icon" type="image/x-icon" href="/favicon.ico"><link rel="preload" as="font" crossorigin="anonymous" href="/font/Bender.ttf"><link rel="preload" as="font" crossorigin="anonymous" href="/font/BenderLight.ttf"><link rel="preload" as="font" crossorigin="anonymous" href="/font/JetBrainsMono-Regular.woff2"><link rel="stylesheet" href="/css/arknights.css"><style>@font-face {
  font-family: Bender;
  src: local('Bender'), url("/font/Bender.ttf"), url("/font/Bender.otf");
}
@font-face {
  font-family: BenderLight;
  src: local('BenderLight'), url("/font/BenderLight.ttf");
}
@font-face {
  font-family: 'JetBrains Mono';
  src: local('JetBrains Mono'), url('/font/JetBrainsMono-Regular.woff2') format('woff2');
}
</style><script>var config = {"root":"/","search":{"preload":false,"activeHolder":"键入以继续","blurHolder":"数据检索","noResult":"无 $0 相关数据"},"code":{"codeInfo":"$0 - $1 行","copy":"复制"}}</script><link type="text/css" rel="stylesheet" href="/lib/encrypt/hbe.style.css"><link type="text/css" rel="stylesheet" href="//unpkg.com/lightgallery@2.7.1/css/lightgallery.css"><link type="text/css" rel="stylesheet" href="//unpkg.com/lightgallery@2.7.1/css/lg-zoom.css"><link type="text/css" rel="stylesheet" href="//unpkg.com/lightgallery@2.7.1/css/lg-thumbnail.css"><link type="text/css" rel="stylesheet" href="/lib/fontawesome/css/all.min.css"><script>if (window.localStorage.getItem('theme-mode') === 'light')
 document.documentElement.setAttribute('theme-mode', 'light')
if (window.localStorage.getItem('theme-mode') === 'dark')
 document.documentElement.setAttribute('theme-mode', 'dark')</script><style>:root {
 --dark-background: url('https://ak.hypergryph.com/assets/index/images/ak/pc/bk.jpg');
 --light-background: url('/img/bk.jpg');
 --theme-encrypt-confirm: '确认'
}</style><script defer src="/js/arknights.js"></script><script defer src="/js/search.js"></script><script defer type="module">import mermaid from '//unpkg.com/mermaid@10.5.0/dist/mermaid.esm.mjs';
window.mermaid = mermaid;
code.paintMermaid();
</script><script async src="//unpkg.com/lightgallery@2.7.1/lightgallery.min.js"></script><script async src="//unpkg.com/lightgallery@2.7.1/plugins/zoom/lg-zoom.min.js"></script><script async src="//unpkg.com/lightgallery@2.7.1/plugins/thumbnail/lg-thumbnail.min.js"></script><script async src="/lib/encrypt/hbe.js"></script><script async src="/js/pjax.js"></script><script class="pjax-js">reset= () => {document.querySelector('.lg-container')?.remove()
lightGallery(document.getElementById('post-bg'), {
  plugins: [lgZoom,lgThumbnail],
  selector: '.item-img'})}</script><script>window.addEventListener("load",() => {pjax = new Pjax({
 cacheBust: false,
 selectors: ['title','article','#aside-block','.pjax-js','data-pjax','.busuanzi'],
 switches: {'article': Pjax.switches.sideBySide},
 switchesOptions: {
   'article': {
     classNames: {
       remove: "pjax-out",
       add: "pjax-in"
     }
   }
 }
});
document.addEventListener("pjax:complete", reset);reset()})</script><meta name="generator" content="Hexo 7.1.1"><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style></head><body><div class="loading" style="opacity: 0;"><div class="loadingBar left"></div><div class="loadingBar right"></div></div><main><header class="closed"><div class="navBtn"><i class="navBtnIcon"><span class="navBtnIconBar"></span><span class="navBtnIconBar"></span><span class="navBtnIconBar"></span></i></div><nav><div class="navItem" id="search-header"><span class="navItemTitle"><input autocomplete="off" autocorrect="off" autocapitalize="none" placeholder="数据检索" spellcheck="false" maxlength="50" type="text" id="search-input"></span></div><div class="navItem" id="search-holder"></div><div class="search-popup" tabindex="0"><div id="search-result"></div></div><ol class="navContent"><li class="navItem"><a class="navBlock" href="/"><span class="navItemTitle">Home</span></a></li><li class="navItem" matchdata="categories,tags"><a class="navBlock" href="/archives/"><span class="navItemTitle">Archives</span></a></li></ol></nav></header><article><div id="post-bg"><div id="post-title"><h1>3.训练diffusion model</h1><div id="post-info"><span>文章发布时间: <div class="control"><time datetime="2024-04-09T13:35:30.000Z" id="date"> 2024-04-09</time></div></span><br><span>最后更新时间: <div class="control"><time datetime="2024-04-11T10:52:50.979Z" id="updated"> 2024-04-11</time></div></span><br><span>文章总字数: <div class="control">2.1k</div></span><br><span>预计阅读时间: <div class="control">9 分钟</div></span></div></div><hr><div id="post-content"><h1 id="Train-a-diffusion-model"><a href="#Train-a-diffusion-model" class="headerlink" title="Train a diffusion model"></a>Train a diffusion model</h1><p>无条件图像生成是扩散模型的一种流行应用，它生成的图像与用于训练的数据集中的图像相似。通常，最好的结果是通过在特定数据集上微调预训练模型来获得的。</p>
<p>您可以在 <a target="_blank" rel="noopener" href="https://huggingface.co/search/full-text?q=unconditional-image-generation&type=model">Hub</a> 上找到许多这样的检查点，但如果您找不到您喜欢的检查点，您可以随时训练自己的检查点！</p>
<p>本教程将教您如何在 Smithsonian Butterflies 数据集的子集上从头开始训练 UNet2DModel，以生成您自己的Butterflies</p>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/training_example.ipynb">diffusers_training_example.ipynb - Colaboratory (google.com)</a></p>
</blockquote>
<h2 id="训练配置"><a href="#训练配置" class="headerlink" title="训练配置"></a>训练配置</h2><p>为了方便起见，创建一个包含训练超参数的 TrainingConfig 类：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> dataclasses <span class="hljs-keyword">import</span> dataclass<br><br><span class="hljs-meta">@dataclass</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">TrainingConfig</span>:<br>    image_size = <span class="hljs-number">128</span>                       <span class="hljs-comment"># 生成图像的分辨率</span><br>    train_batch_size = <span class="hljs-number">16</span>                  <span class="hljs-comment"># 训练batch</span><br>    eval_batch_size = <span class="hljs-number">16</span>                   <span class="hljs-comment"># 验证阶段的图像数量</span><br>    num_epochs = <span class="hljs-number">50</span><br>    gradient_accumulation_steps = <span class="hljs-number">1</span>        <span class="hljs-comment">#</span><br>    learning_rate = <span class="hljs-number">1e-4</span><br>    lr_warmup_steps = <span class="hljs-number">500</span><br>    save_image_epochs = <span class="hljs-number">10</span><br>    save_model_epochs = <span class="hljs-number">30</span><br>    mixed_precision = <span class="hljs-string">"fp16"</span>               <span class="hljs-comment"># `no` for float32, `fp16` for automatic mixed precision</span><br>    output_dir = <span class="hljs-string">"ddpm-butterflies-128"</span>  <span class="hljs-comment"># the model name locally and on the HF Hub</span><br>    push_to_hub = <span class="hljs-literal">False</span>  <span class="hljs-comment"># whether to upload the saved model to the HF Hub</span><br>    hub_model_id = <span class="hljs-string">"TO-Hitori/my-awesome-model"</span>  <span class="hljs-comment"># the name of the repository to create on the HF Hub</span><br>    hub_private_repo = <span class="hljs-literal">False</span><br>    overwrite_output_dir = <span class="hljs-literal">True</span>  <span class="hljs-comment"># overwrite the old model when re-running the notebook</span><br>    seed = <span class="hljs-number">0</span><br><br><br>config = TrainingConfig()<br></code></pre></td></tr></table></figure>



<h2 id="载入数据集"><a href="#载入数据集" class="headerlink" title="载入数据集"></a>载入数据集</h2><p>您可以使用datasets库轻松加载<a target="_blank" rel="noopener" href="https://huggingface.co/datasets/huggan/smithsonian_butterflies_subset">Smithsonian Butterflies</a>数据集：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset<br><br><span class="hljs-comment"># 数据集路径：本地路径或hugging-face路径</span><br>config.dataset_name = <span class="hljs-string">r"D:\MyData\smithsonian_butterflies_subset"</span><br>dataset = load_dataset(config.dataset_name, split=<span class="hljs-string">"train"</span>)<br></code></pre></td></tr></table></figure>

<blockquote>
<p>在此查找其他数据集：<a target="_blank" rel="noopener" href="https://huggingface.co/huggan">huggan (HugGAN Community) (huggingface.co)</a></p>
</blockquote>
<p>Datasets 使用 Image 功能自动解码图像数据并将其加载为我们可以可视化的 PIL.Image：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><br>fig, axs = plt.subplots(<span class="hljs-number">1</span>, <span class="hljs-number">4</span>, figsize=(<span class="hljs-number">16</span>, <span class="hljs-number">4</span>))<br><span class="hljs-keyword">for</span> i, image <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(dataset[:<span class="hljs-number">4</span>][<span class="hljs-string">"image"</span>]):<br>    axs[i].imshow(image)<br>    axs[i].set_axis_off()<br><br>fig.show()<br></code></pre></td></tr></table></figure>

<p>这些图像的尺寸各不相同，因此需要先对它们进行预处理：</p>
<ul>
<li>Resize 将图像大小更改为 config.image_size 中定义的大小。 </li>
<li>RandomHorizontalFlip 通过随机镜像翻转图像来增强数据集。 </li>
<li>Normalize对于将像素值重新缩放到 [-1, 1] 范围非常重要，这是模型所期望的输入范围。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> torchvision <span class="hljs-keyword">import</span> transforms<br><br>preprocess = transforms.Compose(<br>    [<br>        transforms.Resize((config.image_size, config.image_size)),<br>        transforms.RandomHorizontalFlip(),<br>        transforms.ToTensor(),<br>        transforms.Normalize([<span class="hljs-number">0.5</span>], [<span class="hljs-number">0.5</span>]),<br>    ]<br>)<br></code></pre></td></tr></table></figure>

<p>使用Datasets的 <code>set_transform</code> 方法在训练期间动态应用预处理函数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">transform</span>(<span class="hljs-params">examples</span>):<br>    images = [preprocess(image.convert(<span class="hljs-string">"RGB"</span>)) <span class="hljs-keyword">for</span> image <span class="hljs-keyword">in</span> examples[<span class="hljs-string">"image"</span>]]<br>    <span class="hljs-keyword">return</span> {<span class="hljs-string">"images"</span>: images}<br><br>dataset.set_transform(transform)<br></code></pre></td></tr></table></figure>

<p>将数据集包装在torch的 <code>DataLoader</code> 中进行训练！</p>
<figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs haskell"><span class="hljs-keyword">import</span> torch<br><br><span class="hljs-title">train_dataloader</span> = torch.utils.<span class="hljs-class"><span class="hljs-keyword">data</span>.<span class="hljs-type">DataLoader</span>(<span class="hljs-title">dataset</span>, <span class="hljs-title">batch_size</span>=<span class="hljs-title">config</span>.<span class="hljs-title">train_batch_size</span>, <span class="hljs-title">shuffle</span>=<span class="hljs-type">True</span>)</span><br></code></pre></td></tr></table></figure>



<h2 id="创建-UNet2D-模型"><a href="#创建-UNet2D-模型" class="headerlink" title="创建 UNet2D 模型"></a>创建 UNet2D 模型</h2><p> Diffusers 中的预训练模型可以使用您想要的参数轻松地从其模型类创建。例如，要创建 UNet2DModel：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 创建U-Net</span><br><span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> UNet2DModel<br><br>model = UNet2DModel(<br>    sample_size=config.image_size,  <span class="hljs-comment"># 图像分辨率</span><br>    in_channels=<span class="hljs-number">3</span>,                  <span class="hljs-comment"># 输入图像的通道数量</span><br>    out_channels=<span class="hljs-number">3</span>,                 <span class="hljs-comment"># 输出图像的通道数量</span><br>    layers_per_block=<span class="hljs-number">2</span>,             <span class="hljs-comment"># 每层使用的残差块个数</span><br>    block_out_channels=(<span class="hljs-number">128</span>, <span class="hljs-number">128</span>, <span class="hljs-number">256</span>, <span class="hljs-number">256</span>, <span class="hljs-number">512</span>, <span class="hljs-number">512</span>),  <span class="hljs-comment"># 每一层的输出通道数量</span><br>    down_block_types=(<br>        <span class="hljs-string">"DownBlock2D"</span>,              <span class="hljs-comment"># 残差下采样模块</span><br>        <span class="hljs-string">"DownBlock2D"</span>,<br>        <span class="hljs-string">"DownBlock2D"</span>,<br>        <span class="hljs-string">"DownBlock2D"</span>,<br>        <span class="hljs-string">"AttnDownBlock2D"</span>,          <span class="hljs-comment"># 有spatial self-attention的下采样残差模块</span><br>        <span class="hljs-string">"DownBlock2D"</span>,<br>    ),<br>    up_block_types=(<br>        <span class="hljs-string">"UpBlock2D"</span>,                <span class="hljs-comment"># 残差上采样模块</span><br>        <span class="hljs-string">"AttnUpBlock2D"</span>,            <span class="hljs-comment"># 有spatial self-attention的上采样残差模块</span><br>        <span class="hljs-string">"UpBlock2D"</span>,<br>        <span class="hljs-string">"UpBlock2D"</span>,<br>        <span class="hljs-string">"UpBlock2D"</span>,<br>        <span class="hljs-string">"UpBlock2D"</span>,<br>    ),<br>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">"UNet2DModel have {} paramerters in total"</span>.<span class="hljs-built_in">format</span>(<span class="hljs-built_in">sum</span>(x.numel() <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> model.parameters())))<br><span class="hljs-comment"># UNet2DModel have 113673219 paramerters in total</span><br></code></pre></td></tr></table></figure>

<p>检查样本图像形状与模型输出形状是否匹配：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">sample_image = dataset[<span class="hljs-number">0</span>][<span class="hljs-string">"images"</span>].unsqueeze(<span class="hljs-number">0</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">"Input shape:"</span>, sample_image.shape)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">"Output shape:"</span>, model(sample_image, timestep=<span class="hljs-number">0</span>).sample.shape)<br><span class="hljs-string">'''</span><br><span class="hljs-string">Input shape: torch.Size([1, 3, 128, 128])</span><br><span class="hljs-string">Output shape: torch.Size([1, 3, 128, 128])</span><br><span class="hljs-string">'''</span><br></code></pre></td></tr></table></figure>



<h2 id="创建采样器"><a href="#创建采样器" class="headerlink" title="创建采样器"></a>创建采样器</h2><p>根据您使用模型进行训练还是推理，采样器的行为会有所不同。</p>
<ul>
<li>在推理过程中，采样器根据噪声生成图像。</li>
<li>在训练期间，采样器从扩散过程中的特定点获取模型输出（或样本），并根据噪声调度<code>noise schedule</code>和更新规则<code>update rule</code>将噪声注入图像。</li>
</ul>
<p>让我们看一下 <code>DDPMScheduler</code> 并使用 <code>add_noise</code> 方法向<code>sample_image</code> 添加一些随机噪声：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image<br><span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> DDPMScheduler<br><span class="hljs-keyword">from</span> torchvision.utils <span class="hljs-keyword">import</span> save_image, make_grid<br><br><span class="hljs-comment"># 用总步数来初始化采样器</span><br>noise_scheduler = DDPMScheduler(num_train_timesteps=<span class="hljs-number">1000</span>)<br><br><span class="hljs-comment"># 设定加噪序列，这里选择了7个依次增大的时间步</span><br>timesteps = torch.LongTensor([<span class="hljs-number">50</span>, <span class="hljs-number">150</span>, <span class="hljs-number">250</span>, <span class="hljs-number">450</span>, <span class="hljs-number">650</span>, <span class="hljs-number">850</span>, <span class="hljs-number">990</span>])<br><span class="hljs-comment"># 时间步的数量为batch，采样图片的形状后三个维度，构建采样噪声</span><br>noise = torch.randn(timesteps.shape + sample_image.shape[<span class="hljs-number">1</span>:])<br><span class="hljs-comment"># 利用采样器的add_noise方法将噪声注入采样图片</span><br>noisy_image = noise_scheduler.add_noise(sample_image, noise, timesteps)<br><span class="hljs-comment"># 保存图片观测采样器的加噪效果</span><br>save_to_show = make_grid(torch.cat([sample_image, noisy_image], dim=<span class="hljs-number">0</span>))<br>save_image(save_to_show, <span class="hljs-string">'./test_scheduler.png'</span>)<br></code></pre></td></tr></table></figure>

<p>模型的训练目标是预测添加到图像中的噪声。这一步的损失可以通过下式计算：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 损失函数：最简单的MSE损失函数</span><br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">'test loss func'</span>)<br>noise_pred = model(noisy_image, timesteps).sample<br>loss = F.mse_loss(noise_pred, noise)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">'loss value = '</span>, loss.item())<br></code></pre></td></tr></table></figure>



<h2 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h2><p>到目前为止，您已经掌握了开始训练模型的大部分内容，剩下的就是将所有内容组合在一起。 首先，您需要一个优化器和一个学习率调度器：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 开始训练：设置调度器</span><br><span class="hljs-keyword">from</span> diffusers.optimization <span class="hljs-keyword">import</span> get_cosine_schedule_with_warmup<br><br>optimizer = torch.optim.AdamW(model.parameters(), lr=config.learning_rate)<br>lr_scheduler = get_cosine_schedule_with_warmup(<br>    optimizer=optimizer,<br>    num_warmup_steps=config.lr_warmup_steps,<br>    num_training_steps=(<span class="hljs-built_in">len</span>(train_dataloader) * config.num_epochs),<br>)<br></code></pre></td></tr></table></figure>

<p>然后，您需要一种评估模型的方法。为了进行评估，您可以使用 DDPMPipeline 生成一批样本图像并将其保存为网格：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> DDPMPipeline<br><span class="hljs-keyword">from</span> diffusers.utils <span class="hljs-keyword">import</span> make_image_grid<br><span class="hljs-keyword">import</span> os<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">evaluate</span>(<span class="hljs-params">config, epoch, pipeline</span>):<br>    <span class="hljs-comment"># Sample some images from random noise (this is the backward diffusion process).</span><br>    <span class="hljs-comment"># The default pipeline output type is `List[PIL.Image]`</span><br>    <span class="hljs-comment"># 使用pipeline生成图像</span><br>    images = pipeline(<br>        batch_size=config.eval_batch_size,<br>        generator=torch.manual_seed(config.seed),<br>    ).images<br><br>    <span class="hljs-comment"># 将图像拼接为网格</span><br>    image_grid = make_image_grid(images, rows=<span class="hljs-number">4</span>, cols=<span class="hljs-number">4</span>)<br><br>    <span class="hljs-comment"># 保存验证图像</span><br>    test_dir = os.path.join(config.output_dir, <span class="hljs-string">"samples"</span>)<br>    os.makedirs(test_dir, exist_ok=<span class="hljs-literal">True</span>)<br>    image_grid.save(<span class="hljs-string">f"<span class="hljs-subst">{test_dir}</span>/<span class="hljs-subst">{epoch:04d}</span>.png"</span>)<br></code></pre></td></tr></table></figure>

<p>现在，您可以使用 Accelerate 将所有这些组件包装在一个训练循环中，以轻松进行：</p>
<ol>
<li>TensorBoard 日志记录</li>
<li>梯度累积和混合精度训练。</li>
<li>要将模型上传到 Hub，请编写一个函数来获取存储库名称和信息，然后将其推送到 Hub。</li>
</ol>
<p>接下来是训练核心部分：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">train_loop</span>(<span class="hljs-params">config, model, noise_scheduler, optimizer, train_dataloader, lr_scheduler</span>):<br><br>    <span class="hljs-comment"># 初始化 accelerator 和 tensorboard 日志记录</span><br>    accelerator = Accelerator(<br>        mixed_precision=config.mixed_precision,                          <span class="hljs-comment"># 是否混合精度训练</span><br>        gradient_accumulation_steps=config.gradient_accumulation_steps,  <span class="hljs-comment"># 梯度累积步数</span><br>        log_with=<span class="hljs-string">"tensorboard"</span>,                                          <span class="hljs-comment"># 使用tensorboard记录日志</span><br>        project_dir=os.path.join(config.output_dir, <span class="hljs-string">"logs"</span>),             <span class="hljs-comment"># 日志路径</span><br>    )<br><br><br>    <span class="hljs-comment"># 如果在主进程</span><br>    <span class="hljs-keyword">if</span> accelerator.is_main_process:<br>        <span class="hljs-comment"># 创建输出文件夹</span><br>        <span class="hljs-keyword">if</span> config.output_dir <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>            os.makedirs(config.output_dir, exist_ok=<span class="hljs-literal">True</span>)<br>        <span class="hljs-comment"># 上传到HF的设置</span><br>        <span class="hljs-keyword">if</span> config.push_to_hub:<br>            repo_id = create_repo(<br>                repo_id=config.hub_model_id <span class="hljs-keyword">or</span> Path(config.output_dir).name, exist_ok=<span class="hljs-literal">True</span><br>            ).repo_id<br>        <span class="hljs-comment"># 初始化追踪器</span><br>        accelerator.init_trackers(<span class="hljs-string">"train_example"</span>)<br><br>    <span class="hljs-comment"># 用accelerate包装：模型、优化器、数据加载器和学习率调度器</span><br>    <span class="hljs-comment"># 保证输入和输出的顺序一致即可</span><br>    model, optimizer, train_dataloader, lr_scheduler = accelerator.prepare(<br>        model, optimizer, train_dataloader, lr_scheduler<br>    )<br><br>    <span class="hljs-comment"># 初始化全局步数</span><br>    global_step = <span class="hljs-number">0</span><br><br>    <span class="hljs-comment"># 开始训练模型</span><br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(config.num_epochs):<br>        <span class="hljs-comment"># 创建进度条</span><br>        progress_bar = tqdm(total=<span class="hljs-built_in">len</span>(train_dataloader), disable=<span class="hljs-keyword">not</span> accelerator.is_local_main_process)<br>        <span class="hljs-comment"># 设置进度条描述</span><br>        progress_bar.set_description(<span class="hljs-string">f"Epoch <span class="hljs-subst">{epoch}</span>"</span>)<br><br>        <span class="hljs-comment"># 对数据加载器中的每个批次进行循环</span><br>        <span class="hljs-keyword">for</span> step, batch <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(train_dataloader):<br>            <span class="hljs-comment"># 从数据集获取图像</span><br>            clean_images = batch[<span class="hljs-string">"images"</span>]<br>            <span class="hljs-comment"># 生成即将加入图像的噪声</span><br>            noise = torch.randn(clean_images.shape, device=clean_images.device)<br>            <span class="hljs-comment"># 获取当前batch-size</span><br>            bs = clean_images.shape[<span class="hljs-number">0</span>]<br><br>            <span class="hljs-comment"># 为当前batch中每个图像随机采样一个时间步</span><br>            timesteps = torch.randint(<br>                <span class="hljs-number">0</span>,                                          <span class="hljs-comment"># 起点</span><br>                noise_scheduler.config.num_train_timesteps, <span class="hljs-comment"># 终点</span><br>                (bs,),                                      <span class="hljs-comment"># 形状/数量</span><br>                device=clean_images.device,<br>                dtype=torch.int64<br>            )<br><br>            <span class="hljs-comment"># 使用采样器，根据每个时间步的噪声幅度向干净的图像添加噪声</span><br>            <span class="hljs-comment"># 这是前向扩散过程</span><br>            noisy_images = noise_scheduler.add_noise(clean_images, noise, timesteps)<br><br>            <span class="hljs-comment"># 使用accelerator累积模型梯度</span><br>            <span class="hljs-keyword">with</span> accelerator.accumulate(model):<br>                <span class="hljs-comment"># 预测噪声残差</span><br>                noise_pred = model(noisy_images, timesteps, return_dict=<span class="hljs-literal">False</span>)[<span class="hljs-number">0</span>]<br>                <span class="hljs-comment"># 计算损失函数</span><br>                loss = F.mse_loss(noise_pred, noise)<br>                <span class="hljs-comment"># 反向传播梯度</span><br>                accelerator.backward(loss)<br>                <span class="hljs-comment"># 梯度裁剪</span><br>                accelerator.clip_grad_norm_(model.parameters(), <span class="hljs-number">1.0</span>)<br><br>                optimizer.step()      <span class="hljs-comment"># 迭代优化器</span><br>                lr_scheduler.step()   <span class="hljs-comment"># 迭代学习率调度器</span><br>                optimizer.zero_grad() <span class="hljs-comment"># 清零梯度</span><br><br>            <span class="hljs-comment"># 更新基督徒</span><br>            progress_bar.update(<span class="hljs-number">1</span>)<br>            <span class="hljs-comment"># 记录日志：损失函数，学习率变化</span><br>            logs = {<span class="hljs-string">"loss"</span>: loss.detach().item(), <span class="hljs-string">"lr"</span>: lr_scheduler.get_last_lr()[<span class="hljs-number">0</span>], <span class="hljs-string">"step"</span>: global_step}<br>            progress_bar.set_postfix(**logs)<br>            accelerator.log(logs, step=global_step)<br>            <span class="hljs-comment"># 全局步数增加</span><br>            global_step += <span class="hljs-number">1</span><br><br>        <span class="hljs-comment"># 在每个epoch后，你可以选择使用evaluate()采样一些演示图像并保存模型</span><br>        <span class="hljs-keyword">if</span> accelerator.is_main_process:<br>            <span class="hljs-comment"># 初始化一个pipeline，传入当前训练的模型和调度器</span><br>            pipeline = DDPMPipeline(unet=accelerator.unwrap_model(model), scheduler=noise_scheduler)<br><br>            <span class="hljs-comment"># 根据验证频率保存研究结果</span><br>            <span class="hljs-keyword">if</span> (epoch + <span class="hljs-number">1</span>) % config.save_image_epochs == <span class="hljs-number">0</span> <span class="hljs-keyword">or</span> epoch == config.num_epochs - <span class="hljs-number">1</span>:<br>                evaluate(config, epoch, pipeline)<br><br>            <span class="hljs-keyword">if</span> (epoch + <span class="hljs-number">1</span>) % config.save_model_epochs == <span class="hljs-number">0</span> <span class="hljs-keyword">or</span> epoch == config.num_epochs - <span class="hljs-number">1</span>:<br>                <span class="hljs-keyword">if</span> config.push_to_hub:<br>                    upload_folder(<br>                        repo_id=repo_id,<br>                        folder_path=config.output_dir,<br>                        commit_message=<span class="hljs-string">f"Epoch <span class="hljs-subst">{epoch}</span>"</span>,<br>                        ignore_patterns=[<span class="hljs-string">"step_*"</span>, <span class="hljs-string">"epoch_*"</span>],<br>                    )<br>                <span class="hljs-keyword">else</span>:<br>                    pipeline.save_pretrained(config.output_dir)<br><br>train_loop(config, model, noise_scheduler, optimizer, train_dataloader, lr_scheduler)<br></code></pre></td></tr></table></figure>













<h2 id="Next"><a href="#Next" class="headerlink" title="Next"></a>Next</h2><p><a target="_blank" rel="noopener" href="https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/training_example.ipynb">diffusers_training_example.ipynb - Colaboratory (google.com)</a></p>
<p><a target="_blank" rel="noopener" href="https://huggingface.co/docs/diffusers/training/text_inversion">Textual Inversion (huggingface.co)</a></p>
<p><a target="_blank" rel="noopener" href="https://huggingface.co/docs/diffusers/training/dreambooth">DreamBooth (huggingface.co)</a></p>
<p><a target="_blank" rel="noopener" href="https://huggingface.co/docs/diffusers/training/text2image">Text-to-image (huggingface.co)</a></p>
<p><a target="_blank" rel="noopener" href="https://huggingface.co/docs/diffusers/training/lora">LoRA (huggingface.co)</a></p>
<div id="paginator"></div></div><div id="post-footer"><div id="pages"><div class="footer-link" style="width: 50%;text-align:right;border-right:1px #fe2 solid"><a href="/2024/04/10/4.%20%E8%BD%BD%E5%85%A5%20LoRA%20%E8%BF%9B%E8%A1%8C%E6%8E%A8%E7%90%86/">← 下一篇 4.载入 LoRA 进行推理</a></div><div class="footer-link" style="width: 50%;right:1px;border-left:1px #fe2 solid"><a href="/2024/04/09/2.%20Auto%20Pipeline/">2.AutoPipeline基本教程 上一篇 →</a></div></div></div></div><div class="bottom-btn"><div><a class="i-top" id="to-top" onClick="scrolls.scrolltop();" title="回到顶部" style="opacity: 0; display: none;">∧ </a><a class="i-index" id="to-index" href="#toc-div" title="文章目录">≡</a><a class="i-color" id="color-mode" onClick="colorMode.change()" title="切换主题"></a></div></div></article><aside><div id="about"><a href="/" id="logo"><img src="https://ak.hypergryph.com/assets/index/images/ak/pc/faction/1.png" alt="Logo"></a><h1 id="Dr"><a href="/">TO-Hitori</a></h1><div id="description"><p></p></div></div><div id="aside-block"><div id="toc-div"><h1>目录</h1><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Train-a-diffusion-model"><span class="toc-number">1.</span> <span class="toc-text">Train a diffusion model</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E9%85%8D%E7%BD%AE"><span class="toc-number">1.1.</span> <span class="toc-text">训练配置</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%BD%BD%E5%85%A5%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">1.2.</span> <span class="toc-text">载入数据集</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA-UNet2D-%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.3.</span> <span class="toc-text">创建 UNet2D 模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA%E9%87%87%E6%A0%B7%E5%99%A8"><span class="toc-number">1.4.</span> <span class="toc-text">创建采样器</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.5.</span> <span class="toc-text">训练模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Next"><span class="toc-number">1.6.</span> <span class="toc-text">Next</span></a></li></ol></li></ol></div></div><footer><nobr>构建自 <a target="_blank" rel="noopener" href="http://hexo.io">Hexo</a></nobr><wbr><nobr> 使用主题 <a target="_blank" rel="noopener" href="https://github.com/Yue-plus/hexo-theme-arknights">Arknights</a></nobr><wbr><nobr> 主题作者 <a target="_blank" rel="noopener" href="https://github.com/Yue-plus">Yue_plus</a></nobr></footer></aside></main><canvas id="canvas-dust"></canvas></body></html>