[{"title":"YAML","url":"/2024/03/14/YAML%E5%9F%BA%E7%A1%80/","content":"YAMLYAML Ain’t a Markup Language\nYet Another Markup Language\nYAML是”YAML Ain’t a Markup Language”（YAML不是一种标记语言）的递归缩写。在开发的这种语言时，YAML的意思其实是：”Yet Another Markup Language”（仍是一种标记语言），但为了强调这种语言以数据为中心，而不是以标记语言为重点，而用反向缩略语重命名。YAML (wikipedia.org)\nYAML特点是使用空格来表达层次结构，特别适合用来表达或编辑数据结构、各种配置文件，其文件一般以 .yaml 为后缀。\n基本语法\n以 k: v 的形式来表示键值对的关系\n\n冒号后面必须有一个空格\n\n\n只支持单行注释，注释符号：# \n\n大小写敏感\n\n通过缩进来表示层级关系\n\n缩排中空格的数目不重要，只要相同阶层的元素左侧对齐就可以了\n缩进只能使用空格，不能使用 tab 缩进\n\n\n字符串可以不用双引号\n\n一个文件中可以包含多个文件的内容\n\n用--- 即三个破折号表示一份内容的开始\n用...即三个小数点表示一份内容的结束（非必需）\n\n\n\n数据结构与类型对象以键值对 key: value 形式组织数据\n1. 使用**冒号+空格**来分开键与值\n1. 支持多层嵌套（**用缩进表示层级关系**）\n\nmodel:  base_learning_rate: 4.5e-6  target: ldm.models.autoencoder.AutoencoderKL  params:    monitor: &quot;val/rec_loss&quot;    embed_dim: 64    lossconfig:      target: ldm.modules.losses.LPIPSWithDiscriminator      params:        disc_start: 50001        kl_weight: 0.000001        disc_weight: 0.5\n\n\n支持流式风格（Flow style）的语法：用花括号包裹，用逗号加空格分隔\n\nkey: &#123;child-key1: value1, child-key2: value2 &#125;\n\n\n\n数组\n一组以区块格式（“破折号+空格”）开头的数据组成一个数组\n\nunet_config:  target: ldm.modules.diffusionmodules.openaimodel.UNetModel  params:    image_size: 64    in_channels: 3    out_channels: 3    model_channels: 224    attention_resolutions:    - 8    - 4    - 2    num_res_blocks: 2    channel_mult:    - 1    - 2    - 3    - 4    num_head_channels: 32\n\n\n也支持内联格式来表达（用方括号包裹，逗号加空格分隔）\n\nddconfig:  double_z: True  z_channels: 64  resolution: 256  in_channels: 3  out_ch: 3  ch: 128  ch_mult: [1, 1, 2, 2, 4, 4]    num_res_blocks: 2  attn_resolutions: [16, 8]  dropout: 0.0\n\n\n支持多维数组（用缩进表示层级关系）\n\nvalues:  - - 1    - 2  - - 3    - 4# 等价：    values: [[1, 2], [3, 4]]\n\n\n\n字符串\n字符串一般不需要用引号包裹\n字符串换行视为一个空格\n单引号可以屏蔽转义\n字符串中需要使用转义字符\\就必须使用双引号包裹\n\nstrings:  - Hello world # 不用引号包裹  - Hello     world # 换行视为一个空格  - &#x27;字符串\\n换行\\n演示&#x27;  # 单引号可以屏蔽转义  - &quot;字符串\\n换行\\n演示&quot;  # 双引号使用转移符号# 结果：- Hello world- Hello world- 字符串\\n换行\\n演示- &#x27;字符串  换行  演示&#x27;\n\n\n保留换行：使用竖线符“ | ”来表示该语法，每行的缩进和行尾空白都会被去掉，而额外的缩进会被保留\n\nlines: |  我是第一行  我是第二行    我是吴彦祖      我是第四行  我是第五行  # 结果&quot;我是第一行\\n我是第二行\\n  我是吴彦祖\\n    我是第四行\\n我是第五行\\n&quot;\n\n\n折叠换行：使用右尖括号“ &gt; ”来表示该语法，只有空白行才会被识别为换行，原来的换行符都会被转换成空格\n\nlines: &gt;  我是第一行  我也是第一行  我仍是第一行  我依旧是第一行  我是第二行  这么巧我也是第二行# 结果lines2: &#x27;我是第一行 我也是第一行 我仍是第一行 我依旧是第一行  我是第二行 这么巧我也是第二行  &#x27;\n\n\n\n布尔值\n“true”、“True”、“TRUE”、“yes”、“Yes”和“YES”皆为真\n“false”、“False”、“FALSE”、“no”、“No”和“NO”皆为假\n\n整数\n支持二进制表示\n\nint:  - 666  - 0001_0000# 结果int:- 666- 4096\n\n\n\n浮点数\n支持科学计数法\n\nfloat:  - 3.14  - 6.8523015e+5 # 使用科学计数法# 结果float:- 3.14- 685230.15\n\n空 Nullnull、Null、~ 和不指定值都表示空\nnulls:  - null  - Null  - ~  -# 结果nulls:- null- null- null- null\n\n\n\n强制类型转换双感叹号+目标类型来强制转换类型\na: !!float &#x27;666&#x27; # !! 为严格类型标签b: !!int &#x27;666&#x27;   # 字符串转为整型c: !!str 666     # 整数转为字符串d: !!str 666.66  # 浮点数转为字符串e: !!str true    # 布尔值转为字符串f: !!bool &#x27;yes&#x27;  # 字符串转为布尔值# 结果a: 666.0b: 666c: &#x27;666&#x27;d: &#x27;666.66&#x27;e: &#x27;true&#x27;f: true\n\n\n\n数据复用与合并数据复用在key的冒号后，使用锚点符号&amp;设定锚点，使用引用符号*引用锚点\nmodel: &amp;all_parm  base_learning_rate: 2.0e-06  target: ldm.models.diffusion.ddpm.LatentDiffusion  params: &amp;model_parm    linear_start: 0.0015    linear_end: 0.0195    num_timesteps_cond: 1    log_every_t: 200    timesteps: 1000    first_stage_key: image    image_size: 64    channels: 3    monitor: val/loss_simple_emanew_model: *all_parmnew_params: *model_parm# 结果new_model:  base_learning_rate: 2.0e-06  target: ldm.models.diffusion.ddpm.LatentDiffusion  params:    linear_start: 0.0015    linear_end: 0.0195    num_timesteps_cond: 1    log_every_t: 200    timesteps: 1000    first_stage_key: image    image_size: 64    channels: 3    monitor: val/loss_simple_emanew_params:  linear_start: 0.0015  linear_end: 0.0195  num_timesteps_cond: 1  log_every_t: 200  timesteps: 1000  first_stage_key: image  image_size: 64  channels: 3  monitor: val/loss_simple_ema\n\n\n\n数据合并合并标签符号“&lt;&lt;”配合锚点符号和引用符号使用可以与任意数据进行合并，可以视为面向对象中的继承\nmodel_location: &amp;loc  target: ldm.models.diffusion.ddpm.LatentDiffusionmodel_params: &amp;params  params:    linear_start: 0.0015    linear_end: 0.0195    num_timesteps_cond: 1    log_every_t: 200    timesteps: 1000    first_stage_key: image    image_size: 64    channels: 3    monitor: val/loss_simple_emanew_model:  base_learning_rate: 2.0e-06  &lt;&lt;: *loc  &lt;&lt;: *params  # 结果new_model:  target: ldm.models.diffusion.ddpm.LatentDiffusion  params:    linear_start: 0.0015    linear_end: 0.0195    num_timesteps_cond: 1    log_every_t: 200    timesteps: 1000    first_stage_key: image    image_size: 64    channels: 3    monitor: val/loss_simple_ema  base_learning_rate: 2.0e-06\n\n\n\n参考一文看懂 YAML - 知乎 (zhihu.com)\n","categories":["Tech"],"tags":["python"]},{"title":"conda常用命令","url":"/2021/11/25/conda%E5%B8%B8%E7%94%A8%E6%8C%87%E4%BB%A4/","content":"conda常用命令在windows的cmd下使用如下指令进入conda：\nactivate\n\n环境管理创建虚拟环境：conda create -n [env_name] python=[X.X]\n\n\nenv_name：要创建的环境的名字\nX.X：要创建的环境的python的版本，如3.7\n\n激活虚拟环境conda activate [env_name]\n\n停用当前环境conda deactivate\n\n查看当前环境的python版本python --version\n\n查看所有存在的虚拟环境conda info -econda env list\n\n删除虚拟环境：conda remove -n [env_name] --all\n\n重命名环境\nconda没有直接重命名环境的功能，但可以通过以下两个步骤完成：\n克隆要重命名的环境\n将原环境删除\n\n\n\nconda create --name [newname] --clone [oldname]conda remove --name [oldname] --all\n\n\n\n包管理安装包conda install [pac_name]=[包的版本号]\n\n查看已经安装的包\n查看当前环境：\n\nconda listpip list\n\n\n查看指定环境：\n\nconda list -n [env_name]\n\n删除包conda uninstall [pac_name]\n\n更新指定包conda update [pac_name]pip install [pac_name] -U\n\n清理包\n通过以下指令来删除一些没用的包，这个命令会检查哪些包没有在包缓存中被硬依赖到其他地方，并删除它们\n\nconda clean -p\n\n\n删除conda保存下来的tar包\n\nconda clean -t\n\n\n删除所有的安装包及cache\n\nconda clean -y --all\n\n更新condaconda update conda\n\n安装requirements.txt文件内的包\n首先通过cd指令进入requirements.txt文件所在路径，然后执行如下指令即可\n\npip install -r requirements.txt\n\n包的数据源管理\n显示目前conda的数据源有哪些：\n\nconda config --show channels\n\n\n添加数据源：(清华源)\n\nconda config --add https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/\n\n\n删除数据源\n\nconda config --remove channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/\n\n\n安装出现异常：创建文件：C:\\Users\\[user name]\\AppData\\Roaming\\pip\\pip.ini写入：[global]index-url = http://mirrors.aliyun.com/pypi/simple/[install]trusted-host = mirrors.aliyun.com\n\n","categories":["Tech"],"tags":["python"]},{"title":"PPT注意事项","url":"/2023/12/25/ppt%E5%88%B6%E4%BD%9C/","content":"PPT注意事项\n无衬线字体\n英文首字母大写即可\n常规内容：18-36字号，底部和引用字号&lt;12\n空白简单背景\n徽标不要在内容页出现，用于首页、过渡页、尾页\n避免高饱和颜色的撞色，黑白永不过时\n给页面留白：侧面留出空间，底部不要放太多内容\n标题：每页都要有标题，一个简单句、不要超过两行\n不能出现大段文字\n单页不能有过多内容，独立内容放在不同页，避免失去焦点\n同一页列表不要超过3个条目\n图表的全部要素都要解释清楚\n考虑不同时间限制的情况下内容的安排\n动画：少就是多，简单为主。用来表达递进、放大、进一步、变化等逻辑\n页面切换：平滑\n总结：强调重要内容，增加页面的总结和页面之间的串联讲解，让听众明白当前的演讲处于什么阶段\n\n基本原则\n始终考虑听众如何更容易的接受内容\n不打算聊的内容删除\n好的演讲始于一个好问题\n一页中保持一个内容\n\n","categories":["Note"]},{"title":"NeuS笔记","url":"/2025/05/06/NeuS%E7%AC%94%E8%AE%B0/","content":"NeuS Note渲染过程场景表示要重建的物体场景由两个函数表示：\n\n：将空间位置  映射到物体的符号距离\n：将空间位置  和视图方向  映射为颜色\n\n这两个函数都通过 MLP 实现\n物体的表面  由其 SDF（signed distance function） 的零等值面表示，即Missing or unrecognized delimiter for \\left \\mathcal{S} = \\left{ \\mathbf{x} \\in \\mathbb{R}^3 \\mid f(\\mathbf{x}) = 0 \\right}. \\tag{1} \n\n符号距离函数 SDF\n具体来说，SDF是一个函数，通常表示为 ，其中  是空间的维度（例如二维或三维）。对于空间中的任意一点 ，SDF  表示从点  到最近表面的距离，并且：\n\n如果 ，则点  在物体内部；\n如果 ，则点  在物体表面上；\n如果 ，则点  在物体外部。\n\n\nS-密度为了将体渲染的方法用于训练 SDF 神经网络，引入概率密度函数  ，称为 S-密度场：S-密度场是 Sigmoid 函数  的导数\n即 。\n\n原则上， 可以是任何以 0 为中心的单峰（即钟形）密度分布；这里我们选择逻辑密度分布是因为它的计算方便。\n注意， 的标准差由  给出，这也是一个可训练参数，即随着网络训练的收敛， 接近于零。\n随着  的增大， 的的峰值高度会增加，宽度会变窄，也就是说随着 s 的增大而变得更加尖锐和集中\n\n\nNeuS 的主要思想是，在 S-密度场  的帮助下，使用体渲染通过仅以 2D 输入图像作为监督来训练 SDF 网络。在成功最小化基于这种监督的损失函数之后，期望网络编码的 SDF 的零等值面能够准确地表示重建的表面 ，其诱导的 S-密度  在表面附近呈现出显著的高值。\n\n  越大 -&gt; 越趋近于0 -&gt;  越趋近于物体表面\n\n渲染给定一个像素，我们将从该像素发出的射线表示为 ，其中  是相机的中心， 是射线的单位方向向量。我们通过以下方式沿射线累积颜色：\n\n\n 是该像素的输出颜色\n 是点  的权重函数\n 是沿视图方向  的点  处的颜色。\n\n对权重函数  的要求从 2D 图像中学习精确的 SDF 表示的关键是建立输出颜色  和 SDF  之间的适当联系，即基于场景的 SDF  导出沿射线的适当权重函数 。\n权重函数  要满足以下条件：\n\n无偏性。给定一条相机射线 ， 在表面交点  处取得局部最大值，即 ，也就是说，点  位于 SDF 的零等值面上（）。\n\n遮挡感知。给定任意两个深度值  和 ，满足 ，，，且 ，有 。也就是说，当两个点具有相同的 SDF 值（因此具有相同的 SDF 诱导的 S-密度值）时，更靠近视点的点应该对最终输出颜色有更大的贡献。\n\n\n一个无偏的权重函数  保证了相机射线与 SDF 的零等值面的交点对像素颜色的贡献最大。\n遮挡感知属性确保了当一条射线依次穿过多个表面时，渲染过程将正确地使用离相机最近的表面的颜色来计算输出颜色。\nNeRF的朴素解NeRF中的权重函数定义如下：\n\n 是NeRF中所谓的体密度，这里将  设置为等于 S-密度值，即  \n 表示沿射线的累积透射率。\n\n尽管由此产生的权重函数具有遮挡感知性，但它是有偏的，因为它在重建的表面中引入了固有的误差。如图所示，权重函数  在射线达到满足  的表面点  之前的某点达到局部最大值\n\nNeuS对权重函数  的解为了介绍 NeuS 的解决方案，首先介绍一种直接使用归一化 S-密度作为权重来构建无偏权重函数的简单方法：这种权重函数的构造是无偏的，但不具备遮挡感知性。\n\n例如，如果射线穿透两个表面，SDF 函数  将在射线上有两个零点，这导致权重函数  上有两个峰值，并且由此产生的权重函数将平均混合这两个表面的颜色，而不考虑遮挡。\n\n为了确保权重函数  的遮挡感知属性，我们仍将遵循NeRF 的基本框架，以一种新的方式从 S-密度定义我们的权重函数 ：\n\n：不透明密度函数，是标准体积渲染中体积密度  的对应\n：累积透射率， 区间的不透明度越大 -&gt;  的积分越大 -&gt;  越小，累积透明度越小\n\n不透明密度函数  的推导首先考虑一个简单的理想情况：表面是一个远离相机的平面，且只有一个交点\n此时的符号距离函数 SDF 很明显是：\n\n焦点位置：\n 是视图方向  和向外表面法线向量  之间的角度\n\n在这种假设下公式 5 确实满足要求，由于 是一个常数，可以得出：\n在体积渲染框架内，权重函数由  给出，为了推导 ，有：\n\n由于 ，很容易验证 。\n根据  函数的设定：，可知  \n由此可得：\n\n朴素解中的偏差权重函数定义为 ，其中不透明度 。因此，我们有待定\n","categories":["Note"],"tags":["三维重建"]},{"url":"/2025/05/07/hexo-blog/Welcome/","content":"This is your new vault.\nMake a note of something, [[create a link]], or try the Importer!\nWhen you’re ready, delete this note and make the vault your own.\n"},{"title":"ffmpeg","url":"/2025/05/07/ffmpeg/","content":"下载与安装\n下载链接：ffmpeg-win64-动态链接版本\n\n安装：解压后将 bin 文件夹的路径加入到环境变量\n\n验证安装：ffmpeg -version，出现如下信息\nffmpeg version N-105384-g3c831847a8-20220127 Copyright (c) 2000-2022 the FFmpeg developersbuilt with gcc 11.2.0 (crosstool-NG 1.24.0.498_5075e1f)configuration: --prefix=/ffbuild/prefix --pkg-config-flags=--static --pkg-config=pkg-config --cross-prefix=x86_64-w64-mingw32- --arch=x86_64 --target-os=mingw32 --enable-gpl --enable-version3 --disable-debug --disable-w32threads --enable-pthreads --enable-iconv --enable-libxml2 --enable-zlib --enable-libfreetype --enable-libfribidi --enable-gmp --enable-lzma --enable-fontconfig --enable-libvorbis --enable-opencl --disable-libpulse --enable-libvmaf --disable-libxcb --disable-xlib --enable-amf --enable-libaom --enable-avisynth --enable-libdav1d --enable-libdavs2 --disable-libfdk-aac --enable-ffnvcodec --enable-cuda-llvm --enable-frei0r --enable-libgme --enable-libass --enable-libbluray --enable-libmp3lame --enable-libopus --enable-librist --enable-libtheora --enable-libvpx --enable-libwebp --enable-lv2 --enable-libmfx --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenh264 --enable-libopenjpeg --enable-libopenmpt --enable-librav1e --enable-librubberband --enable-schannel --enable-sdl2 --enable-libsoxr --enable-libsrt --enable-libsvtav1 --enable-libtwolame --enable-libuavs3d --disable-libdrm --disable-vaapi --enable-libvidstab --enable-vulkan --enable-libshaderc --enable-libplacebo --enable-libx264 --enable-libx265 --enable-libxavs2 --enable-libxvid --enable-libzimg --enable-libzvbi --extra-cflags=-DLIBTWOLAME_STATIC --extra-cxxflags= --extra-ldflags=-pthread --extra-ldexeflags= --extra-libs=-lgomp --extra-version=20220127libavutil      57. 19.100 / 57. 19.100libavcodec     59. 20.100 / 59. 20.100libavformat    59. 17.101 / 59. 17.101libavdevice    59.  5.100 / 59.  5.100libavfilter     8. 26.101 /  8. 26.101libswscale      6.  5.100 /  6.  5.100libswresample   4.  4.100 /  4.  4.100libpostproc    56.  4.100 / 56.  4.100\n\n使用方法\n基本使用方法：-i 指定输入视频，-y 自动覆盖输出文件\nffmpeg -i input.avi -y output.mp4\n\n指定视频编码器：-c:v video encoder\n# h264ffmpeg -i input.avi -c:v libx264 output.mp4# Nvidia GPU 加速编码（速度快但质量差）ffmpeg -i input.avi -c:v h264_nvenc output.mp4\n\n预设编码速度：-preset\nffmpeg -i input.avi -c:v libx264 -preset [value] output.mp4value取值如下：\t- ultrafas\t- superfast\t- veryfast\t- faster\t- fast\t- medium (default)\t- slow\t- slower\t- veryslow速度越快，压缩后文件越大\n\n控制编码视频的质量：-crf 参数用于设置恒定质量模式（Constant Rate Factor，CRF）。它通过调整编码器的压缩级别来平衡视频质量和文件大小。\nffmpeg -i input.mp4 -c:v libx264 -crf 18 output.mp4\n\n\nCRF 值范围：通常在 0 到 51 之间，数值越低，质量越高，文件大小也越大；数值越高，质量越低，文件大小越小。\n推荐值：\n18：被认为是视觉上无损的，适合高质量视频。\n23：默认值，适合普通质量需求。\n28：适合较低质量需求，文件大小更小。\n51：最低质量，文件大小最小，但可能会出现明显的压缩伪影。\n\n\n\n\n\n常见的视频过滤器\n裁剪（crop）\n\n语法：crop=width:height:x:y\n\n示例：\nffmpeg -i input.mp4 -vf \"crop=1280:720:0:0\" output.mp4\n\n这将从输入视频中裁剪出一个宽为 1280 像素、高为 720 像素的区域，裁剪区域的左上角坐标为 (0, 0)。\n\n\n\n缩放（scale）\n\n语法：scale=width:height\n\n示例：\nffmpeg -i input.mp4 -vf \"scale=640:480\" output.mp4\n\n这将把输入视频缩放到宽为 640 像素、高为 480 像素。\n\n\n\n改变帧率（fps）：\n\n语法：fps=25\n\n示例：\n\n\nffmpeg -i input.mp4 -vf \"fps=30\" output.mp4\n\n这将把输入视频缩放到宽为 640 像素、高为 480 像素。\n\n旋转（rotate）\n\n语法：rotate=angle\n\n示例：\nffmpeg -i input.mp4 -vf \"rotate=90\" output.mp4\n\n这将把输入视频顺时针旋转 90 度。\n\n\n\n添加水印（overlay）\n\n语法：overlay=x:y\n\n示例：\nffmpeg -i input.mp4 -i watermark.png -filter_complex \"overlay=10:10\" output.mp4\n\n这将把 watermark.png 图片作为水印添加到输入视频的左上角，水印的左上角坐标为 (10, 10)。\n\n\n\n调整颜色（eq）\n\n语法：eq=brightness:contrast:saturation\n\n示例：\nffmpeg -i input.mp4 -vf \"eq=0.5:1.5:1.2\" output.mp4\n\n这将调整视频的亮度为 0.5、对比度为 1.5、饱和度为 1.2。\n\n\n\n模糊（boxblur）\n\n语法：boxblur=luma_radius:chroma_radius:luma_power:chroma_power\n\n示例：\nffmpeg -i input.mp4 -vf \"boxblur=10:10\" output.mp4\n\n这将对视频应用模糊效果，模糊半径为 10。\n\n\n\n裁剪并缩放（crop 和 scale 组合）\n\n语法：crop=width:height:x:y,scale=width:height\n\n示例：\nffmpeg -i input.mp4 -vf \"crop=1280:720:0:0,scale=640:480\" output.mp4\n\n这将先裁剪视频，然后将裁剪后的视频缩放到宽为 640 像素、高为 480 像素。\n\n\n\n\n裁剪视频\n指定持续时间：-ss -t\nffmpeg -i input.mp4 -ss 00:01:30 -t 00:00:30 output.mp4\n\n这个命令表示从输入视频 input.mp4 的第1分30秒开始，截取30秒的内容，保存为 output.mp4。\n\n\n\n注意事项\n\n精度问题：-ss 参数在某些情况下可能会有精度问题，尤其是在使用硬件加速或某些特定的编解码器时。如果需要高精度裁剪，建议在解码后使用 -ss 参数。\n位置：-ss 参数的位置很重要。如果放在 -i 参数之前，ffmpeg 会在解码时跳过指定的时间，这可能会更快，但精度较低。如果放在 -i 参数之后，ffmpeg 会在解码后裁剪，精度更高，但速度可能会慢一些。\n\n\n\n指定结束时间：-ss -to\n ffmpeg -i input.mp4 -ss 00:01:30 -to 00:02:00 output.mp4\n\n 这个命令表示从输入视频 input.mp4 的第1分30秒开始，处理到第2分钟结束，保存为 output.mp4。\n\n\n总结ffmpeg -i input.mp4 -vf \"fps=30,scale=1920:1080\" -crf 18 -y output.mp4\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","categories":["tool"],"tags":["video_c"]}]